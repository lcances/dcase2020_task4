import collections
import os

os.environ["MKL_NUM_THREADS"] = "2"
os.environ["NUMEXPR_NUM_THREADS"] = "2"
os.environ["OMP_NUM_THREADS"] = "2"
import numpy as np
import pandas as pd

from .datasetManager import DatasetManager, DESEDManager
import torch.utils.data

from .augmentation_utils.signal_augmentations import SignalAugmentation
from .augmentation_utils.spec_augmentations import SpecAugmentation

#log system
import logging
from dcase2020.util.log import log_flat
log = logging.getLogger(__name__)


class DESEDDataset(torch.utils.data.Dataset):
    def __init__(self, manager: DatasetManager, train: bool, val: bool,
                 weak: bool = True, strong: bool = False,
                 augments=(), cached=False):
        """
        The DESED pytorch ready dataset. It  automatically apply augmentation on the signal if needed, extract the
        feature describe by :func:`extract_feature() <dcase2020.datasetManager.DatasetManager.extract_feature>` and
        apply augmentation of the feature if needed.

        :param manager: The DESEDManager with the wanted subset loaded
        :param train: The dataset will poll files within the training subset generated by the manager (val must be
        False)
        :param val: The dataset will poll files within the validation subset generated by the manager (train must be
        False)
        :param weak: Does the dataset will return the weak ground truth
        :param strong: Does the dataset will return the strong ground truth
        :param augments: The list of augmentation to apply :see: augmentation__utils
        :param cached: If true the feature extracted will be store in memory to be reuse. Greatly reduce training
        time. It is thread/process safe but can lead to huge memory usage (whole features can be store in memory). It
        is automatically deactivate if the list of augmentation is not empty.
        """
        self.manager = manager
        self.train = train
        self.val = val
        self.weak = weak
        self.strong = strong
        self.augments = augments
        self.cached = cached

        if len(augments) != 0 and cached:
            logging.info("Cache system deactivate due to usage of online augmentation")
            self.cached = False

        self._check_arguments()

        if self.train:
            self.X = self.manager.X
            self.y = self.manager.y
            
        elif self.val:
            self.X = self.manager.X_val
            self.y = self.manager.y_val

        self.filenames = list(self.X.keys())

        # alias for verbose mode
        self.tqdm_func = self.manager.tqdm_func

    def _check_arguments(self):
        if sum([self.train, self.val]) != 1:
            raise AssertionError("Train and val and mutually exclusive")
        
        if self.val:
            if not self.manager.validation_exist:
                raise RuntimeError("Can't create a validation set if the split is not done. Call \"split_train_validation\" from the manager")
        
    def __len__(self):
        nb_file = len(self.filenames)
        return nb_file

    def __getitem__(self, index):
        filename = self.filenames[index]
        return self._generate_data(filename)

    def _generate_data(self, filename: str):
        # load the raw_audio
        raw_audio = self.X[filename]

        # recover ground truth
        y = []
        if self.weak:
            weak_y = self.y.at[filename, "classID"]
            weak_y = np.asarray(weak_y)
            y.append(weak_y)
        elif self.strong:
            strong_y = self.y.at[filename, "strongID"]
            strong_y = np.asarray(strong_y)
            y.append(strong_y)

        raw_audio = self._apply_augmentation(raw_audio, SignalAugmentation)
        raw_audio = self._pad_and_crop(raw_audio)

        # extract feature and apply spec augmentation
        feat = self.manager.extract_feature(raw_audio, filename=filename, cached=self.cached)
        feat = self._apply_augmentation(feat, SpecAugmentation)

        return feat, y

    def _pad_and_crop(self, raw_audio):
        LENGTH = DESEDManager.LENGTH
        SR = self.manager.sampling_rate

        if len(raw_audio) < LENGTH * SR:
            missing = (LENGTH * SR) - len(raw_audio)
            raw_audio = np.concatenate((raw_audio, [0] * missing))

        if len(raw_audio) > LENGTH * SR:
            raw_audio = raw_audio[:LENGTH * SR]

        return raw_audio

    def _apply_augmentation(self, data, augType):
        np.random.shuffle(self.augments)
        for augment_func in self.augments:
            if isinstance(augment_func, augType):
                return augment_func(data)

        return data