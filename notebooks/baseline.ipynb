{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%% Import\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# dataset manager\n",
    "from dcase2020.datasetManager import DESEDManager\n",
    "from dcase2020.datasets import DESEDDataset\n",
    "\n",
    "# utility function & metrics & augmentation\n",
    "import dcase2020.augmentation_utils.signal_augmentations as signal_augmentations\n",
    "import dcase2020.augmentation_utils.spec_augmentations as spec_augmentations\n",
    "import dcase2020.augmentation_utils.signal_augmentations as signal_augmentations\n",
    "from dcase2020.pytorch_metrics.metrics import FScore, BinaryAccuracy\n",
    "from dcase2020.util.utils import get_datetime, reset_seed\n",
    "\n",
    "# models\n",
    "from dcase2020.models import WeakBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ==== set the log ====\n",
    "import logging\n",
    "import logging.config\n",
    "from dcase2020.util.log import DEFAULT_LOGGING\n",
    "logging.config.dictConfig(DEFAULT_LOGGING)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ==== reset the seed for reproductability ====\n",
    "reset_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mDEBUG --- datasetManager.__init__ >>> ../dataset/dcase2020_dataset_22050.hdf5\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._load_metadata >>> Reading metadata: ../dataset/DESED/dataset/metadata/train/weak.tsv\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._load_metadata >>> Reading metadata: ../dataset/DESED/dataset/metadata/train/unlabel_in_domain.tsv\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._load_metadata >>> Reading metadata: ../dataset/DESED/dataset/metadata/train/synthetic20.tsv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ==== load the dataset ====\n",
    "dese_metadata_root = \"../dataset/DESED/dataset/metadata\"\n",
    "desed_audio_root = \"../dataset/DESED/dataset/audio\"\n",
    "\n",
    "manager = DESEDManager(\n",
    "    dese_metadata_root, desed_audio_root,\n",
    "    sampling_rate = 22050,\n",
    "    validation_ratio=0.2,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37mINFO --- datasetManager.add_subset >>> Loading dataset: train, subset: weak\u001b[0m\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> hdf_file: <HDF5 file \"dcase2020_dataset_22050.hdf5\" (mode r)>\u001b[0m\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> path: ../dataset/DESED/dataset/audio/train/weak\u001b[0m\n",
      "\u001b[1;34mDEBUG --- datasetManager.get_subset >>> output size: 1340\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "manager.add_subset(\"weak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37mINFO --- datasetManager.split_train_validation >>> Creating new train / validation split\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager.split_train_validation >>> validation ratio : 0.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "manager.split_train_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%  setup augmentation and create pytorch dataset\n"
    }
   },
   "outputs": [],
   "source": [
    "augments = [\n",
    "    # signal_augmentation.Noise(0.5, target_snr=15),\n",
    "    # signal_augmentation.RandomTimeDropout(0.5, dropout=0.2)\n",
    "]\n",
    "\n",
    "train_dataset = DESEDDataset(manager, train=True, val=False, augments=augments, cached=True)\n",
    "val_dataset = DESEDDataset(manager, train=False, val=True, augments=[], cached=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1097, 243)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.filenames), len(val_dataset.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Setup model and training parameters\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeakBaseline(\n",
       "  (features): Sequential(\n",
       "    (0): ConvPoolReLU(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=(4, 2), stride=(4, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout2d(p=0.0, inplace=False)\n",
       "      (4): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): ConvPoolReLU(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=(4, 2), stride=(4, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout2d(p=0.3, inplace=False)\n",
       "      (4): ReLU6(inplace=True)\n",
       "    )\n",
       "    (2): ConvPoolReLU(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=(4, 2), stride=(4, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout2d(p=0.3, inplace=False)\n",
       "      (4): ReLU6(inplace=True)\n",
       "    )\n",
       "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): ReLU6()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten()\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=1696, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WeakBaseline()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================\n",
      "                               Kernel Shape      Output Shape  Params  \\\n",
      "Layer                                                                   \n",
      "0_features.0.Conv2d_0         [1, 32, 3, 3]  [1, 32, 64, 431]   320.0   \n",
      "1_features.0.MaxPool2d_1                  -  [1, 32, 16, 215]       -   \n",
      "2_features.0.BatchNorm2d_2             [32]  [1, 32, 16, 215]    64.0   \n",
      "3_features.0.Dropout2d_3                  -  [1, 32, 16, 215]       -   \n",
      "4_features.0.ReLU6_4                      -  [1, 32, 16, 215]       -   \n",
      "5_features.1.Conv2d_0        [32, 32, 3, 3]  [1, 32, 16, 215]  9.248k   \n",
      "6_features.1.MaxPool2d_1                  -   [1, 32, 4, 107]       -   \n",
      "7_features.1.BatchNorm2d_2             [32]   [1, 32, 4, 107]    64.0   \n",
      "8_features.1.Dropout2d_3                  -   [1, 32, 4, 107]       -   \n",
      "9_features.1.ReLU6_4                      -   [1, 32, 4, 107]       -   \n",
      "10_features.2.Conv2d_0       [32, 32, 3, 3]   [1, 32, 4, 107]  9.248k   \n",
      "11_features.2.MaxPool2d_1                 -    [1, 32, 1, 53]       -   \n",
      "12_features.2.BatchNorm2d_2            [32]    [1, 32, 1, 53]    64.0   \n",
      "13_features.2.Dropout2d_3                 -    [1, 32, 1, 53]       -   \n",
      "14_features.2.ReLU6_4                     -    [1, 32, 1, 53]       -   \n",
      "15_features.Conv2d_3         [32, 32, 1, 1]    [1, 32, 1, 53]  1.056k   \n",
      "16_features.ReLU6_4                       -    [1, 32, 1, 53]       -   \n",
      "17_classifier.Flatten_0                   -         [1, 1696]       -   \n",
      "18_classifier.Dropout_1                   -         [1, 1696]       -   \n",
      "19_classifier.Linear_2           [1696, 10]           [1, 10]  16.97k   \n",
      "\n",
      "                             Mult-Adds  \n",
      "Layer                                   \n",
      "0_features.0.Conv2d_0        7.944192M  \n",
      "1_features.0.MaxPool2d_1             -  \n",
      "2_features.0.BatchNorm2d_2        32.0  \n",
      "3_features.0.Dropout2d_3             -  \n",
      "4_features.0.ReLU6_4                 -  \n",
      "5_features.1.Conv2d_0        31.70304M  \n",
      "6_features.1.MaxPool2d_1             -  \n",
      "7_features.1.BatchNorm2d_2        32.0  \n",
      "8_features.1.Dropout2d_3             -  \n",
      "9_features.1.ReLU6_4                 -  \n",
      "10_features.2.Conv2d_0       3.944448M  \n",
      "11_features.2.MaxPool2d_1            -  \n",
      "12_features.2.BatchNorm2d_2       32.0  \n",
      "13_features.2.Dropout2d_3            -  \n",
      "14_features.2.ReLU6_4                -  \n",
      "15_features.Conv2d_3           54.272k  \n",
      "16_features.ReLU6_4                  -  \n",
      "17_classifier.Flatten_0              -  \n",
      "18_classifier.Dropout_1              -  \n",
      "19_classifier.Linear_2          16.96k  \n",
      "----------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params             37.034k\n",
      "Trainable params         37.034k\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             43.663008M\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "input_tensor = torch.zeros((1, 64, 431), dtype=torch.float)\n",
    "input_tensor = input_tensor.cuda()\n",
    "\n",
    "s = summary(model, input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters (crit & callbacks & loaders & metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Setup model and training parameters\n"
    }
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "nb_epochs = 100\n",
    "batch_size = 32\n",
    "nb_batch = len(train_dataset) // batch_size\n",
    "\n",
    "# criterion & optimizers\n",
    "criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "optimizers = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# callbacks\n",
    "callbacks = []\n",
    "\n",
    "# tensorboard\n",
    "title = \"WeakBaseline_%s\" % (get_datetime())\n",
    "tensorboard = SummaryWriter(log_dir=\"../tensorboard/%s\" % title, comment=\"weak baseline\")\n",
    "\n",
    "# loaders\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Metrics\n",
    "binacc_func = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% training function\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch: int):\n",
    "    start_time = time.time()\n",
    "    binacc_func.reset()\n",
    "    model.train()\n",
    "    print(\"\") # <-- Force new line\n",
    "    \n",
    "    for i, (X, y) in enumerate(training_loader):\n",
    "        X, y = X.cuda().float(), y.cuda().float()\n",
    "        \n",
    "        logits = model(X)\n",
    "        \n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        # calc metrics\n",
    "        pred = F.sigmoid(logits)\n",
    "        binacc = binacc_func(pred, y)\n",
    "        \n",
    "        # back propagation\n",
    "        optimizers.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizers.step()\n",
    "        \n",
    "        # logs\n",
    "        print(\"Epoch {}, {:d}% \\t loss: {:.4e} - acc: {:.4e} - took {:.2f}s\".format(\n",
    "            epoch + 1,\n",
    "            int(100 * (i + 1) / nb_batch),\n",
    "            loss.item(),\n",
    "            binacc,\n",
    "            time.time() - start_time\n",
    "        ), end=\"\\r\")\n",
    "        \n",
    "    # tensorboard logs\n",
    "    tensorboard.add_scalar(\"train/loss\", loss.item(), epoch)\n",
    "    tensorboard.add_scalar(\"train/acc\", binacc, epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% validation function\n"
    }
   },
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    binacc_func.reset()\n",
    "    model.train()\n",
    "    print(\"\") # <-- Force new line\n",
    "    \n",
    "    for i, (X, y) in enumerate(val_loader):\n",
    "        X, y = X.cuda().float(), y.cuda().float()\n",
    "        \n",
    "        logits = model(X)\n",
    "        \n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        # calc metrics\n",
    "        pred = F.sigmoid(logits)\n",
    "        binacc = binacc_func(pred, y)\n",
    "        \n",
    "        # back propagation\n",
    "        optimizers.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizers.step()\n",
    "        \n",
    "        # logs\n",
    "        print(\"validation \\t val_loss: {:.4e} - val_acc: {:.4e}\".format(\n",
    "            loss.item(),\n",
    "            binacc,\n",
    "        ), end=\"\\r\")\n",
    "        \n",
    "    # tensorboard logs\n",
    "    tensorboard.add_scalar(\"val/loss\", loss.item(), epoch)\n",
    "    tensorboard.add_scalar(\"val/acc\", binacc, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/samova/lcances/.miniconda3/envs/dl/lib/python3.7/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 102% \t loss: 3.5969e-01 - acc: 8.4414e-01 - took 10.90s\n",
      "validation \t val_loss: 4.4592e-01 - val_acc: 8.4969e-01\n",
      "Epoch 2, 102% \t loss: 3.8914e-01 - acc: 8.5528e-01 - took 0.49s\n",
      "validation \t val_loss: 4.6168e-01 - val_acc: 8.4681e-01\n",
      "Epoch 3, 102% \t loss: 2.4749e-01 - acc: 8.5740e-01 - took 0.44s\n",
      "validation \t val_loss: 4.6852e-01 - val_acc: 8.4850e-01\n",
      "Epoch 4, 102% \t loss: 2.7380e-01 - acc: 8.6133e-01 - took 0.44s\n",
      "validation \t val_loss: 5.0707e-01 - val_acc: 8.5512e-01\n",
      "Epoch 5, 102% \t loss: 3.6495e-01 - acc: 8.7035e-01 - took 0.44s\n",
      "validation \t val_loss: 5.1737e-01 - val_acc: 8.6083e-01\n",
      "Epoch 6, 102% \t loss: 2.7983e-01 - acc: 8.7504e-01 - took 0.44s\n",
      "validation \t val_loss: 4.6521e-01 - val_acc: 8.7062e-01\n",
      "Epoch 7, 102% \t loss: 3.9089e-01 - acc: 8.7562e-01 - took 0.44s\n",
      "validation \t val_loss: 5.0123e-01 - val_acc: 8.7007e-01\n",
      "Epoch 8, 102% \t loss: 3.0307e-01 - acc: 8.8002e-01 - took 0.44s\n",
      "validation \t val_loss: 4.6439e-01 - val_acc: 8.7494e-01\n",
      "Epoch 9, 102% \t loss: 2.7678e-01 - acc: 8.8177e-01 - took 0.44s\n",
      "validation \t val_loss: 4.4926e-01 - val_acc: 8.6645e-01\n",
      "Epoch 10, 102% \t loss: 2.6141e-01 - acc: 8.8611e-01 - took 0.44s\n",
      "validation \t val_loss: 4.5168e-01 - val_acc: 8.7724e-01\n",
      "Epoch 11, 102% \t loss: 2.5756e-01 - acc: 8.8455e-01 - took 0.44s\n",
      "validation \t val_loss: 4.2119e-01 - val_acc: 8.7531e-01\n",
      "Epoch 12, 102% \t loss: 3.1256e-01 - acc: 8.8655e-01 - took 0.44s\n",
      "validation \t val_loss: 4.2797e-01 - val_acc: 8.8495e-01\n",
      "Epoch 13, 102% \t loss: 3.0626e-01 - acc: 8.9059e-01 - took 0.44s\n",
      "validation \t val_loss: 4.3721e-01 - val_acc: 8.7675e-01\n",
      "Epoch 14, 102% \t loss: 2.5748e-01 - acc: 8.8955e-01 - took 0.44s\n",
      "validation \t val_loss: 4.4478e-01 - val_acc: 8.8051e-01\n",
      "Epoch 15, 102% \t loss: 2.5421e-01 - acc: 8.8870e-01 - took 0.44s\n",
      "validation \t val_loss: 4.2328e-01 - val_acc: 8.8250e-01\n",
      "Epoch 16, 102% \t loss: 2.2661e-01 - acc: 8.9205e-01 - took 0.44s\n",
      "validation \t val_loss: 3.9745e-01 - val_acc: 8.8771e-01\n",
      "Epoch 17, 102% \t loss: 4.0001e-01 - acc: 8.9399e-01 - took 0.44s\n",
      "validation \t val_loss: 3.6169e-01 - val_acc: 8.8287e-01\n",
      "Epoch 18, 102% \t loss: 2.2765e-01 - acc: 8.9514e-01 - took 0.44s\n",
      "validation \t val_loss: 4.0761e-01 - val_acc: 8.8146e-01\n",
      "Epoch 19, 102% \t loss: 3.2371e-01 - acc: 8.9570e-01 - took 0.44s\n",
      "validation \t val_loss: 3.8078e-01 - val_acc: 8.8729e-01\n",
      "Epoch 20, 102% \t loss: 2.3143e-01 - acc: 8.9513e-01 - took 0.44s\n",
      "validation \t val_loss: 4.3414e-01 - val_acc: 8.9060e-01\n",
      "Epoch 21, 102% \t loss: 3.1221e-01 - acc: 8.9824e-01 - took 0.44s\n",
      "validation \t val_loss: 3.7648e-01 - val_acc: 8.8680e-01\n",
      "Epoch 22, 102% \t loss: 3.2883e-01 - acc: 8.9588e-01 - took 0.44s\n",
      "validation \t val_loss: 3.2401e-01 - val_acc: 8.9385e-01\n",
      "Epoch 23, 102% \t loss: 2.8663e-01 - acc: 8.9570e-01 - took 0.44s\n",
      "validation \t val_loss: 3.5072e-01 - val_acc: 8.9840e-01\n",
      "Epoch 24, 102% \t loss: 3.4101e-01 - acc: 8.9860e-01 - took 0.44s\n",
      "validation \t val_loss: 4.7750e-01 - val_acc: 8.8703e-01\n",
      "Epoch 25, 102% \t loss: 2.2448e-01 - acc: 8.9541e-01 - took 0.44s\n",
      "validation \t val_loss: 3.4138e-01 - val_acc: 8.9891e-01\n",
      "Epoch 26, 102% \t loss: 1.9786e-01 - acc: 9.0247e-01 - took 0.44s\n",
      "validation \t val_loss: 3.9825e-01 - val_acc: 9.0033e-01\n",
      "Epoch 27, 102% \t loss: 3.8250e-01 - acc: 9.0027e-01 - took 0.44s\n",
      "validation \t val_loss: 3.9015e-01 - val_acc: 8.9137e-01\n",
      "Epoch 28, 102% \t loss: 2.2549e-01 - acc: 9.0206e-01 - took 0.44s\n",
      "validation \t val_loss: 3.5439e-01 - val_acc: 9.0789e-01\n",
      "Epoch 29, 102% \t loss: 1.9635e-01 - acc: 9.0482e-01 - took 0.44s\n",
      "validation \t val_loss: 3.6305e-01 - val_acc: 8.9383e-01\n",
      "Epoch 30, 102% \t loss: 3.3350e-01 - acc: 9.0558e-01 - took 0.44s\n",
      "validation \t val_loss: 4.6901e-01 - val_acc: 9.0199e-01\n",
      "Epoch 31, 102% \t loss: 3.9385e-01 - acc: 9.0227e-01 - took 0.44s\n",
      "validation \t val_loss: 3.0837e-01 - val_acc: 8.9722e-01\n",
      "Epoch 32, 102% \t loss: 1.9663e-01 - acc: 9.0381e-01 - took 0.44s\n",
      "validation \t val_loss: 3.9473e-01 - val_acc: 8.9591e-01\n",
      "Epoch 33, 102% \t loss: 1.6457e-01 - acc: 9.0818e-01 - took 0.44s\n",
      "validation \t val_loss: 3.7418e-01 - val_acc: 9.0884e-01\n",
      "Epoch 34, 102% \t loss: 2.2282e-01 - acc: 9.0755e-01 - took 0.44s\n",
      "validation \t val_loss: 3.2343e-01 - val_acc: 8.9852e-01\n",
      "Epoch 35, 102% \t loss: 2.6389e-01 - acc: 9.1048e-01 - took 0.44s\n",
      "validation \t val_loss: 3.9185e-01 - val_acc: 9.0228e-01\n",
      "Epoch 36, 102% \t loss: 2.8366e-01 - acc: 9.0991e-01 - took 0.44s\n",
      "validation \t val_loss: 3.8794e-01 - val_acc: 9.0035e-01\n",
      "Epoch 37, 102% \t loss: 2.6819e-01 - acc: 9.1161e-01 - took 0.44s\n",
      "validation \t val_loss: 2.6542e-01 - val_acc: 9.1678e-01\n",
      "Epoch 38, 102% \t loss: 3.0882e-01 - acc: 9.1039e-01 - took 0.44s\n",
      "validation \t val_loss: 3.3377e-01 - val_acc: 9.1024e-01\n",
      "Epoch 39, 102% \t loss: 2.0068e-01 - acc: 9.1163e-01 - took 0.44s\n",
      "validation \t val_loss: 3.1729e-01 - val_acc: 9.0870e-01\n",
      "Epoch 40, 102% \t loss: 2.9148e-01 - acc: 9.1462e-01 - took 0.44s\n",
      "validation \t val_loss: 3.3299e-01 - val_acc: 9.0362e-01\n",
      "Epoch 41, 102% \t loss: 3.1760e-01 - acc: 9.1179e-01 - took 0.45s\n",
      "validation \t val_loss: 3.2291e-01 - val_acc: 9.0633e-01\n",
      "Epoch 42, 102% \t loss: 1.9647e-01 - acc: 9.1206e-01 - took 0.45s\n",
      "validation \t val_loss: 3.4029e-01 - val_acc: 9.0623e-01\n",
      "Epoch 43, 102% \t loss: 2.3498e-01 - acc: 9.1202e-01 - took 0.44s\n",
      "validation \t val_loss: 3.5344e-01 - val_acc: 9.1141e-01\n",
      "Epoch 44, 102% \t loss: 2.2794e-01 - acc: 9.1301e-01 - took 0.44s\n",
      "validation \t val_loss: 3.3266e-01 - val_acc: 9.1118e-01\n",
      "Epoch 45, 102% \t loss: 2.4304e-01 - acc: 9.1299e-01 - took 0.45s\n",
      "validation \t val_loss: 3.2357e-01 - val_acc: 9.0463e-01\n",
      "Epoch 46, 102% \t loss: 1.6528e-01 - acc: 9.1586e-01 - took 0.44s\n",
      "validation \t val_loss: 3.5015e-01 - val_acc: 9.1571e-01\n",
      "Epoch 47, 102% \t loss: 1.6321e-01 - acc: 9.1403e-01 - took 0.44s\n",
      "validation \t val_loss: 3.3014e-01 - val_acc: 9.1194e-01\n",
      "Epoch 48, 102% \t loss: 2.3985e-01 - acc: 9.1915e-01 - took 0.44s\n",
      "validation \t val_loss: 2.8571e-01 - val_acc: 9.1028e-01\n",
      "Epoch 49, 102% \t loss: 2.2252e-01 - acc: 9.2085e-01 - took 0.44s\n",
      "validation \t val_loss: 2.8914e-01 - val_acc: 9.1626e-01\n",
      "Epoch 50, 102% \t loss: 1.7444e-01 - acc: 9.1779e-01 - took 0.44s\n",
      "validation \t val_loss: 3.1198e-01 - val_acc: 9.0870e-01\n",
      "Epoch 51, 102% \t loss: 2.5236e-01 - acc: 9.1494e-01 - took 0.44s\n",
      "validation \t val_loss: 2.8580e-01 - val_acc: 9.1421e-01\n",
      "Epoch 52, 102% \t loss: 2.4151e-01 - acc: 9.1661e-01 - took 0.45s\n",
      "validation \t val_loss: 2.8307e-01 - val_acc: 9.2175e-01\n",
      "Epoch 53, 102% \t loss: 9.4998e-02 - acc: 9.1749e-01 - took 0.44s\n",
      "validation \t val_loss: 2.9591e-01 - val_acc: 9.0874e-01\n",
      "Epoch 54, 102% \t loss: 2.1791e-01 - acc: 9.2010e-01 - took 0.44s\n",
      "validation \t val_loss: 3.0544e-01 - val_acc: 9.1106e-01\n",
      "Epoch 55, 102% \t loss: 2.6949e-01 - acc: 9.1812e-01 - took 0.44s\n",
      "validation \t val_loss: 2.9930e-01 - val_acc: 9.1770e-01\n",
      "Epoch 56, 102% \t loss: 2.0430e-01 - acc: 9.1890e-01 - took 0.44s\n",
      "validation \t val_loss: 3.8273e-01 - val_acc: 9.1067e-01\n",
      "Epoch 57, 102% \t loss: 2.3163e-01 - acc: 9.1741e-01 - took 0.44s\n",
      "validation \t val_loss: 2.7470e-01 - val_acc: 9.2344e-01\n",
      "Epoch 58, 102% \t loss: 1.2828e-01 - acc: 9.2386e-01 - took 0.44s\n",
      "validation \t val_loss: 3.1239e-01 - val_acc: 9.1743e-01\n",
      "Epoch 59, 102% \t loss: 1.5382e-01 - acc: 9.2136e-01 - took 0.44s\n",
      "validation \t val_loss: 3.7083e-01 - val_acc: 9.2044e-01\n",
      "Epoch 60, 102% \t loss: 2.0442e-01 - acc: 9.1827e-01 - took 0.44s\n",
      "validation \t val_loss: 3.1682e-01 - val_acc: 9.2278e-01\n",
      "Epoch 61, 102% \t loss: 1.5890e-01 - acc: 9.1724e-01 - took 0.44s\n",
      "validation \t val_loss: 2.8440e-01 - val_acc: 9.1926e-01\n",
      "Epoch 62, 102% \t loss: 1.4842e-01 - acc: 9.2511e-01 - took 0.44s\n",
      "validation \t val_loss: 2.7899e-01 - val_acc: 9.2198e-01\n",
      "Epoch 63, 102% \t loss: 2.6652e-01 - acc: 9.2084e-01 - took 0.45s\n",
      "validation \t val_loss: 2.5635e-01 - val_acc: 9.1694e-01\n",
      "Epoch 64, 102% \t loss: 2.6358e-01 - acc: 9.2053e-01 - took 0.44s\n",
      "validation \t val_loss: 3.0339e-01 - val_acc: 9.1511e-01\n",
      "Epoch 65, 102% \t loss: 1.8214e-01 - acc: 9.2310e-01 - took 0.44s\n",
      "validation \t val_loss: 2.6557e-01 - val_acc: 9.2356e-01\n",
      "Epoch 66, 102% \t loss: 1.8980e-01 - acc: 9.1903e-01 - took 0.44s\n",
      "validation \t val_loss: 2.4999e-01 - val_acc: 9.1618e-01\n",
      "Epoch 67, 102% \t loss: 2.0035e-01 - acc: 9.1840e-01 - took 0.44s\n",
      "validation \t val_loss: 2.9983e-01 - val_acc: 9.1994e-01\n",
      "Epoch 68, 102% \t loss: 1.1143e-01 - acc: 9.2962e-01 - took 0.45s\n",
      "validation \t val_loss: 3.4569e-01 - val_acc: 9.1883e-01\n",
      "Epoch 69, 102% \t loss: 2.0107e-01 - acc: 9.2644e-01 - took 0.44s\n",
      "validation \t val_loss: 3.2232e-01 - val_acc: 9.2290e-01\n",
      "Epoch 70, 102% \t loss: 3.3902e-01 - acc: 9.2293e-01 - took 0.44s\n",
      "validation \t val_loss: 2.6182e-01 - val_acc: 9.2109e-01\n",
      "Epoch 71, 102% \t loss: 2.1684e-01 - acc: 9.2808e-01 - took 0.44s\n",
      "validation \t val_loss: 2.7797e-01 - val_acc: 9.2434e-01\n",
      "Epoch 72, 102% \t loss: 2.7870e-01 - acc: 9.2603e-01 - took 0.44s\n",
      "validation \t val_loss: 2.7195e-01 - val_acc: 9.2681e-01\n",
      "Epoch 73, 102% \t loss: 2.8487e-01 - acc: 9.2736e-01 - took 0.44s\n",
      "validation \t val_loss: 2.7251e-01 - val_acc: 9.2344e-01\n",
      "Epoch 74, 102% \t loss: 1.7122e-01 - acc: 9.2917e-01 - took 0.44s\n",
      "validation \t val_loss: 2.3262e-01 - val_acc: 9.3310e-01\n",
      "Epoch 75, 102% \t loss: 1.6603e-01 - acc: 9.2768e-01 - took 0.44s\n",
      "validation \t val_loss: 2.5329e-01 - val_acc: 9.2644e-01\n",
      "Epoch 76, 102% \t loss: 1.5885e-01 - acc: 9.2390e-01 - took 0.44s\n",
      "validation \t val_loss: 2.6245e-01 - val_acc: 9.1889e-01\n",
      "Epoch 77, 102% \t loss: 1.9360e-01 - acc: 9.3045e-01 - took 0.45s\n",
      "validation \t val_loss: 3.4822e-01 - val_acc: 9.2391e-01\n",
      "Epoch 78, 102% \t loss: 2.6874e-01 - acc: 9.2920e-01 - took 0.44s\n",
      "validation \t val_loss: 2.3384e-01 - val_acc: 9.2397e-01\n",
      "Epoch 79, 102% \t loss: 1.8056e-01 - acc: 9.3127e-01 - took 0.44s\n",
      "validation \t val_loss: 3.0109e-01 - val_acc: 9.3008e-01\n",
      "Epoch 80, 102% \t loss: 2.5004e-01 - acc: 9.2825e-01 - took 0.44s\n",
      "validation \t val_loss: 6.2369e-01 - val_acc: 9.2418e-01\n",
      "Epoch 81, 102% \t loss: 2.6558e-01 - acc: 9.2509e-01 - took 0.44s\n",
      "validation \t val_loss: 2.8655e-01 - val_acc: 9.2578e-01\n",
      "Epoch 82, 102% \t loss: 1.8101e-01 - acc: 9.2613e-01 - took 0.44s\n",
      "validation \t val_loss: 3.0399e-01 - val_acc: 9.3530e-01\n",
      "Epoch 83, 102% \t loss: 2.2846e-01 - acc: 9.3135e-01 - took 0.44s\n",
      "validation \t val_loss: 2.7263e-01 - val_acc: 9.2058e-01\n",
      "Epoch 84, 102% \t loss: 1.6595e-01 - acc: 9.3314e-01 - took 0.45s\n",
      "validation \t val_loss: 2.7687e-01 - val_acc: 9.2512e-01\n",
      "Epoch 85, 102% \t loss: 1.0664e-01 - acc: 9.3226e-01 - took 0.45s\n",
      "validation \t val_loss: 2.8685e-01 - val_acc: 9.2708e-01\n",
      "Epoch 86, 102% \t loss: 2.8253e-01 - acc: 9.3129e-01 - took 0.44s\n",
      "validation \t val_loss: 2.7617e-01 - val_acc: 9.2514e-01\n",
      "Epoch 87, 102% \t loss: 1.9639e-01 - acc: 9.2913e-01 - took 0.44s\n",
      "validation \t val_loss: 2.6175e-01 - val_acc: 9.2173e-01\n",
      "Epoch 88, 102% \t loss: 1.1621e-01 - acc: 9.2953e-01 - took 0.44s\n",
      "validation \t val_loss: 3.1616e-01 - val_acc: 9.2486e-01\n",
      "Epoch 89, 102% \t loss: 2.0517e-01 - acc: 9.2889e-01 - took 0.44s\n",
      "validation \t val_loss: 2.4667e-01 - val_acc: 9.2983e-01\n",
      "Epoch 90, 102% \t loss: 1.4902e-01 - acc: 9.3052e-01 - took 0.44s\n",
      "validation \t val_loss: 3.5167e-01 - val_acc: 9.2642e-01\n",
      "Epoch 91, 102% \t loss: 1.3489e-01 - acc: 9.2993e-01 - took 0.45s\n",
      "validation \t val_loss: 2.9424e-01 - val_acc: 9.2773e-01\n",
      "Epoch 92, 102% \t loss: 1.8609e-01 - acc: 9.3350e-01 - took 0.44s\n",
      "validation \t val_loss: 2.8746e-01 - val_acc: 9.3464e-01\n",
      "Epoch 93, 102% \t loss: 1.9646e-01 - acc: 9.3131e-01 - took 0.44s\n",
      "validation \t val_loss: 2.3516e-01 - val_acc: 9.3100e-01\n",
      "Epoch 94, 102% \t loss: 3.9475e-01 - acc: 9.3333e-01 - took 0.44s\n",
      "validation \t val_loss: 2.2533e-01 - val_acc: 9.3088e-01\n",
      "Epoch 95, 102% \t loss: 1.0213e-01 - acc: 9.3155e-01 - took 0.44s\n",
      "validation \t val_loss: 2.7210e-01 - val_acc: 9.2891e-01\n",
      "Epoch 96, 102% \t loss: 1.7683e-01 - acc: 9.3295e-01 - took 0.47s\n",
      "validation \t val_loss: 2.4969e-01 - val_acc: 9.2356e-01\n",
      "Epoch 97, 102% \t loss: 1.6209e-01 - acc: 9.3068e-01 - took 0.45s\n",
      "validation \t val_loss: 2.8436e-01 - val_acc: 9.2837e-01\n",
      "Epoch 98, 102% \t loss: 2.9023e-01 - acc: 9.3278e-01 - took 0.44s\n",
      "validation \t val_loss: 2.9779e-01 - val_acc: 9.2876e-01\n",
      "Epoch 99, 102% \t loss: 2.0615e-01 - acc: 9.3519e-01 - took 0.44s\n",
      "validation \t val_loss: 2.6107e-01 - val_acc: 9.3074e-01\n",
      "Epoch 100, 102% \t loss: 1.9260e-01 - acc: 9.3325e-01 - took 0.44s\n",
      "validation \t val_loss: 3.1122e-01 - val_acc: 9.3631e-01\r"
     ]
    }
   ],
   "source": [
    "for e in range(nb_epochs):\n",
    "    train(e)\n",
    "    val(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ♫♪.ılılıll|̲̅̅●̲̅̅|̲̅̅=̲̅̅|̲̅̅●̲̅̅|llılılı.♫♪"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
