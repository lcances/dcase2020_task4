{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% Import\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# dataset manager\n",
    "from dcase2020.datasetManager import DESEDManager\n",
    "from dcase2020.datasets import DESEDDataset\n",
    "\n",
    "# utility function & metrics & augmentation\n",
    "import dcase2020.augmentation_utils.signal_augmentations as signal_augmentations\n",
    "import dcase2020.augmentation_utils.spec_augmentations as spec_augmentations\n",
    "import dcase2020.augmentation_utils.signal_augmentations as signal_augmentations\n",
    "from dcase2020.pytorch_metrics.metrics import FScore\n",
    "from dcase2020.util.utils import get_datetime, reset_seed\n",
    "\n",
    "# models\n",
    "from dcase2020.models import WeakBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ==== set the log ====\n",
    "import logging\n",
    "import logging.config\n",
    "from dcase2020.util.log import DEFAULT_LOGGING\n",
    "logging.config.dictConfig(DEFAULT_LOGGING)\n",
    "log = logging.getLogger(__name__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ==== reset the seed for reproductability ====\n",
    "reset_seed(1234)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ==== load the dataset ====\n",
    "dese_metadata_root = \"../dataset/DESED/metadata\"\n",
    "desed_audio_root = \"../dataset/DESED/audio\"\n",
    "\n",
    "manager = DESEDManager(\n",
    "    dese_metadata_root, desed_audio_root,\n",
    "    sampling_rate = 22050,\n",
    "    validation_ratio=0.2,\n",
    "    verbose = 2\n",
    ")\n",
    "\n",
    "manager.add_subset(\"weak\")\n",
    "\n",
    "manager.split_train_validation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "augments = [\n",
    "    # signal_augmentation.Noise(0.5, target_snr=15),\n",
    "    # signal_augmentation.RandomTimeDropout(0.5, dropout=0.2)\n",
    "]\n",
    "\n",
    "train_dataset = DESEDDataset(manager, train=True, val=False, augments=augments, cached=True)\n",
    "val_dataset = DESEDDataset(manager, train=False, val=True, augments=[], cached=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  setup augmentation and create pytorch dataset\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = WeakBaseline()\n",
    "\n",
    "# training parameters\n",
    "nb_epochs = 100\n",
    "batch_size = 32\n",
    "nb_batch = len(train_dataset) // batch_size\n",
    "\n",
    "# criterion & optimizers\n",
    "criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "optimizers = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# callbacks\n",
    "callbacks = []\n",
    "\n",
    "# tensorboard\n",
    "title = \"WeakBaseline_%s\" % (get_datetime())\n",
    "tensorboard = SummaryWriter(log_dir=\"../tensorboard/%s\" % title, comment=\"weak baseline\")\n",
    "\n",
    "# loaders\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Metrics\n",
    "fscore_func = FScore()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Setup model and training parameters\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Training\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(epoch: int):\n",
    "    start_time = time.time()\n",
    "    fscore_func.reset()\n",
    "    model.train()\n",
    "    print(\"\") # <-- Force new line\n",
    "    \n",
    "    for i, (X, y) in enumerate(training_loader):\n",
    "        X, y = X.cuda().float(), y.cuda().long()\n",
    "        \n",
    "        logits = model(X)\n",
    "        \n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        # calc metrics\n",
    "        _, pred = torch.max(logits, 1)\n",
    "        f1 = fscore_func(pred, y)\n",
    "        \n",
    "        # back propagation\n",
    "        optimizers.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizers.step()\n",
    "        \n",
    "        # logs\n",
    "        print(\"Epoch {}, {:d}% \\t loss: {:.4e} - f1: {:.4e} - took {:.2f}s\".format(\n",
    "            epoch + 1,\n",
    "            int(100 * (i + 1) / nb_batch),\n",
    "            loss.item(),\n",
    "            f1,\n",
    "            time.time() - start_time\n",
    "        ), end=\"\\r\")\n",
    "        \n",
    "    # tensorboard logs\n",
    "    tensorboard.add_scalar(\"train/loss\", loss.item(), epoch)\n",
    "    tensorboard.add_scalar(\"train/f1\", f1, epoch)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% training function\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    fscore_func.reset()\n",
    "    model.train()\n",
    "    print(\"\") # <-- Force new line\n",
    "    \n",
    "    for i, (X, y) in enumerate(val_loader):\n",
    "        X, y = X.cuda().float(), y.cuda().long()\n",
    "        \n",
    "        logits = model(X)\n",
    "        \n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        # calc metrics\n",
    "        _, pred = torch.max(logits, 1)\n",
    "        f1 = fscore_func(pred, y)\n",
    "        \n",
    "        # back propagation\n",
    "        optimizers.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizers.step()\n",
    "        \n",
    "        # logs\n",
    "        print(\"validation \\t val_loss: {:.4e} - val_f1: {:.4e}\".format(\n",
    "            loss.item(),\n",
    "            f1,\n",
    "        ), end=\"\\r\")\n",
    "        \n",
    "    # tensorboard logs\n",
    "    tensorboard.add_scalar(\"val/loss\", loss.item(), epoch)\n",
    "    tensorboard.add_scalar(\"val/f1\", f1, epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% validation function\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for e in range(nb_epochs):\n",
    "    train()\n",
    "    val()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}