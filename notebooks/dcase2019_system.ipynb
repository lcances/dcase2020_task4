{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%% Import\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# dataset manager\n",
    "from dcase2020.datasetManager import DESEDManager\n",
    "from dcase2020.datasets import DESEDDataset\n",
    "\n",
    "# utility function & metrics & augmentation\n",
    "from metric_utils.metrics import FScore, BinaryAccuracy\n",
    "from dcase2020_task4.util.utils import get_datetime, reset_seed\n",
    "from dcase2020_task4.util.checkpoint import CheckPoint\n",
    "\n",
    "# models\n",
    "from dcase2020_task4.dcase2019.models import dcase2019_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ==== set the log ====\n",
    "import logging\n",
    "import logging.config\n",
    "from dcase2020.util.log import DEFAULT_LOGGING\n",
    "logging.config.dictConfig(DEFAULT_LOGGING)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ==== reset the seed for reproductability ====\n",
    "reset_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mDEBUG --- datasetManager.__init__ >>> ../dataset/DESED/dataset/audio/dcase2020_dataset_22050.hdf5\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._load_metadata >>> Reading metadata: ../dataset/DESED/dataset/metadata/train/weak.tsv\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._load_metadata >>> Reading metadata: ../dataset/DESED/dataset/metadata/train/unlabel_in_domain.tsv\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._load_metadata >>> Reading metadata: ../dataset/DESED/dataset/metadata/train/synthetic20.tsv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ==== load the dataset ====\n",
    "desed_metadata_root = \"../dataset/DESED/dataset/metadata\"\n",
    "desed_audio_root = \"../dataset/DESED/dataset/audio\"\n",
    "# desed_metadata_root = os.path.join(\"e:/\", \"Corpus\", \"dcase2020\", \"DESED\", \"dataset\", \"metadata\")\n",
    "# desed_audio_root = os.path.join(\"e:/\", \"Corpus\", \"dcase2020\", \"DESED\", \"dataset\", \"audio\")\n",
    "\n",
    "manager = DESEDManager(\n",
    "    desed_metadata_root, desed_audio_root,\n",
    "    sampling_rate = 22050,\n",
    "    from_disk=False,\n",
    "    nb_vector_bin=431, # there is no temporal reduction in this model\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add weak ans synthetic20 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37mINFO --- datasetManager._add_train_metadata >>> Loading metadata for: weak\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._add_train_subset >>> Loading dataset: train, subset: weak\u001b[0m\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> hdf_file: <HDF5 file \"dcase2020_dataset_22050.hdf5\" (mode r)>\u001b[0m\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> path: DESED/dataset/audio/train/weak\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._add_train_metadata >>> Loading metadata for: synthetic20\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/7582 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 52/7582 [00:00<00:14, 513.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 100/7582 [00:00<00:14, 502.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 152/7582 [00:00<00:14, 506.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 202/7582 [00:00<00:14, 500.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 248/7582 [00:00<00:15, 484.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 301/7582 [00:00<00:14, 496.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 354/7582 [00:00<00:14, 504.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 401/7582 [00:00<00:14, 492.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 448/7582 [00:00<00:15, 474.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 494/7582 [00:01<00:15, 462.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 543/7582 [00:01<00:14, 469.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 594/7582 [00:01<00:14, 479.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 642/7582 [00:01<00:14, 477.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 690/7582 [00:01<00:14, 474.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 738/7582 [00:01<00:14, 467.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 796/7582 [00:01<00:13, 494.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 846/7582 [00:01<00:13, 488.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 896/7582 [00:01<00:13, 485.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 945/7582 [00:01<00:13, 482.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 1000/7582 [00:02<00:13, 499.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 1065/7582 [00:02<00:12, 534.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 1121/7582 [00:02<00:11, 540.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 1177/7582 [00:02<00:11, 543.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 1232/7582 [00:02<00:11, 531.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 1286/7582 [00:02<00:12, 519.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 1347/7582 [00:02<00:11, 539.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 1405/7582 [00:02<00:11, 548.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 1461/7582 [00:02<00:11, 528.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 1515/7582 [00:02<00:11, 521.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 1568/7582 [00:03<00:11, 522.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 1621/7582 [00:03<00:11, 516.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 1673/7582 [00:03<00:11, 513.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 1725/7582 [00:03<00:11, 499.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 1777/7582 [00:03<00:11, 502.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 1832/7582 [00:03<00:11, 513.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 1885/7582 [00:03<00:11, 516.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1937/7582 [00:03<00:11, 501.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1988/7582 [00:03<00:11, 490.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 2038/7582 [00:04<00:11, 463.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 2087/7582 [00:04<00:11, 468.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 2151/7582 [00:04<00:10, 509.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 2209/7582 [00:04<00:10, 526.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 2267/7582 [00:04<00:09, 539.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 2324/7582 [00:04<00:09, 544.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 2380/7582 [00:04<00:09, 536.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 2443/7582 [00:04<00:09, 561.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 2500/7582 [00:04<00:09, 538.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 2555/7582 [00:05<00:09, 523.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 2608/7582 [00:05<00:09, 515.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 2668/7582 [00:05<00:09, 533.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 2724/7582 [00:05<00:08, 540.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 2779/7582 [00:05<00:09, 527.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 2833/7582 [00:05<00:09, 526.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 2886/7582 [00:05<00:09, 520.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 2939/7582 [00:05<00:09, 515.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 2991/7582 [00:05<00:09, 497.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 3042/7582 [00:05<00:09, 488.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 3092/7582 [00:06<00:09, 489.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 3150/7582 [00:06<00:08, 513.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 3209/7582 [00:06<00:08, 533.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 3263/7582 [00:06<00:08, 508.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 3319/7582 [00:06<00:08, 522.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 3372/7582 [00:06<00:08, 517.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 3425/7582 [00:06<00:08, 503.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 3480/7582 [00:06<00:07, 515.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 3539/7582 [00:06<00:07, 534.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 3593/7582 [00:07<00:07, 527.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 3648/7582 [00:07<00:07, 531.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 3707/7582 [00:07<00:07, 546.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 3765/7582 [00:07<00:06, 555.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 3821/7582 [00:07<00:06, 555.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 3877/7582 [00:07<00:06, 533.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 3931/7582 [00:07<00:07, 519.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 3984/7582 [00:07<00:07, 511.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 4036/7582 [00:07<00:07, 499.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 4087/7582 [00:07<00:07, 495.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 4137/7582 [00:08<00:06, 495.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 4195/7582 [00:08<00:06, 516.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 4264/7582 [00:08<00:05, 556.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 4321/7582 [00:08<00:05, 554.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 4378/7582 [00:08<00:05, 546.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 4434/7582 [00:08<00:05, 538.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 4490/7582 [00:08<00:05, 543.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 4548/7582 [00:08<00:05, 552.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 4610/7582 [00:08<00:05, 569.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 4668/7582 [00:08<00:05, 545.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 4724/7582 [00:09<00:05, 512.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 4782/7582 [00:09<00:05, 530.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 4838/7582 [00:09<00:05, 536.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 4893/7582 [00:09<00:05, 537.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 4948/7582 [00:09<00:04, 539.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 5003/7582 [00:09<00:05, 511.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 5055/7582 [00:09<00:05, 502.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 5106/7582 [00:09<00:05, 462.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 5156/7582 [00:09<00:05, 471.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 5204/7582 [00:10<00:05, 473.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 5267/7582 [00:10<00:04, 511.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 5328/7582 [00:10<00:04, 535.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 5389/7582 [00:10<00:03, 553.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 5446/7582 [00:10<00:03, 544.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 5506/7582 [00:10<00:03, 560.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 5568/7582 [00:10<00:03, 576.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 5627/7582 [00:10<00:03, 562.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 5684/7582 [00:10<00:03, 550.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 5745/7582 [00:11<00:03, 564.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 5802/7582 [00:11<00:03, 553.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 5859/7582 [00:11<00:03, 556.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 5915/7582 [00:11<00:02, 557.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 5971/7582 [00:11<00:02, 549.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 6027/7582 [00:11<00:02, 545.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 6082/7582 [00:11<00:02, 517.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 6135/7582 [00:11<00:02, 499.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 6195/7582 [00:11<00:02, 525.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 6256/7582 [00:11<00:02, 547.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 6312/7582 [00:12<00:02, 543.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 6367/7582 [00:12<00:02, 545.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 6424/7582 [00:12<00:02, 550.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 6480/7582 [00:12<00:02, 537.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 6534/7582 [00:12<00:01, 530.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 6598/7582 [00:12<00:01, 557.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 6655/7582 [00:12<00:01, 537.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 6710/7582 [00:12<00:01, 521.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 6770/7582 [00:12<00:01, 540.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 6830/7582 [00:13<00:01, 555.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 6887/7582 [00:13<00:01, 543.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 6942/7582 [00:13<00:01, 537.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 6997/7582 [00:13<00:01, 537.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 7051/7582 [00:13<00:00, 537.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 7107/7582 [00:13<00:00, 543.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 7163/7582 [00:13<00:00, 547.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 7218/7582 [00:13<00:00, 535.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 7272/7582 [00:13<00:00, 519.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 7325/7582 [00:13<00:00, 511.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 7377/7582 [00:14<00:00, 509.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 7430/7582 [00:14<00:00, 514.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 7483/7582 [00:14<00:00, 518.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 7582/7582 [00:14<00:00, 524.94it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37mINFO --- datasetManager._add_train_subset >>> Loading dataset: train, subset: synthetic20\u001b[0m\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> hdf_file: <HDF5 file \"dcase2020_dataset_22050.hdf5\" (mode r)>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> path: DESED/dataset/audio/train/synthetic20\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4251 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 61/4251 [00:00<00:06, 602.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 115/4251 [00:00<00:07, 553.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 163/4251 [00:00<00:07, 528.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 224/4251 [00:00<00:07, 549.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 279/4251 [00:00<00:07, 548.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 325/4251 [00:00<00:08, 487.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 384/4251 [00:00<00:07, 513.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 440/4251 [00:00<00:07, 524.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 497/4251 [00:00<00:06, 536.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 550/4251 [00:01<00:07, 523.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 602/4251 [00:01<00:07, 517.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 654/4251 [00:01<00:08, 431.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 700/4251 [00:01<00:08, 430.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 759/4251 [00:01<00:07, 468.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 813/4251 [00:01<00:07, 485.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 864/4251 [00:01<00:06, 483.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 914/4251 [00:01<00:07, 473.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 967/4251 [00:01<00:06, 488.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 1025/4251 [00:02<00:06, 510.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1077/4251 [00:02<00:06, 498.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1128/4251 [00:02<00:06, 496.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1179/4251 [00:02<00:06, 471.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1228/4251 [00:02<00:06, 474.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1281/4251 [00:02<00:06, 489.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 1335/4251 [00:02<00:05, 503.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1393/4251 [00:02<00:05, 521.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 1446/4251 [00:02<00:05, 513.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1500/4251 [00:02<00:05, 520.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1553/4251 [00:03<00:05, 509.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1609/4251 [00:03<00:05, 523.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1662/4251 [00:03<00:04, 518.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1722/4251 [00:03<00:04, 538.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1777/4251 [00:03<00:04, 509.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1834/4251 [00:03<00:04, 524.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1892/4251 [00:03<00:04, 537.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1947/4251 [00:03<00:04, 518.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 2003/4251 [00:03<00:04, 530.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 2057/4251 [00:04<00:04, 479.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 2118/4251 [00:04<00:04, 510.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2171/4251 [00:04<00:04, 500.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2225/4251 [00:04<00:03, 510.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 2281/4251 [00:04<00:03, 523.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 2335/4251 [00:04<00:03, 519.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2390/4251 [00:04<00:03, 527.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2444/4251 [00:04<00:03, 520.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 2497/4251 [00:04<00:03, 522.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 2550/4251 [00:05<00:03, 485.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 2600/4251 [00:05<00:03, 471.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 2648/4251 [00:05<00:03, 472.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 2696/4251 [00:05<00:03, 460.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 2744/4251 [00:05<00:03, 464.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 2791/4251 [00:05<00:03, 444.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 2836/4251 [00:05<00:03, 423.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 2879/4251 [00:05<00:03, 421.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 2922/4251 [00:05<00:03, 422.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 2969/4251 [00:06<00:02, 433.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 3013/4251 [00:06<00:02, 423.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 3056/4251 [00:06<00:02, 421.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 3101/4251 [00:06<00:02, 428.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 3144/4251 [00:06<00:02, 422.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 3195/4251 [00:06<00:02, 445.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 3247/4251 [00:06<00:02, 464.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 3296/4251 [00:06<00:02, 471.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 3344/4251 [00:06<00:02, 448.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 3390/4251 [00:06<00:02, 426.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 3442/4251 [00:07<00:01, 450.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 3489/4251 [00:07<00:01, 455.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 3538/4251 [00:07<00:01, 463.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 3585/4251 [00:07<00:01, 458.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 3640/4251 [00:07<00:01, 482.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 3695/4251 [00:07<00:01, 499.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 3746/4251 [00:07<00:01, 476.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 3795/4251 [00:07<00:00, 469.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 3844/4251 [00:07<00:00, 473.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 3892/4251 [00:08<00:00, 474.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 3944/4251 [00:08<00:00, 484.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 4002/4251 [00:08<00:00, 508.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 4061/4251 [00:08<00:00, 527.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 4115/4251 [00:08<00:00, 490.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 4165/4251 [00:08<00:00, 473.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 4251/4251 [00:08<00:00, 486.03it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37mINFO --- datasetManager._add_val_subset >>> Loading dataset: validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> hdf_file: <HDF5 file \"dcase2020_dataset_22050.hdf5\" (mode r)>\u001b[0m\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> path: DESED/dataset/audio/validation\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "manager.add_subset(\"weak\")\n",
    "manager.add_subset(\"synthetic20\")\n",
    "manager.add_subset(\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep dataset\n",
    "\n",
    "- We want both the weak and strong ground truth --> the *weak* and *strong* parameters to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "augments = [\n",
    "    # signal_augmentation.Noise(0.5, target_snr=15),\n",
    "    # signal_augmentation.RandomTimeDropout(0.5, dropout=0.2)\n",
    "]\n",
    "\n",
    "train_dataset = DESEDDataset(manager, train=True, val=False, weak=True, strong=True, augments=augments, cached=True)\n",
    "val_dataset = DESEDDataset(manager, train=False, val=True, weak=True, strong=True, augments=[], cached=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4049, 1058)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.filenames), len(val_dataset.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model\n",
    "\n",
    "This model is the same than the weak baseline but have an extra output. <br />\n",
    "the loc_output is compose of a single convolution layer with nb_filters == nb_class. <br />\n",
    "Since their is some pooling layer, the *loc_ouput* have a precision of 53 bins (~= 18 ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Setup model and training parameters\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dcase2019_model(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLUPool(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout2d(p=0.0, inplace=False)\n",
       "      (3): ReLU6(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): ConvBNReLUPool(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout2d(p=0.0, inplace=False)\n",
       "      (3): ReLU6(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): ConvBNReLUPool(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout2d(p=0.0, inplace=False)\n",
       "      (3): ReLU6(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (bi_gru): GRU(64, 64, batch_first=True, bidirectional=True)\n",
       "  (strong_classifier): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       "  (g_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (g_max_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "  (weak_classifier): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "model = dcase2019_model()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n",
      "                                 Kernel Shape      Output Shape   Params  \\\n",
      "Layer                                                                      \n",
      "0_features.0.Conv2d_0           [1, 64, 3, 3]  [2, 64, 64, 431]    640.0   \n",
      "1_features.0.BatchNorm2d_1               [64]  [2, 64, 64, 431]    128.0   \n",
      "2_features.0.Dropout2d_2                    -  [2, 64, 64, 431]        -   \n",
      "3_features.0.ReLU6_3                        -  [2, 64, 64, 431]        -   \n",
      "4_features.0.MaxPool2d_4                    -  [2, 64, 16, 431]        -   \n",
      "5_features.1.Conv2d_0          [64, 64, 3, 3]  [2, 64, 16, 431]  36.928k   \n",
      "6_features.1.BatchNorm2d_1               [64]  [2, 64, 16, 431]    128.0   \n",
      "7_features.1.Dropout2d_2                    -  [2, 64, 16, 431]        -   \n",
      "8_features.1.ReLU6_3                        -  [2, 64, 16, 431]        -   \n",
      "9_features.1.MaxPool2d_4                    -   [2, 64, 4, 431]        -   \n",
      "10_features.2.Conv2d_0         [64, 64, 3, 3]   [2, 64, 4, 431]  36.928k   \n",
      "11_features.2.BatchNorm2d_1              [64]   [2, 64, 4, 431]    128.0   \n",
      "12_features.2.Dropout2d_2                   -   [2, 64, 4, 431]        -   \n",
      "13_features.2.ReLU6_3                       -   [2, 64, 4, 431]        -   \n",
      "14_features.2.MaxPool2d_4                   -   [2, 64, 1, 431]        -   \n",
      "15_bi_gru                                   -     [2, 431, 128]   49.92k   \n",
      "16_strong_classifier.Linear_0       [128, 64]      [2, 431, 64]   8.256k   \n",
      "17_strong_classifier.ReLU_1                 -      [2, 431, 64]        -   \n",
      "18_strong_classifier.Linear_2        [64, 10]      [2, 431, 10]    650.0   \n",
      "19_g_avg_pool                               -        [2, 10, 1]        -   \n",
      "20_g_max_pool                               -        [2, 10, 1]        -   \n",
      "21_weak_classifier.Linear_0        [20, 1024]         [2, 1024]  21.504k   \n",
      "22_weak_classifier.ReLU_1                   -         [2, 1024]        -   \n",
      "23_weak_classifier.Linear_2        [1024, 10]           [2, 10]   10.25k   \n",
      "\n",
      "                                 Mult-Adds  \n",
      "Layer                                       \n",
      "0_features.0.Conv2d_0           15.888384M  \n",
      "1_features.0.BatchNorm2d_1            64.0  \n",
      "2_features.0.Dropout2d_2                 -  \n",
      "3_features.0.ReLU6_3                     -  \n",
      "4_features.0.MaxPool2d_4                 -  \n",
      "5_features.1.Conv2d_0          254.214144M  \n",
      "6_features.1.BatchNorm2d_1            64.0  \n",
      "7_features.1.Dropout2d_2                 -  \n",
      "8_features.1.ReLU6_3                     -  \n",
      "9_features.1.MaxPool2d_4                 -  \n",
      "10_features.2.Conv2d_0          63.553536M  \n",
      "11_features.2.BatchNorm2d_1           64.0  \n",
      "12_features.2.Dropout2d_2                -  \n",
      "13_features.2.ReLU6_3                    -  \n",
      "14_features.2.MaxPool2d_4                -  \n",
      "15_bi_gru                          49.152k  \n",
      "16_strong_classifier.Linear_0       8.192k  \n",
      "17_strong_classifier.ReLU_1              -  \n",
      "18_strong_classifier.Linear_2        640.0  \n",
      "19_g_avg_pool                            -  \n",
      "20_g_max_pool                            -  \n",
      "21_weak_classifier.Linear_0         20.48k  \n",
      "22_weak_classifier.ReLU_1                -  \n",
      "23_weak_classifier.Linear_2         10.24k  \n",
      "-------------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params             165.46k\n",
      "Trainable params         165.46k\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             333.74496M\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "input_tensor = torch.zeros((2, 64, 431), dtype=torch.float)\n",
    "input_tensor = input_tensor.cuda()\n",
    "\n",
    "s = summary(model, input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom loss function\n",
    "\n",
    "Since not all file have strong truth, it is necessary to remove those files. <br />\n",
    "For that, the strong mask is computed. If the sum of the strong ground truth is equal to 0 then it is a fake one <br />\n",
    "This file strong loss must not be taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weak_synth_loss(logits_weak, logits_strong, y_weak, y_strong, reduce: str = \"mean\"):\n",
    "    assert reduce in [\"mean\", \"sum\"], \"support only \\\"mean\\\" and \\\"sum\\\"\"\n",
    "    \n",
    "    #  Reduction function\n",
    "    if reduce == \"mean\":\n",
    "        reduce_fn = torch.mean\n",
    "    elif reduce == \"sum\":\n",
    "        reduce_fn = torch.sum\n",
    "    \n",
    "    # based on Binary Cross Entropy loss\n",
    "    weak_criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    strong_criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    \n",
    "    # calc separate loss function\n",
    "    weak_bce = weak_criterion(logits_weak, y_weak)\n",
    "    strong_bce = strong_criterion(logits_strong, y_strong)\n",
    "    \n",
    "    weak_bce = reduce_fn(weak_bce, dim=1)\n",
    "    strong_bce = reduce_fn(strong_bce, dim=(1, 2))\n",
    "    \n",
    "    # calc strong mask\n",
    "    strong_mask = torch.clamp(torch.sum(y_strong, dim=(1, 2)), 0, 1) # vector of 0 or 1\n",
    "#     strong_mask = strong_mask.detach() # declared not to need gradients\n",
    "    \n",
    "    # Output the different loss for logging purpose\n",
    "    weak_loss = reduce_fn(weak_bce)\n",
    "    strong_loss = reduce_fn(strong_mask * strong_bce)\n",
    "    total_loss = reduce_fn(weak_bce + strong_mask * strong_bce)\n",
    "    \n",
    "    return weak_loss, strong_loss, total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters (crit & callbacks & loaders & metrics)m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Setup model and training parameters\n"
    }
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "nb_epochs = 100\n",
    "batch_size = 32\n",
    "nb_batch = len(train_dataset) // batch_size\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# callbacks\n",
    "checkpoint = CheckPoint(model, optimizer, mode=\"max\", name=\"../models/best_dcase2019.torch\")\n",
    "callbacks = []\n",
    "\n",
    "# tensorboard\n",
    "title = \"WeakBaseline_%s\" % (get_datetime())\n",
    "tensorboard = SummaryWriter(log_dir=Path(\"../tensorboard/%s\" % title), comment=\"weak baseline\")\n",
    "\n",
    "# loaders\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Metrics\n",
    "weak_binacc_func = BinaryAccuracy()\n",
    "strong_binacc_func = BinaryAccuracy()\n",
    "weak_f_func = FScore()\n",
    "strong_f_func = FScore()\n",
    "metrics = [weak_binacc_func, strong_binacc_func, weak_f_func, strong_f_func]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_all_metrics(metrics):\n",
    "    for m in metrics:\n",
    "        m.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Epoch  - %      - Losses:  Weak  | Strong  | Total  - metrics:  Weak acc  | Strong acc  | Weak F1  | Strong F1  - Time  \n"
     ]
    }
   ],
   "source": [
    "UNDERLINE_SEQ = \"\\033[1;4m\"\n",
    "RESET_SEQ = \"\\033[0m\"\n",
    "\n",
    "header_form = \"{:<8.8} {:<6.6} - {:<6.6} - {:<8.8} {:<6.6}| {:<8.8}| {:<6.6} - {:<9.9} {:<10.10}| {:<12.12}| {:<9.9}| {:<11.11}- {:<6.6}\"\n",
    "\n",
    "value_form  = \"{:<8.8} {:<6} - {:<6} - {:<8.8} {:<6.4f}| {:<8.4f}| {:<6.4f} - {:<9.9} {:<10.4f}| {:<12.4f}| {:<9.4f}| {:<11.4f}- {:<6.4f}\"\n",
    "\n",
    "train_form = value_form\n",
    "val_form = UNDERLINE_SEQ + value_form + RESET_SEQ\n",
    "\n",
    "header = header_form.format(\n",
    "    \"\", \"Epoch\", \"%\", \"Losses:\", \"Weak \", \"Strong \", \"Total \", \"metrics: \", \"Weak acc \", \"Strong acc \", \"Weak F1 \", \"Strong F1\", \"Time\"\n",
    ")\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% training function\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch: int):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    reset_all_metrics(metrics)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"\") # <-- Force new line\n",
    "    \n",
    "    for i, (X, y) in enumerate(training_loader):\n",
    "        # The DESEDDataset return a list of ground truth depending on the selecting option.\n",
    "        # If weak and strong ground truth are selected, the list order is [WEAK, STRONG]\n",
    "        # here there is only one [WEAK]\n",
    "        X = X.cuda().float()\n",
    "        y_weak = y[0].cuda().float()\n",
    "        y_strong = y[1].cuda().float()\n",
    "        \n",
    "        weak_logits, strong_logits = model(X)\n",
    "        \n",
    "        # calc the loss\n",
    "        weak_loss, strong_loss, total_loss = weak_synth_loss(\n",
    "            weak_logits, strong_logits,\n",
    "            y_weak, y_strong,\n",
    "            reduce=\"mean\"\n",
    "        )\n",
    "        \n",
    "        # back propagation\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            # calc metrics\n",
    "            weak_pred = torch.sigmoid(weak_logits)\n",
    "            strong_pred = torch.sigmoid(strong_logits)\n",
    "\n",
    "            # tagging\n",
    "            weak_binacc = weak_binacc_func(weak_pred, y_weak)\n",
    "            weak_fscore = weak_f_func(weak_pred, y_weak)\n",
    "\n",
    "            # loc\n",
    "            strong_binacc = strong_binacc_func(strong_pred, y_strong)\n",
    "            strong_fscore = strong_f_func(strong_pred, y_strong)\n",
    "        \n",
    "            # logs\n",
    "            print(train_form.format(\n",
    "                \"Training: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / len(training_loader)),\n",
    "                \"\", weak_loss.item(), strong_loss.item(), total_loss.item(),\n",
    "                \"\", weak_binacc, strong_binacc, weak_fscore, strong_fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "        # tensorboard logs\n",
    "        tensorboard.add_scalar(\"train/weak_loss\", weak_loss.item(), epoch)\n",
    "        tensorboard.add_scalar(\"train/strong_loss\", strong_loss.item(), epoch)\n",
    "        tensorboard.add_scalar(\"train/total_loss\", total_loss.item(), epoch)\n",
    "\n",
    "        tensorboard.add_scalar(\"train/weak_acc\", weak_binacc, epoch)\n",
    "        tensorboard.add_scalar(\"train/strong_acc\", strong_binacc, epoch)\n",
    "        tensorboard.add_scalar(\"train/weak_f1\", weak_fscore, epoch)\n",
    "        tensorboard.add_scalar(\"train/strong_f1\", strong_fscore, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% validation function\n"
    }
   },
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    start_time = time.time()\n",
    "\n",
    "        \n",
    "    reset_all_metrics(metrics)\n",
    "    \n",
    "    model.eval()\n",
    "    print(\"\") # <-- Force new line\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(val_loader):\n",
    "            X = X.cuda().float()\n",
    "            y_weak = y[0].cuda().float()\n",
    "            y_strong = y[1].cuda().float()\n",
    "\n",
    "            weak_logits, strong_logits = model(X)\n",
    "\n",
    "            # calc the loss\n",
    "            weak_loss, strong_loss, total_loss = weak_synth_loss(\n",
    "                weak_logits, strong_logits,\n",
    "                y_weak, y_strong,\n",
    "                reduce=\"mean\"\n",
    "            )\n",
    "            \n",
    "             # calc metrics\n",
    "            weak_pred = torch.sigmoid(weak_logits)\n",
    "            strong_pred = torch.sigmoid(strong_logits)\n",
    "\n",
    "            # tagging\n",
    "            weak_binacc = weak_binacc_func(weak_pred, y_weak)\n",
    "            weak_fscore = weak_f_func(weak_pred, y_weak)\n",
    "\n",
    "            # loc\n",
    "            strong_binacc = strong_binacc_func(strong_pred, y_strong)\n",
    "            strong_fscore = strong_f_func(strong_pred, y_strong)\n",
    "            \n",
    "            # The interesting metric here is the weak F1\n",
    "            checkpoint.step(weak_fscore)\n",
    "\n",
    "            # logs\n",
    "            print(val_form.format(\n",
    "                \"Validation: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / len(val_loader)),\n",
    "                \"\", weak_loss.item(), strong_loss.item(), total_loss.item(),\n",
    "                \"\", weak_binacc, strong_binacc, weak_fscore, strong_fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "        # tensorboard logs\n",
    "        tensorboard.add_scalar(\"val/weak_loss\", weak_loss.item(), epoch)\n",
    "        tensorboard.add_scalar(\"val/strong_loss\", strong_loss.item(), epoch)\n",
    "        tensorboard.add_scalar(\"val/total_loss\", total_loss.item(), epoch)\n",
    "\n",
    "        tensorboard.add_scalar(\"val/weak_acc\", weak_binacc, epoch)\n",
    "        tensorboard.add_scalar(\"val/strong_acc\", strong_binacc, epoch)\n",
    "        tensorboard.add_scalar(\"val/weak_f1\", weak_fscore, epoch)\n",
    "        tensorboard.add_scalar(\"val/strong_f1\", strong_fscore, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Epoch  - %      - Losses:  Weak  | Strong  | Total  - metrics:  Weak acc  | Strong acc  | Weak F1  | Strong F1  - Time  \n",
      "\n",
      "Training 1      - 100    -          0.3251| 0.0915  | 0.4166 -           0.8347    | 0.9555      | 0.2694   | 0.0170     - 63.7409\n",
      "\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 1      - 5      -          0.3774| 0.2619  | 0.6392 -           0.8500    | 0.9139      | 0.1587   | 0.0988     - 0.0863\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 1      - 8      -          0.3344| 0.2308  | 0.5652 -           0.8563    | 0.9178      | 0.2391   | 0.1110     - 0.1290\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 1      - 11     -          0.3948| 0.2641  | 0.6589 -           0.8531    | 0.9127      | 0.2400   | 0.0958     - 0.1704\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 1      - 14     -          0.3557| 0.2726  | 0.6283 -           0.8562    | 0.9092      | 0.2607   | 0.0946     - 0.2113\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 1      - 41     -          0.3450| 0.2807  | 0.6257 -           0.8574    | 0.9091      | 0.2810   | 0.0895     - 0.4380\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 1      - 44     -          0.3617| 0.2754  | 0.6372 -           0.8577    | 0.9084      | 0.2845   | 0.0873     - 0.4788\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 1      - 47     -          0.3805| 0.2517  | 0.6322 -           0.8580    | 0.9094      | 0.2863   | 0.0915     - 0.5177\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 1      - 100    -          0.2596| 0.2161  | 0.4757 -           0.8551    | 0.9109      | 0.2445   | 0.0930     - 0.9366\u001b[0m\n",
      "Training 2      - 100    -          0.2974| 0.0770  | 0.3744 -           0.8546    | 0.9602      | 0.3622   | 0.1671     - 7.3236\n",
      "\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 2      - 2      -          0.3388| 0.2564  | 0.5953 -           0.8656    | 0.9163      | 0.3385   | 0.1343     - 0.0385\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 2      - 5      -          0.3112| 0.2300  | 0.5412 -           0.8719    | 0.9194      | 0.4021   | 0.1288     - 0.0746\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 2      - 11     -          0.3520| 0.2169  | 0.5688 -           0.8711    | 0.9237      | 0.4437   | 0.2171     - 0.1328\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 2      - 14     -          0.3197| 0.2497  | 0.5693 -           0.8738    | 0.9203      | 0.4613   | 0.2173     - 0.1694\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 2      - 17     -          0.2875| 0.2199  | 0.5074 -           0.8760    | 0.9207      | 0.4654   | 0.2170     - 0.2052\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 2      - 23     -          0.3463| 0.2215  | 0.5679 -           0.8766    | 0.9211      | 0.4776   | 0.2280     - 0.2639\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 2      - 100    -          0.3402| 0.2455  | 0.5857 -           0.8714    | 0.9222      | 0.4531   | 0.2029     - 0.8327\u001b[0m\n",
      "Training 3      - 100    -          0.2371| 0.0723  | 0.3093 -           0.8730    | 0.9606      | 0.5028   | 0.2980     - 7.4087\n",
      "\u001b[1;4mValidati 3      - 8      -          0.2438| 0.1791  | 0.4229 -           0.8854    | 0.9275      | 0.4822   | 0.3481     - 0.0689\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 3      - 11     -          0.2941| 0.2054  | 0.4995 -           0.8859    | 0.9279      | 0.4992   | 0.3747     - 0.1068\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 3      - 14     -          0.2721| 0.2429  | 0.5149 -           0.8888    | 0.9263      | 0.5173   | 0.3868     - 0.1436\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 3      - 20     -          0.2609| 0.2064  | 0.4673 -           0.8902    | 0.9274      | 0.5206   | 0.3951     - 0.2035\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 3      - 23     -          0.3154| 0.2175  | 0.5329 -           0.8883    | 0.9273      | 0.5273   | 0.4065     - 0.2407\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 3      - 26     -          0.2494| 0.1944  | 0.4439 -           0.8910    | 0.9284      | 0.5280   | 0.4087     - 0.2791\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 3      - 29     -          0.2863| 0.1881  | 0.4744 -           0.8916    | 0.9289      | 0.5323   | 0.3992     - 0.3166\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 3      - 38     -          0.3161| 0.2266  | 0.5427 -           0.8916    | 0.9290      | 0.5348   | 0.4037     - 0.3986\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 3      - 76     -          0.2787| 0.2295  | 0.5082 -           0.8915    | 0.9269      | 0.5425   | 0.4125     - 0.7093\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 3      - 85     -          0.2690| 0.2201  | 0.4891 -           0.8926    | 0.9267      | 0.5434   | 0.4110     - 0.7948\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 3      - 100    -          0.2771| 0.2116  | 0.4887 -           0.8908    | 0.9273      | 0.5360   | 0.3793     - 0.9128\u001b[0m\n",
      "Training 4      - 100    -          0.2286| 0.0708  | 0.2994 -           0.8883    | 0.9589      | 0.5982   | 0.3506     - 7.2782\n",
      "\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 4      - 8      -          0.2307| 0.1703  | 0.4009 -           0.8969    | 0.9286      | 0.5609   | 0.3803     - 0.0843\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 4      - 11     -          0.2634| 0.1947  | 0.4581 -           0.8992    | 0.9300      | 0.5834   | 0.4115     - 0.1214\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 4      - 14     -          0.2529| 0.2208  | 0.4737 -           0.8975    | 0.9286      | 0.5898   | 0.4226     - 0.1574\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 4      - 17     -          0.2554| 0.2080  | 0.4634 -           0.8990    | 0.9282      | 0.5924   | 0.4176     - 0.1940\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 4      - 23     -          0.2857| 0.2084  | 0.4941 -           0.8957    | 0.9295      | 0.5964   | 0.4374     - 0.2528\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 4      - 26     -          0.2228| 0.1874  | 0.4102 -           0.8990    | 0.9297      | 0.6020   | 0.4358     - 0.2893\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 4      - 29     -          0.2332| 0.1695  | 0.4027 -           0.9009    | 0.9308      | 0.6085   | 0.4301     - 0.3268\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 4      - 100    -          0.3111| 0.2440  | 0.5552 -           0.8972    | 0.9300      | 0.5979   | 0.4083     - 0.8615\u001b[0m\n",
      "Training 5      - 100    -          0.2278| 0.0952  | 0.3229 -           0.9020    | 0.9579      | 0.6635   | 0.3731     - 7.3167\n",
      "\u001b[1;4mValidati 5      - 100    -          0.3252| 0.2360  | 0.5612 -           0.8882    | 0.9273      | 0.5838   | 0.3959     - 0.7277\u001b[0m\n",
      "Training 6      - 100    -          0.2465| 0.1077  | 0.3541 -           0.9115    | 0.9561      | 0.7055   | 0.3846     - 7.2709\n",
      "\u001b[1;4mValidati 6      - 100    -          0.3530| 0.2290  | 0.5820 -           0.8947    | 0.9313      | 0.5602   | 0.4165     - 0.7282\u001b[0m\n",
      "Training 7      - 100    -          0.1813| 0.0514  | 0.2327 -           0.9211    | 0.9547      | 0.7430   | 0.3968     - 7.4363\n",
      "\u001b[1;4mValidati 7      - 17     -          0.2151| 0.1890  | 0.4042 -           0.9036    | 0.9315      | 0.6107   | 0.4952     - 0.1374\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 7      - 20     -          0.2410| 0.1881  | 0.4292 -           0.9040    | 0.9314      | 0.6140   | 0.4955     - 0.1759\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 7      - 23     -          0.2831| 0.2022  | 0.4854 -           0.9031    | 0.9310      | 0.6197   | 0.4988     - 0.2128\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 7      - 26     -          0.2072| 0.1838  | 0.3910 -           0.9069    | 0.9315      | 0.6320   | 0.4994     - 0.2492\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 7      - 29     -          0.1947| 0.1608  | 0.3555 -           0.9097    | 0.9323      | 0.6435   | 0.4967     - 0.2864\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 7      - 32     -          0.2113| 0.2046  | 0.4159 -           0.9108    | 0.9328      | 0.6491   | 0.4989     - 0.3231\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 7      - 38     -          0.2577| 0.2098  | 0.4675 -           0.9120    | 0.9326      | 0.6542   | 0.4959     - 0.3824\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 7      - 100    -          0.2724| 0.2247  | 0.4972 -           0.9083    | 0.9308      | 0.6092   | 0.4610     - 0.8617\u001b[0m\n",
      "Training 8      - 100    -          0.1871| 0.0674  | 0.2544 -           0.9276    | 0.9552      | 0.7664   | 0.4112     - 7.5496\n",
      "\u001b[1;4mValidati 8      - 38     -          0.2682| 0.2271  | 0.4953 -           0.9065    | 0.9245      | 0.6604   | 0.5023     - 0.2933\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 8      - 79     -          0.2244| 0.2119  | 0.4363 -           0.9058    | 0.9224      | 0.6640   | 0.5034     - 0.6400\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 8      - 100    -          0.3521| 0.2309  | 0.5830 -           0.9038    | 0.9228      | 0.6466   | 0.4641     - 0.8042\u001b[0m\n",
      "Training 9      - 100    -          0.2112| 0.1079  | 0.3192 -           0.9325    | 0.9551      | 0.7842   | 0.4258     - 7.4437\n",
      "\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 9      - 29     -          0.1817| 0.1878  | 0.3695 -           0.9116    | 0.9187      | 0.6750   | 0.4957     - 0.2407\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 9      - 38     -          0.2916| 0.2338  | 0.5253 -           0.9118    | 0.9194      | 0.6763   | 0.4975     - 0.3216\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 9      - 50     -          0.2452| 0.2181  | 0.4633 -           0.9116    | 0.9178      | 0.6767   | 0.4950     - 0.4270\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 9      - 55     -          0.2559| 0.2419  | 0.4978 -           0.9122    | 0.9165      | 0.6820   | 0.4919     - 0.4869\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 9      - 100    -          0.3330| 0.2100  | 0.5430 -           0.9088    | 0.9183      | 0.6632   | 0.4623     - 0.8337\u001b[0m\n",
      "Training 10     - 100    -          0.1461| 0.0738  | 0.2199 -           0.9375    | 0.9546      | 0.8018   | 0.4353     - 7.4447\n",
      "\u001b[1;4mValidati 10     - 100    -          0.2923| 0.2474  | 0.5398 -           0.9060    | 0.9328      | 0.6182   | 0.4919     - 0.7711\u001b[0m\n",
      "Training 11     - 100    -          0.1070| 0.0515  | 0.1585 -           0.9408    | 0.9556      | 0.8132   | 0.4487     - 7.5633\n",
      "\u001b[1;4mValidati 11     - 100    -          0.3004| 0.2254  | 0.5259 -           0.8962    | 0.9251      | 0.6235   | 0.4588     - 0.7511\u001b[0m\n",
      "Training 12     - 100    -          0.2304| 0.0390  | 0.2695 -           0.9419    | 0.9566      | 0.8177   | 0.4566     - 7.4521\n",
      "\u001b[1;4mValidati 12     - 100    -          0.2660| 0.2021  | 0.4681 -           0.9014    | 0.9298      | 0.6339   | 0.4704     - 0.7864\u001b[0m\n",
      "Training 13     - 100    -          0.1556| 0.0674  | 0.2230 -           0.9477    | 0.9579      | 0.8353   | 0.4796     - 7.6363\n",
      "\u001b[1;4mValidati 13     - 32     -          0.2112| 0.2091  | 0.4203 -           0.9128    | 0.9367      | 0.6848   | 0.5416     - 0.2482\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 13     - 35     -          0.1887| 0.1743  | 0.3630 -           0.9141    | 0.9368      | 0.6868   | 0.5382     - 0.2863\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 13     - 38     -          0.2400| 0.2096  | 0.4496 -           0.9142    | 0.9370      | 0.6886   | 0.5433     - 0.3354\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 13     - 58     -          0.2182| 0.1765  | 0.3947 -           0.9145    | 0.9355      | 0.6962   | 0.5429     - 0.5161\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 13     - 61     -          0.2242| 0.2249  | 0.4492 -           0.9150    | 0.9350      | 0.6985   | 0.5417     - 0.5534\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 13     - 64     -          0.2292| 0.2015  | 0.4307 -           0.9153    | 0.9354      | 0.6997   | 0.5440     - 0.5907\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 13     - 70     -          0.2094| 0.1984  | 0.4078 -           0.9156    | 0.9357      | 0.7015   | 0.5481     - 0.6508\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 13     - 79     -          0.2419| 0.1884  | 0.4303 -           0.9154    | 0.9360      | 0.7016   | 0.5502     - 0.7337\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 13     - 100    -          0.2818| 0.2106  | 0.4924 -           0.9126    | 0.9355      | 0.6505   | 0.5087     - 0.8987\u001b[0m\n",
      "Training 14     - 100    -          0.1713| 0.0666  | 0.2380 -           0.9502    | 0.9588      | 0.8452   | 0.4847     - 7.4242\n",
      "\u001b[1;4mValidati 14     - 100    -          0.3031| 0.2193  | 0.5224 -           0.9050    | 0.9366      | 0.6493   | 0.4947     - 0.7526\u001b[0m\n",
      "Training 15     - 100    -          0.0918| 0.0354  | 0.1272 -           0.9527    | 0.9592      | 0.8534   | 0.4968     - 7.5098\n",
      "\u001b[1;4mValidati 15     - 100    -          0.3327| 0.2395  | 0.5722 -           0.9060    | 0.9351      | 0.6000   | 0.4961     - 0.7910\u001b[0m\n",
      "Training 16     - 100    -          0.1584| 0.0415  | 0.1999 -           0.9530    | 0.9584      | 0.8535   | 0.5004     - 7.5044\n",
      "\u001b[1;4mValidati 16     - 100    -          0.3201| 0.2026  | 0.5227 -           0.9100    | 0.9369      | 0.6454   | 0.5102     - 0.7327\u001b[0m\n",
      "Training 17     - 100    -          0.0703| 0.0215  | 0.0918 -           0.9557    | 0.9605      | 0.8636   | 0.5156     - 7.4036\n",
      "\u001b[1;4mValidati 17     - 35     -          0.1808| 0.1820  | 0.3627 -           0.9143    | 0.9352      | 0.7027   | 0.5528     - 0.2689\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 17     - 38     -          0.2560| 0.2155  | 0.4715 -           0.9154    | 0.9353      | 0.7070   | 0.5547     - 0.3067\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 17     - 41     -          0.1920| 0.1785  | 0.3704 -           0.9158    | 0.9351      | 0.7109   | 0.5584     - 0.3437\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 17     - 47     -          0.2493| 0.1905  | 0.4398 -           0.9164    | 0.9350      | 0.7118   | 0.5560     - 0.4038\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 17     - 50     -          0.1958| 0.1847  | 0.3805 -           0.9167    | 0.9350      | 0.7133   | 0.5547     - 0.4504\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 17     - 55     -          0.2423| 0.2096  | 0.4520 -           0.9176    | 0.9339      | 0.7191   | 0.5528     - 0.5097\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 17     - 100    -          0.3342| 0.2157  | 0.5498 -           0.9141    | 0.9337      | 0.6961   | 0.5150     - 0.8427\u001b[0m\n",
      "Training 18     - 100    -          0.1140| 0.0291  | 0.1431 -           0.9589    | 0.9592      | 0.8737   | 0.5148     - 7.4036\n",
      "\u001b[1;4mValidati 18     - 100    -          0.2746| 0.1877  | 0.4623 -           0.9103    | 0.9327      | 0.6531   | 0.5188     - 0.7547\u001b[0m\n",
      "Training 19     - 100    -          0.2227| 0.0504  | 0.2730 -           0.9575    | 0.9612      | 0.8682   | 0.5274     - 7.4564\n",
      "\u001b[1;4mValidati 19     - 100    -          0.3147| 0.1836  | 0.4984 -           0.9023    | 0.9341      | 0.6609   | 0.5070     - 0.7288\u001b[0m\n",
      "Training 20     - 100    -          0.0854| 0.0220  | 0.1074 -           0.9585    | 0.9613      | 0.8719   | 0.5299     - 7.3576\n",
      "\u001b[1;4mValidati 20     - 100    -          0.2910| 0.2231  | 0.5141 -           0.9014    | 0.9340      | 0.6201   | 0.5156     - 0.7407\u001b[0m\n",
      "Training 21     - 100    -          0.1693| 0.0440  | 0.2133 -           0.9619    | 0.9612      | 0.8829   | 0.5349     - 7.4928\n",
      "\u001b[1;4mValidati 21     - 88     -          0.1624| 0.1520  | 0.3144 -           0.9176    | 0.9380      | 0.7192   | 0.5765     - 0.6696\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 21     - 100    -          0.3124| 0.2066  | 0.5190 -           0.9141    | 0.9378      | 0.6978   | 0.5356     - 0.7834\u001b[0m\n",
      "Training 22     - 100    -          0.1247| 0.0430  | 0.1677 -           0.9657    | 0.9620      | 0.8953   | 0.5442     - 7.3537\n",
      "\u001b[1;4mValidati 22     - 50     -          0.2157| 0.1807  | 0.3964 -           0.9160    | 0.9350      | 0.7134   | 0.5678     - 0.3720\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 22     - 52     -          0.1376| 0.1808  | 0.3183 -           0.9186    | 0.9342      | 0.7228   | 0.5663     - 0.4128\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 22     - 55     -          0.2581| 0.2106  | 0.4687 -           0.9192    | 0.9337      | 0.7265   | 0.5657     - 0.4486\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 22     - 88     -          0.1523| 0.1383  | 0.2905 -           0.9198    | 0.9344      | 0.7299   | 0.5751     - 0.7055\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 22     - 100    -          0.2951| 0.1814  | 0.4766 -           0.9159    | 0.9346      | 0.7068   | 0.5342     - 0.8167\u001b[0m\n",
      "Training 23     - 100    -          0.0524| 0.0176  | 0.0700 -           0.9665    | 0.9618      | 0.8978   | 0.5459     - 7.4104\n",
      "\u001b[1;4mValidati 23     - 100    -          0.2884| 0.2283  | 0.5167 -           0.9146    | 0.9385      | 0.6534   | 0.5280     - 0.7714\u001b[0m\n",
      "Training 24     - 100    -          0.0951| 0.0228  | 0.1179 -           0.9654    | 0.9615      | 0.8945   | 0.5448     - 7.6024\n",
      "\u001b[1;4mValidati 24     - 44     -          0.2497| 0.2199  | 0.4696 -           0.9219    | 0.9405      | 0.7291   | 0.5834     - 0.3437\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 24     - 47     -          0.2662| 0.1765  | 0.4428 -           0.9229    | 0.9408      | 0.7318   | 0.5825     - 0.3804\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 24     - 50     -          0.1790| 0.1714  | 0.3504 -           0.9230    | 0.9409      | 0.7329   | 0.5823     - 0.4182\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 24     - 52     -          0.1964| 0.1971  | 0.3935 -           0.9236    | 0.9402      | 0.7364   | 0.5786     - 0.4561\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 24     - 55     -          0.2989| 0.2307  | 0.5295 -           0.9235    | 0.9395      | 0.7375   | 0.5769     - 0.4935\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 24     - 85     -          0.1720| 0.2032  | 0.3752 -           0.9230    | 0.9388      | 0.7368   | 0.5778     - 0.7342\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 24     - 100    -          0.2672| 0.1966  | 0.4638 -           0.9189    | 0.9387      | 0.7131   | 0.5365     - 0.8530\u001b[0m\n",
      "Training 25     - 100    -          0.1112| 0.0463  | 0.1575 -           0.9658    | 0.9613      | 0.8956   | 0.5426     - 7.5215\n",
      "\u001b[1;4mValidati 25     - 100    -          0.3152| 0.2305  | 0.5457 -           0.9160    | 0.9385      | 0.6656   | 0.5278     - 0.7554\u001b[0m\n",
      "Training 26     - 100    -          0.0888| 0.0321  | 0.1209 -           0.9679    | 0.9617      | 0.9021   | 0.5480     - 7.4285\n",
      "\u001b[1;4mValidati 26     - 100    -          0.3047| 0.2020  | 0.5068 -           0.9108    | 0.9363      | 0.6925   | 0.5221     - 0.7603\u001b[0m\n",
      "Training 27     - 100    -          0.0672| 0.0359  | 0.1030 -           0.9692    | 0.9618      | 0.9065   | 0.5523     - 7.6129\n",
      "\u001b[1;4mValidati 27     - 100    -          0.2766| 0.1978  | 0.4744 -           0.9099    | 0.9284      | 0.6410   | 0.5072     - 0.7479\u001b[0m\n",
      "Training 28     - 100    -          0.1079| 0.0253  | 0.1332 -           0.9703    | 0.9623      | 0.9096   | 0.5552     - 7.3690\n",
      "\u001b[1;4mValidati 28     - 100    -          0.3241| 0.2363  | 0.5604 -           0.8813    | 0.9247      | 0.6042   | 0.4530     - 0.7237\u001b[0m\n",
      "Training 29     - 100    -          0.0929| 0.0349  | 0.1278 -           0.9734    | 0.9625      | 0.9193   | 0.5590     - 7.4608\n",
      "\u001b[1;4mValidati 29     - 100    -          0.2770| 0.2439  | 0.5209 -           0.9113    | 0.9212      | 0.6969   | 0.4998     - 0.7819\u001b[0m\n",
      "Training 30     - 100    -          0.1140| 0.0250  | 0.1390 -           0.9706    | 0.9619      | 0.9110   | 0.5549     - 7.4016\n",
      "\u001b[1;4mValidati 30     - 100    -          0.2972| 0.2171  | 0.5142 -           0.9122    | 0.9373      | 0.6950   | 0.5241     - 0.7360\u001b[0m\n",
      "Training 31     - 100    -          0.0831| 0.0217  | 0.1047 -           0.9744    | 0.9625      | 0.9227   | 0.5617     - 7.4408\n",
      "\u001b[1;4mValidati 31     - 100    -          0.3044| 0.2068  | 0.5112 -           0.9151    | 0.9354      | 0.6973   | 0.5315     - 0.7413\u001b[0m\n",
      "Training 32     - 100    -          0.0943| 0.0397  | 0.1340 -           0.9730    | 0.9628      | 0.9183   | 0.5636     - 7.4963\n",
      "\u001b[1;4mValidati 32     - 100    -          0.3090| 0.2279  | 0.5370 -           0.9102    | 0.9344      | 0.6827   | 0.5202     - 0.7958\u001b[0m\n",
      "Training 33     - 100    -          0.0690| 0.0233  | 0.0923 -           0.9763    | 0.9626      | 0.9282   | 0.5643     - 7.4532\n",
      "\u001b[1;4mValidati 33     - 100    -          0.3202| 0.2068  | 0.5270 -           0.9113    | 0.9337      | 0.6599   | 0.5288     - 0.7280\u001b[0m\n",
      "Training 34     - 100    -          0.1237| 0.0603  | 0.1840 -           0.9738    | 0.9627      | 0.9204   | 0.5639     - 7.3682\n",
      "\u001b[1;4mValidati 34     - 100    -          0.2966| 0.1838  | 0.4804 -           0.9131    | 0.9355      | 0.7005   | 0.5336     - 0.7500\u001b[0m\n",
      "Training 35     - 100    -          0.0203| 0.0349  | 0.0552 -           0.9767    | 0.9635      | 0.9296   | 0.5728     - 7.4556\n",
      "\u001b[1;4mValidati 35     - 100    -          0.3335| 0.2274  | 0.5608 -           0.9150    | 0.9389      | 0.7024   | 0.5402     - 0.7569\u001b[0m\n",
      "Training 36     - 100    -          0.0435| 0.0195  | 0.0631 -           0.9782    | 0.9639      | 0.9345   | 0.5752     - 7.4432\n",
      "\u001b[1;4mValidati 36     - 100    -          0.2588| 0.1807  | 0.4395 -           0.9075    | 0.9339      | 0.6851   | 0.5216     - 0.7416\u001b[0m\n",
      "Training 37     - 100    -          0.0495| 0.0383  | 0.0878 -           0.9802    | 0.9649      | 0.9399   | 0.5836     - 7.4456\n",
      "\u001b[1;4mValidati 37     - 52     -          0.1928| 0.1952  | 0.3879 -           0.9198    | 0.9305      | 0.7380   | 0.5645     - 0.4103\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 37     - 55     -          0.2880| 0.2204  | 0.5085 -           0.9202    | 0.9301      | 0.7403   | 0.5645     - 0.4495\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 37     - 100    -          0.3129| 0.2396  | 0.5525 -           0.9149    | 0.9312      | 0.7112   | 0.5319     - 0.8031\u001b[0m\n",
      "Training 38     - 100    -          0.0230| 0.0138  | 0.0368 -           0.9778    | 0.9628      | 0.9330   | 0.5691     - 7.4631\n",
      "\u001b[1;4mValidati 38     - 100    -          0.3197| 0.2331  | 0.5529 -           0.9034    | 0.9288      | 0.6741   | 0.5039     - 0.7403\u001b[0m\n",
      "Training 39     - 100    -          0.0385| 0.0228  | 0.0613 -           0.9784    | 0.9642      | 0.9349   | 0.5814     - 7.4110\n",
      "\u001b[1;4mValidati 39     - 100    -          0.2887| 0.2101  | 0.4988 -           0.9136    | 0.9307      | 0.6688   | 0.5148     - 0.7476\u001b[0m\n",
      "Training 40     - 100    -          0.0954| 0.0306  | 0.1261 -           0.9776    | 0.9637      | 0.9323   | 0.5765     - 7.4075\n",
      "\u001b[1;4mValidati 40     - 100    -          0.3292| 0.2232  | 0.5525 -           0.9145    | 0.9332      | 0.7048   | 0.5309     - 0.7673\u001b[0m\n",
      "Training 41     - 100    -          0.0523| 0.0599  | 0.1121 -           0.9815    | 0.9629      | 0.9446   | 0.5738     - 7.5409\n",
      "\u001b[1;4mValidati 41     - 100    -          0.2973| 0.1914  | 0.4888 -           0.9142    | 0.9306      | 0.7019   | 0.5306     - 0.7407\u001b[0m\n",
      "Training 42     - 100    -          0.0464| 0.0377  | 0.0841 -           0.9758    | 0.9624      | 0.9267   | 0.5666     - 7.4056\n",
      "\u001b[1;4mValidati 42     - 100    -          0.2851| 0.1973  | 0.4824 -           0.9131    | 0.9308      | 0.6700   | 0.5279     - 0.7441\u001b[0m\n",
      "Training 43     - 100    -          0.0358| 0.0205  | 0.0563 -           0.9803    | 0.9623      | 0.9408   | 0.5693     - 7.3885\n",
      "\u001b[1;4mValidati 43     - 100    -          0.2788| 0.1796  | 0.4584 -           0.9098    | 0.9340      | 0.7021   | 0.5367     - 0.7656\u001b[0m\n",
      "Training 44     - 100    -          0.0509| 0.0197  | 0.0706 -           0.9818    | 0.9633      | 0.9455   | 0.5775     - 7.4591\n",
      "\u001b[1;4mValidati 44     - 100    -          0.2800| 0.1971  | 0.4772 -           0.9174    | 0.9322      | 0.6719   | 0.5372     - 0.7438\u001b[0m\n",
      "Training 45     - 100    -          0.1498| 0.0404  | 0.1903 -           0.9817    | 0.9628      | 0.9449   | 0.5756     - 7.4571\n",
      "\u001b[1;4mValidati 45     - 100    -          0.3195| 0.2185  | 0.5380 -           0.9123    | 0.9348      | 0.6611   | 0.5230     - 0.7386\u001b[0m\n",
      "Training 46     - 100    -          0.0318| 0.0188  | 0.0506 -           0.9822    | 0.9635      | 0.9465   | 0.5826     - 7.4504\n",
      "\u001b[1;4mValidati 46     - 100    -          0.3099| 0.2459  | 0.5558 -           0.9198    | 0.9315      | 0.7132   | 0.5239     - 0.7871\u001b[0m\n",
      "Training 47     - 100    -          0.0711| 0.0573  | 0.1283 -           0.9804    | 0.9627      | 0.9411   | 0.5756     - 7.3968\n",
      "\u001b[1;4mValidati 47     - 100    -          0.3005| 0.2068  | 0.5073 -           0.9085    | 0.9294      | 0.6899   | 0.5171     - 0.7234\u001b[0m\n",
      "Training 48     - 100    -          0.0324| 0.0266  | 0.0590 -           0.9825    | 0.9625      | 0.9476   | 0.5758     - 7.3397\n",
      "\u001b[1;4mValidati 48     - 100    -          0.3136| 0.2237  | 0.5373 -           0.9096    | 0.9296      | 0.6618   | 0.5185     - 0.7425\u001b[0m\n",
      "Training 49     - 100    -          0.0763| 0.0478  | 0.1241 -           0.9782    | 0.9622      | 0.9346   | 0.5678     - 7.4892\n",
      "\u001b[1;4mValidati 49     - 100    -          0.3041| 0.2036  | 0.5077 -           0.9134    | 0.9355      | 0.7106   | 0.5449     - 0.7551\u001b[0m\n",
      "Training 50     - 100    -          0.0408| 0.0271  | 0.0679 -           0.9835    | 0.9646      | 0.9503   | 0.5880     - 7.3697\n",
      "\u001b[1;4mValidati 50     - 100    -          0.3236| 0.2191  | 0.5428 -           0.9128    | 0.9257      | 0.6675   | 0.4969     - 0.7440\u001b[0m\n",
      "Training 51     - 100    -          0.1309| 0.0529  | 0.1838 -           0.9853    | 0.9645      | 0.9555   | 0.5899     - 7.3700\n",
      "\u001b[1;4mValidati 51     - 58     -          0.3007| 0.2231  | 0.5238 -           0.9250    | 0.9337      | 0.7402   | 0.5545     - 0.4477\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 51     - 100    -          0.3309| 0.2084  | 0.5393 -           0.9198    | 0.9333      | 0.6827   | 0.5158     - 0.7766\u001b[0m\n",
      "Training 52     - 100    -          0.0378| 0.0436  | 0.0813 -           0.9829    | 0.9640      | 0.9486   | 0.5865     - 7.4767\n",
      "\u001b[1;4mValidati 52     - 100    -          0.2964| 0.1850  | 0.4814 -           0.9159    | 0.9274      | 0.7097   | 0.5275     - 0.7588\u001b[0m\n",
      "Training 53     - 100    -          0.0603| 0.0534  | 0.1137 -           0.9815    | 0.9632      | 0.9443   | 0.5768     - 7.4001\n",
      "\u001b[1;4mValidati 53     - 100    -          0.2958| 0.2065  | 0.5022 -           0.9125    | 0.9304      | 0.6702   | 0.5196     - 0.7268\u001b[0m\n",
      "Training 54     - 100    -          0.0688| 0.0334  | 0.1022 -           0.9852    | 0.9635      | 0.9557   | 0.5847     - 7.3014\n",
      "\u001b[1;4mValidati 54     - 100    -          0.2834| 0.2173  | 0.5007 -           0.9128    | 0.9359      | 0.7016   | 0.5359     - 0.7534\u001b[0m\n",
      "Training 55     - 100    -          0.0381| 0.0197  | 0.0579 -           0.9843    | 0.9638      | 0.9529   | 0.5854     - 7.4575\n",
      "\u001b[1;4mValidati 55     - 55     -          0.3912| 0.2427  | 0.6340 -           0.9232    | 0.9374      | 0.7395   | 0.5826     - 0.4126\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 55     - 58     -          0.2447| 0.2022  | 0.4469 -           0.9244    | 0.9377      | 0.7430   | 0.5842     - 0.4500\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 55     - 100    -          0.3221| 0.2207  | 0.5428 -           0.9187    | 0.9373      | 0.7157   | 0.5466     - 0.7594\u001b[0m\n",
      "Training 56     - 100    -          0.0850| 0.0184  | 0.1034 -           0.9865    | 0.9653      | 0.9594   | 0.5984     - 7.3265\n",
      "\u001b[1;4mValidati 56     - 55     -          0.3813| 0.2497  | 0.6310 -           0.9206    | 0.9276      | 0.7423   | 0.5524     - 0.4123\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 56     - 64     -          0.4315| 0.2280  | 0.6595 -           0.9214    | 0.9276      | 0.7447   | 0.5541     - 0.4920\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 56     - 100    -          0.3078| 0.2211  | 0.5289 -           0.9167    | 0.9291      | 0.7179   | 0.5228     - 0.7575\u001b[0m\n",
      "Training 57     - 100    -          0.0206| 0.0306  | 0.0512 -           0.9854    | 0.9652      | 0.9563   | 0.5986     - 7.3374\n",
      "\u001b[1;4mValidati 57     - 100    -          0.3278| 0.1814  | 0.5092 -           0.9096    | 0.9346      | 0.6579   | 0.5236     - 0.7565\u001b[0m\n",
      "Training 58     - 100    -          0.0329| 0.0301  | 0.0630 -           0.9858    | 0.9647      | 0.9577   | 0.5921     - 7.4396\n",
      "\u001b[1;4mValidati 58     - 100    -          0.2832| 0.1904  | 0.4736 -           0.9140    | 0.9275      | 0.6742   | 0.5198     - 0.7234\u001b[0m\n",
      "Training 59     - 100    -          0.0798| 0.0284  | 0.1082 -           0.9798    | 0.9640      | 0.9400   | 0.5828     - 7.3528\n",
      "\u001b[1;4mValidati 59     - 100    -          0.2870| 0.2226  | 0.5096 -           0.9127    | 0.9283      | 0.7033   | 0.5150     - 0.7235\u001b[0m\n",
      "Training 60     - 100    -          0.0628| 0.0184  | 0.0813 -           0.9851    | 0.9641      | 0.9556   | 0.5886     - 7.4239\n",
      "\u001b[1;4mValidati 60     - 100    -          0.2931| 0.1980  | 0.4912 -           0.9160    | 0.9366      | 0.7071   | 0.5435     - 0.7999\u001b[0m\n",
      "Training 61     - 100    -          0.0797| 0.0582  | 0.1380 -           0.9859    | 0.9655      | 0.9579   | 0.6006     - 7.4712\n",
      "\u001b[1;4mValidati 61     - 100    -          0.3430| 0.1997  | 0.5427 -           0.9147    | 0.9320      | 0.6801   | 0.5317     - 0.7280\u001b[0m\n",
      "Training 62     - 100    -          0.0366| 0.0269  | 0.0636 -           0.9839    | 0.9645      | 0.9513   | 0.5908     - 7.3581\n",
      "\u001b[1;4mValidati 62     - 100    -          0.3090| 0.1774  | 0.4864 -           0.9116    | 0.9304      | 0.6652   | 0.5316     - 0.7410\u001b[0m\n",
      "Training 63     - 100    -          0.0224| 0.0174  | 0.0399 -           0.9841    | 0.9646      | 0.9523   | 0.5924     - 7.4772\n",
      "\u001b[1;4mValidati 63     - 100    -          0.2873| 0.1782  | 0.4656 -           0.8959    | 0.9133      | 0.6418   | 0.4633     - 0.7786\u001b[0m\n",
      "Training 64     - 100    -          0.0353| 0.0285  | 0.0637 -           0.9848    | 0.9658      | 0.9542   | 0.6000     - 7.4683\n",
      "\u001b[1;4mValidati 64     - 100    -          0.2965| 0.2074  | 0.5039 -           0.9084    | 0.9229      | 0.6872   | 0.5024     - 0.7427\u001b[0m\n",
      "Training 65     - 100    -          0.0062| 0.0183  | 0.0246 -           0.9850    | 0.9637      | 0.9546   | 0.5880     - 7.4607\n",
      "\u001b[1;4mValidati 65     - 100    -          0.3029| 0.1873  | 0.4902 -           0.9174    | 0.9351      | 0.7140   | 0.5478     - 0.7501\u001b[0m\n",
      "Training 66     - 100    -          0.0398| 0.0415  | 0.0813 -           0.9885    | 0.9649      | 0.9654   | 0.5993     - 7.3853\n",
      "\u001b[1;4mValidati 66     - 100    -          0.2778| 0.1991  | 0.4770 -           0.9143    | 0.9358      | 0.7088   | 0.5412     - 0.7389\u001b[0m\n",
      "Training 67     - 100    -          0.0251| 0.0248  | 0.0499 -           0.9854    | 0.9641      | 0.9562   | 0.5910     - 7.4088\n",
      "\u001b[1;4mValidati 67     - 100    -          0.2855| 0.1970  | 0.4825 -           0.9134    | 0.9370      | 0.6995   | 0.5368     - 0.7451\u001b[0m\n",
      "Training 68     - 100    -          0.1014| 0.0253  | 0.1267 -           0.9834    | 0.9639      | 0.9505   | 0.5866     - 7.3985\n",
      "\u001b[1;4mValidati 68     - 100    -          0.2946| 0.2070  | 0.5017 -           0.9057    | 0.9328      | 0.6750   | 0.5172     - 0.7562\u001b[0m\n",
      "Training 69     - 100    -          0.0676| 0.0167  | 0.0843 -           0.9854    | 0.9653      | 0.9565   | 0.5971     - 7.4903\n",
      "\u001b[1;4mValidati 69     - 29     -          0.2621| 0.1378  | 0.3999 -           0.9219    | 0.9374      | 0.7366   | 0.5934     - 0.2219\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 69     - 38     -          0.3505| 0.2068  | 0.5573 -           0.9245    | 0.9380      | 0.7469   | 0.5950     - 0.3044\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 69     - 44     -          0.4231| 0.2232  | 0.6464 -           0.9254    | 0.9377      | 0.7524   | 0.5965     - 0.3638\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 69     - 47     -          0.3073| 0.1943  | 0.5016 -           0.9264    | 0.9380      | 0.7559   | 0.5963     - 0.4041\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 69     - 50     -          0.2935| 0.1912  | 0.4847 -           0.9270    | 0.9381      | 0.7589   | 0.5955     - 0.4421\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 69     - 52     -          0.2565| 0.2071  | 0.4636 -           0.9283    | 0.9370      | 0.7638   | 0.5911     - 0.4805\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 69     - 55     -          0.3112| 0.2110  | 0.5223 -           0.9289    | 0.9365      | 0.7668   | 0.5904     - 0.5184\u001b[0m\n",
      "\u001b[1;37mINFO --- checkpoint.step >>> Best performance reached: saving the model\u001b[0m\n",
      "\u001b[1;4mValidati 69     - 100    -          0.2997| 0.2234  | 0.5231 -           0.9212    | 0.9364      | 0.7311   | 0.5525     - 0.8599\u001b[0m\n",
      "Training 70     - 100    -          0.0621| 0.0435  | 0.1056 -           0.9882    | 0.9656      | 0.9646   | 0.6026     - 7.3430\n",
      "\u001b[1;4mValidati 70     - 100    -          0.3512| 0.2185  | 0.5697 -           0.9118    | 0.9337      | 0.6766   | 0.5321     - 0.7222\u001b[0m\n",
      "Training 71     - 100    -          0.0407| 0.0292  | 0.0699 -           0.9862    | 0.9643      | 0.9587   | 0.5937     - 7.3937\n",
      "\u001b[1;4mValidati 71     - 100    -          0.2869| 0.2046  | 0.4915 -           0.9080    | 0.9290      | 0.6765   | 0.5109     - 0.7764\u001b[0m\n",
      "Training 72     - 100    -          0.0212| 0.0176  | 0.0387 -           0.9850    | 0.9650      | 0.9549   | 0.5951     - 7.4960\n",
      "\u001b[1;4mValidati 72     - 100    -          0.2996| 0.2082  | 0.5077 -           0.9152    | 0.9344      | 0.6730   | 0.5282     - 0.7448\u001b[0m\n",
      "Training 73     - 100    -          0.0069| 0.0339  | 0.0409 -           0.9868    | 0.9654      | 0.9602   | 0.5993     - 7.4460\n",
      "\u001b[1;4mValidati 73     - 100    -          0.3097| 0.2280  | 0.5378 -           0.9175    | 0.9292      | 0.7059   | 0.5201     - 0.7452\u001b[0m\n",
      "Training 74     - 100    -          0.0044| 0.0179  | 0.0223 -           0.9906    | 0.9655      | 0.9721   | 0.6047     - 7.3942\n",
      "\u001b[1;4mValidati 74     - 100    -          0.2790| 0.1973  | 0.4764 -           0.9208    | 0.9339      | 0.6953   | 0.5331     - 0.7666\u001b[0m\n",
      "Training 75     - 100    -          0.0447| 0.0087  | 0.0534 -           0.9881    | 0.9653      | 0.9640   | 0.6018     - 7.5169\n",
      "\u001b[1;4mValidati 75     - 100    -          0.2934| 0.2343  | 0.5277 -           0.9200    | 0.9397      | 0.6845   | 0.5439     - 0.7382\u001b[0m\n",
      "Training 76     - 100    -          0.0231| 0.0248  | 0.0479 -           0.9814    | 0.9648      | 0.9441   | 0.5918     - 7.3833\n",
      "\u001b[1;4mValidati 76     - 100    -          0.3325| 0.2038  | 0.5363 -           0.9016    | 0.9358      | 0.6377   | 0.5118     - 0.7395\u001b[0m\n",
      "Training 77     - 100    -          0.0181| 0.0245  | 0.0426 -           0.9813    | 0.9651      | 0.9442   | 0.5929     - 7.5440\n",
      "\u001b[1;4mValidati 77     - 100    -          0.2959| 0.2080  | 0.5039 -           0.9121    | 0.9358      | 0.6941   | 0.5321     - 0.7689\u001b[0m\n",
      "Training 78     - 100    -          0.0215| 0.0291  | 0.0507 -           0.9849    | 0.9654      | 0.9548   | 0.5952     - 7.3942\n",
      "\u001b[1;4mValidati 78     - 100    -          0.3298| 0.1965  | 0.5263 -           0.9175    | 0.9359      | 0.7132   | 0.5384     - 0.7193\u001b[0m\n",
      "Training 79     - 100    -          0.0367| 0.0204  | 0.0571 -           0.9879    | 0.9665      | 0.9639   | 0.6082     - 7.3844\n",
      "\u001b[1;4mValidati 79     - 100    -          0.3192| 0.2240  | 0.5432 -           0.9175    | 0.9390      | 0.7195   | 0.5499     - 0.7477\u001b[0m\n",
      "Training 80     - 100    -          0.0635| 0.0484  | 0.1119 -           0.9891    | 0.9653      | 0.9675   | 0.6025     - 7.4934\n",
      "\u001b[1;4mValidati 80     - 100    -          0.3099| 0.2219  | 0.5318 -           0.9153    | 0.9361      | 0.7040   | 0.5336     - 0.7533\u001b[0m\n",
      "Training 81     - 100    -          0.0333| 0.0190  | 0.0523 -           0.9860    | 0.9651      | 0.9582   | 0.6003     - 7.4806\n",
      "\u001b[1;4mValidati 81     - 100    -          0.2937| 0.2056  | 0.4993 -           0.9201    | 0.9358      | 0.7227   | 0.5390     - 0.7226\u001b[0m\n",
      "Training 82     - 100    -          0.0392| 0.0312  | 0.0704 -           0.9886    | 0.9653      | 0.9661   | 0.6012     - 7.3285\n",
      "\u001b[1;4mValidati 82     - 100    -          0.3144| 0.2207  | 0.5350 -           0.9153    | 0.9330      | 0.7144   | 0.5405     - 0.7675\u001b[0m\n",
      "Training 83     - 100    -          0.0358| 0.0331  | 0.0690 -           0.9895    | 0.9661      | 0.9685   | 0.6075     - 7.5555\n",
      "\u001b[1;4mValidati 83     - 100    -          0.3070| 0.2240  | 0.5310 -           0.9161    | 0.9327      | 0.7154   | 0.5380     - 0.7444\u001b[0m\n",
      "Training 84     - 100    -          0.0403| 0.0146  | 0.0549 -           0.9816    | 0.9653      | 0.9452   | 0.5955     - 7.3900\n",
      "\u001b[1;4mValidati 84     - 100    -          0.2872| 0.2212  | 0.5084 -           0.9138    | 0.9371      | 0.7039   | 0.5386     - 0.7372\u001b[0m\n",
      "Training 85     - 100    -          0.0145| 0.0334  | 0.0479 -           0.9874    | 0.9662      | 0.9619   | 0.6077     - 7.3522\n",
      "\u001b[1;4mValidati 85     - 100    -          0.2922| 0.2067  | 0.4990 -           0.9176    | 0.9299      | 0.7186   | 0.5272     - 0.7551\u001b[0m\n",
      "Training 86     - 100    -          0.0012| 0.0173  | 0.0185 -           0.9902    | 0.9648      | 0.9706   | 0.6010     - 7.4897\n",
      "\u001b[1;4mValidati 86     - 100    -          0.2928| 0.1966  | 0.4894 -           0.9062    | 0.9225      | 0.6723   | 0.4874     - 0.7361\u001b[0m\n",
      "Training 87     - 100    -          0.0068| 0.0130  | 0.0198 -           0.9902    | 0.9649      | 0.9705   | 0.6008     - 7.4469\n",
      "\u001b[1;4mValidati 87     - 100    -          0.3058| 0.2122  | 0.5180 -           0.9168    | 0.9344      | 0.7108   | 0.5361     - 0.7464\u001b[0m\n",
      "Training 88     - 100    -          0.0016| 0.0118  | 0.0134 -           0.9880    | 0.9652      | 0.9642   | 0.6006     - 7.4591\n",
      "\u001b[1;4mValidati 88     - 100    -          0.2849| 0.2019  | 0.4868 -           0.8964    | 0.9272      | 0.6281   | 0.4767     - 0.7602\u001b[0m\n",
      "Training 89     - 100    -          0.0137| 0.0394  | 0.0531 -           0.9843    | 0.9653      | 0.9534   | 0.6002     - 7.3480\n",
      "\u001b[1;4mValidati 89     - 100    -          0.2959| 0.2091  | 0.5050 -           0.9156    | 0.9336      | 0.6664   | 0.5229     - 0.7243\u001b[0m\n",
      "Training 90     - 100    -          0.0383| 0.0172  | 0.0554 -           0.9849    | 0.9651      | 0.9545   | 0.5967     - 7.2782\n",
      "\u001b[1;4mValidati 90     - 100    -          0.2943| 0.2103  | 0.5045 -           0.9169    | 0.9359      | 0.7059   | 0.5363     - 0.7380\u001b[0m\n",
      "Training 91     - 100    -          0.0017| 0.0110  | 0.0127 -           0.9876    | 0.9658      | 0.9630   | 0.6036     - 7.4206\n",
      "\u001b[1;4mValidati 91     - 100    -          0.3272| 0.2177  | 0.5449 -           0.9138    | 0.9368      | 0.7125   | 0.5507     - 0.7400\u001b[0m\n",
      "Training 92     - 100    -          0.0509| 0.0334  | 0.0843 -           0.9898    | 0.9659      | 0.9697   | 0.6079     - 7.3220\n",
      "\u001b[1;4mValidati 92     - 100    -          0.2911| 0.2005  | 0.4916 -           0.9138    | 0.9350      | 0.7131   | 0.5473     - 0.7262\u001b[0m\n",
      "Training 93     - 100    -          0.0451| 0.0097  | 0.0547 -           0.9874    | 0.9642      | 0.9622   | 0.5956     - 7.2846\n",
      "\u001b[1;4mValidati 93     - 100    -          0.2916| 0.2044  | 0.4960 -           0.9102    | 0.9393      | 0.6906   | 0.5458     - 0.7357\u001b[0m\n",
      "Training 94     - 100    -          0.0311| 0.0127  | 0.0438 -           0.9851    | 0.9651      | 0.9554   | 0.5930     - 7.3801\n",
      "\u001b[1;4mValidati 94     - 100    -          0.3194| 0.2240  | 0.5434 -           0.9155    | 0.9401      | 0.6716   | 0.5537     - 0.7436\u001b[0m\n",
      "Training 95     - 100    -          0.0419| 0.0412  | 0.0831 -           0.9881    | 0.9664      | 0.9647   | 0.6081     - 7.4561\n",
      "\u001b[1;4mValidati 95     - 100    -          0.2801| 0.2213  | 0.5015 -           0.9112    | 0.9334      | 0.6875   | 0.5160     - 0.7492\u001b[0m\n",
      "Training 96     - 100    -          0.0117| 0.0140  | 0.0256 -           0.9871    | 0.9658      | 0.9612   | 0.6019     - 7.4027\n",
      "\u001b[1;4mValidati 96     - 100    -          0.3036| 0.2123  | 0.5159 -           0.9122    | 0.9299      | 0.6963   | 0.5147     - 0.7681\u001b[0m\n",
      "Training 97     - 100    -          0.0027| 0.0215  | 0.0242 -           0.9906    | 0.9660      | 0.9722   | 0.6090     - 7.5057\n",
      "\u001b[1;4mValidati 97     - 100    -          0.2937| 0.2156  | 0.5093 -           0.9163    | 0.9359      | 0.7101   | 0.5420     - 0.7359\u001b[0m\n",
      "Training 98     - 100    -          0.0381| 0.0194  | 0.0576 -           0.9904    | 0.9663      | 0.9711   | 0.6114     - 7.3889\n",
      "\u001b[1;4mValidati 98     - 100    -          0.3029| 0.2174  | 0.5203 -           0.9151    | 0.9385      | 0.6757   | 0.5471     - 0.7454\u001b[0m\n",
      "Training 99     - 100    -          0.0261| 0.0241  | 0.0502 -           0.9915    | 0.9658      | 0.9746   | 0.6099     - 7.3746\n",
      "\u001b[1;4mValidati 99     - 100    -          0.2974| 0.2243  | 0.5217 -           0.9210    | 0.9362      | 0.7262   | 0.5490     - 0.7567\u001b[0m\n",
      "Training 100    - 100    -          0.0385| 0.0226  | 0.0611 -           0.9883    | 0.9659      | 0.9653   | 0.6082     - 7.4691\n",
      "\u001b[1;4mValidati 100    - 100    -          0.2683| 0.2166  | 0.4849 -           0.9168    | 0.9337      | 0.7084   | 0.5306     - 0.7452\u001b[0m\r"
     ]
    }
   ],
   "source": [
    "# tensorboard\n",
    "title = \"dcase2019_system_%s\" % (get_datetime())\n",
    "tensorboard = SummaryWriter(log_dir=Path(\"../tensorboard/%s\" % title), comment=\"weak baseline\")\n",
    "\n",
    "print(header)\n",
    "for e in range(nb_epochs):\n",
    "    train(e)\n",
    "    val(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization before evaluation - ♫♪.ılılıll|̲̅̅●̲̅̅|̲̅̅=̲̅̅|̲̅̅●̲̅̅|llılılı.♫♪\n",
    "At this stage, we will work with the output of the best epoch on the validation dataset. The process is done into 3 stages\n",
    "- The optimization of tagging performance using simulating annealing\n",
    "- The pruning of the strong prediction\n",
    "- The optimization of the localization system using aeseg (hysteresis thresholding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = dcase2019_model()\n",
    "best_model.cuda()\n",
    "best_model.eval() # <-- for consistency in scoring (deactivate dropout and batchNorm)\n",
    "\n",
    "checkpoint = torch.load(\"../models/best_dcase2019.torch\")\n",
    "best_model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform prediction on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100 %\r"
     ]
    }
   ],
   "source": [
    "weak_y_true, strong_y_true = None, None\n",
    "weak_y_pred, strong_y_pred = None, None\n",
    "y_filenames = list(val_dataset.X.keys())\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    for i, (X, y) in enumerate(val_loader):\n",
    "        weak_y, strong_y = y\n",
    "        weak_y, strong_y = weak_y.cuda(), strong_y.cuda()\n",
    "        X = X.cuda()\n",
    "        \n",
    "        weak_logits, strong_logits = model(X)\n",
    "        \n",
    "        weak_pred = torch.sigmoid(weak_logits)\n",
    "        strong_pred = torch.sigmoid(strong_logits)\n",
    "        \n",
    "        # accumulate prediction and ground truth\n",
    "        if i == 0:\n",
    "            weak_y_true = weak_y.cpu()\n",
    "            strong_y_true = strong_y.cpu()\n",
    "\n",
    "            weak_y_pred =  weak_pred.cpu()\n",
    "            strong_y_pred =  strong_pred.cpu()\n",
    "        else:\n",
    "            weak_y_true = torch.cat((weak_y_true, weak_y.cpu()), dim=0)\n",
    "            strong_y_true = torch.cat((strong_y_true, strong_y.cpu()), dim=0)\n",
    "\n",
    "            weak_y_pred =  torch.cat((weak_y_pred, weak_pred.cpu()), dim=0)\n",
    "            strong_y_pred =  torch.cat((strong_y_pred, strong_pred.cpu()), dim=0)\n",
    "        \n",
    "        print(\" %d %%\" % int(100 * (i + 1) / len(val_loader)), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1058, 10]),\n",
       " torch.Size([1058, 10]),\n",
       " torch.Size([1058, 10, 431]),\n",
       " torch.Size([1058, 10, 431]),\n",
       " 1058)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weak_y_true.shape, weak_y_pred.shape, strong_y_true.shape, strong_y_pred.shape, len(y_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio tagging threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "classwise_f1 = FScore(dim=0)\n",
    "def simulated_anealing(y_pred, y_true, macro_iteration = 50, micro_iteration = 400):\n",
    "    weak_y_pred_ = y_pred.clone().detach()\n",
    "\n",
    "    start_f1 = classwise_f1(weak_y_pred_, weak_y_true)\n",
    "\n",
    "    min_delta = 10e-7\n",
    "    delta_ratio = 0.2\n",
    "#     macro_iteration = 30\n",
    "#     micro_iteration = 400\n",
    "\n",
    "    history = {\n",
    "        \"best_f1\": [[] for _ in range(10)],\n",
    "        \"f1\": [],\n",
    "        \"delta_ratio\": []\n",
    "    }\n",
    "\n",
    "    best_thresholds = torch.ones(10) * 0.5\n",
    "    best_f1 = start_f1.clone().detach()\n",
    "\n",
    "    total_iteration = macro_iteration * micro_iteration\n",
    "    \n",
    "    for M in range(macro_iteration):\n",
    "        thresholds = torch.ones(10) * 0.5\n",
    "        delta_ratio = 0.2\n",
    "        delta_decay = ( (min_delta + delta_ratio) / micro_iteration )\n",
    "\n",
    "        for m in range(micro_iteration):\n",
    "            bin_y_pred = y_pred.clone().detach()\n",
    "\n",
    "            # calc new threhsold\n",
    "            r = torch.normal(mean=thresholds, std=0.4)\n",
    "            delta = r * delta_ratio\n",
    "            new_thresholds = thresholds + delta\n",
    "            delta_ratio -= delta_decay\n",
    "            history[\"delta_ratio\"].append(delta_ratio)\n",
    "\n",
    "            # apply threshold\n",
    "            weak_y_pred_[bin_y_pred > new_thresholds] = 1\n",
    "            weak_y_pred_[bin_y_pred <= new_thresholds] = 0\n",
    "\n",
    "            # calc new f1\n",
    "            new_f1 = classwise_f1(weak_y_pred_, weak_y_true)\n",
    "            history[\"f1\"].append(new_f1)\n",
    "\n",
    "            # check\n",
    "            for i in range(10):\n",
    "                if new_f1[i] > best_f1[i]:\n",
    "#                     print(new_f1[i], \" > \", best_f1[i])\n",
    "                    best_f1[i] = new_f1[i]\n",
    "                    best_thresholds[i] = new_thresholds[i]\n",
    "                    thresholds[i] = best_thresholds[i]\n",
    "                    history[\"best_f1\"][i].append(best_f1[i])\n",
    "\n",
    "            step = M * micro_iteration + m\n",
    "            print(\"%2.2f / 100.0 (%%)\" % ((step / total_iteration) * 100), end=\"\\r\")\n",
    "            \n",
    "    return start_f1, best_f1, best_thresholds, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99 / 100.0 (%)\r"
     ]
    }
   ],
   "source": [
    "initial_f1, best_f1, best_at_thresholds, history = simulated_anealing(weak_y_pred, weak_y_true, 20, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6400), tensor(0.6429))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(initial_f1), torch.mean(best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000, 0.7808, 0.5524, 0.8155, 0.5000, 0.5000, 0.6511, 0.6245,\n",
       "        0.6663])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_at_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply new threshold and perform pruning on strong prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weak_y_pred = weak_y_pred.clone().detach()\n",
    "\n",
    "best_weak_y_pred[best_weak_y_pred > best_at_thresholds] = 1\n",
    "best_weak_y_pred[best_weak_y_pred <= best_at_thresholds] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1058, 10]), torch.Size([1058, 10, 431]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weak_y_pred.shape, strong_y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune the result of fill the missing curve with 0 segments\n",
    "def prune_prediction(strong_y_pred, weak_y_pred):\n",
    "    \"\"\" Prune the strong prediciton by zeroing all classes that are not predicted. \"\"\"\n",
    "    pruned_strong_y_pred = strong_y_pred.clone().detach()\n",
    "    \n",
    "    for index in range(len(pruned_strong_y_pred)):\n",
    "        cls_result = weak_y_pred[index]\n",
    "        \n",
    "        # Create a full mask using repeat\n",
    "        length = strong_y_pred.size()[-1]\n",
    "        cls_mask = cls_result.unsqueeze(1).repeat(1, length)\n",
    "        pruned_strong_y_pred[index] *= cls_mask\n",
    "                \n",
    "    return pruned_strong_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_strong_y_pred = prune_prediction(strong_y_pred, best_weak_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.2572, 0.3861, 0.4987,  ..., 0.0025, 0.0031, 0.0331]]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weak_y_pred[1], pruned_strong_y_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_list = list(DESEDManager.cls_dict.keys())\n",
    "plt.figure(0, figsize=(15, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_list):\n",
    "    plt.plot(pruned_strong_y_pred[1][i], label=class_name)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform segmentation of the prediction curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -i https://test.pypi.org/simple/ aeseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeseg.Encoder import Encoder\n",
    "from aeseg.optimizers import GenOptimizer, DichotomicOptimizer\n",
    "from aeseg.core import eb_evaluator, sb_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.read().splitlines()[1:]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1058, 431, 10]), torch.Size([1058, 431, 10]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Optimizer take data in the following shape (file, seq, class)\n",
    "strong_y_true = strong_y_true.permute(0, 2, 1)\n",
    "pruned_strong_y_pred = pruned_strong_y_pred.permute(0, 2, 1)\n",
    "strong_y_true.shape, pruned_strong_y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_wise_optimization(optimizer, class_to_monitor, strong_y_true, strong_pred, filenames, method=\"threshold\"):\n",
    "    class_wise_results = {}\n",
    "    \n",
    "    for cl in class_to_monitor:\n",
    "        optimizer.fit(\n",
    "            strong_y_true, strong_pred, filenames,\n",
    "            monitor=[\"class_wise\", cl, \"f_measure\", \"f_measure\"],\n",
    "            method=method,\n",
    "            verbose=1)\n",
    "        \n",
    "        parameters, score = optimizer.best\n",
    "        print(cl, parameters, score)\n",
    "        class_wise_results[cl] = (parameters, score)\n",
    "        \n",
    "    return class_wise_results\n",
    "\n",
    "\n",
    "def get_class_dependant_parameters(class_wise_results, class_list):\n",
    "    class_dependant_parameters = {}\n",
    "    for cl in class_list:\n",
    "        for param in class_wise_results[cl][0]:\n",
    "            if param not in class_dependant_parameters.keys():\n",
    "                class_dependant_parameters[param] = []\n",
    "            class_dependant_parameters[param].append(class_wise_results[cl][0][param])\n",
    "            \n",
    "    # TODO find better way\n",
    "    # for \"smooth\" common parameters, remove list\n",
    "    class_dependant_parameters[\"smooth\"] = class_dependant_parameters[\"smooth\"][0]\n",
    "    return class_dependant_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = list(DESEDManager.cls_dict.keys())\n",
    "\n",
    "# Create the encoder that will be used\n",
    "encoder = Encoder(\n",
    "    classes=class_list,\n",
    "    temporal_precision = 50,  # ms\n",
    "    clip_length = 10,          # s\n",
    "    minimal_segment_step = 150 # ms\n",
    ")\n",
    "\n",
    "val_csv_y_true= load_csv(os.path.join(desed_metadata_root, \"validation\", \"validation.tsv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = DichotomicOptimizer(\n",
    "    {\n",
    "        \"threshold\": (0.01, 0.90),\n",
    "        \"smooth\": \"smoothMovingAvg\",\n",
    "        \"window_len\": (5, 27)\n",
    "    },\n",
    "    \n",
    "    encoder = encoder,\n",
    "    step = 6,\n",
    "    nb_recurse = 8,\n",
    "    nb_process = 5\n",
    ")\n",
    "\n",
    "class_wise_results = class_wise_optimization(\n",
    "    optimizer,\n",
    "    class_list,\n",
    "    method=\"threshold\",\n",
    "    strong_y_true=val_csv_y_true,\n",
    "    strong_pred=pruned_strong_y_pred.numpy(),\n",
    "    filenames=y_filenames\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T05:49:07.672707Z",
     "start_time": "2019-06-06T05:49:07.615719Z"
    }
   },
   "outputs": [],
   "source": [
    "best_parameters = get_class_dependant_parameters(class_wise_results, class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold      : [0.8077932007619048, 0.787688, 0.36812160000000005, 0.9, 0.35367360000000003, 0.23318249472000002, 0.01571766857142857, 0.011932665904761905, 0.22503004160000004, 0.5921951809015873]\n",
      "smooth         : smoothMovingAvg\n",
      "window_len     : [8.697109942857143, 11.803439999999998, 13.946666666666667, 9.853818294857142, 27.0, 8.683605333333334, 26.035776, 27.0, 20.918436266666667, 27.0]\n"
     ]
    }
   ],
   "source": [
    "for key, value in best_parameters.items():\n",
    "    print(\"{:<15}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T05:49:28.567651Z",
     "start_time": "2019-06-06T05:49:09.882468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event based metrics (onset-offset)\n",
      "========================================\n",
      "  Evaluated length                  : 10459.12 sec\n",
      "  Evaluated files                   : 1168 \n",
      "  Evaluate onset                    : True \n",
      "  Evaluate offset                   : True \n",
      "  T collar                          : 200.00 ms\n",
      "  Offset (length)                   : 20.00 %\n",
      "\n",
      "  Overall metrics (micro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 26.02 %\n",
      "    Precision                       : 30.80 %\n",
      "    Recall                          : 22.52 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 1.26 \n",
      "    Substitution rate               : 0.02 \n",
      "    Deletion rate                   : 0.76 \n",
      "    Insertion rate                  : 0.49 \n",
      "\n",
      "  Class-wise average metrics (macro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 25.43 %\n",
      "    Precision                       : 28.03 %\n",
      "    Recall                          : 23.87 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 1.43 \n",
      "    Deletion rate                   : 0.76 \n",
      "    Insertion rate                  : 0.67 \n",
      "  \n",
      "\n",
      "  Class-wise metrics\n",
      "  ======================================\n",
      "    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n",
      "    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n",
      "    Alarm_bell.. | 420     310   | 32.6%    38.4%    28.3%  | 1.17     0.72     0.45   |\n",
      "    Blender      | 96      77    | 13.9%    15.6%    12.5%  | 1.55     0.88     0.68   |\n",
      "    Cat          | 341     331   | 24.7%    25.1%    24.3%  | 1.48     0.76     0.73   |\n",
      "    Dishes       | 567     376   | 18.7%    23.4%    15.5%  | 1.35     0.84     0.51   |\n",
      "    Dog          | 570     396   | 16.1%    19.7%    13.7%  | 1.42     0.86     0.56   |\n",
      "    Electric_s.. | 65      55    | 36.7%    40.0%    33.8%  | 1.17     0.66     0.51   |\n",
      "    Frying       | 94      155   | 8.0%     6.5%     10.6%  | 2.44     0.89     1.54   |\n",
      "    Running_wa.. | 237     221   | 25.8%    26.7%    24.9%  | 1.43     0.75     0.68   |\n",
      "    Speech       | 1754    1072  | 30.9%    40.8%    24.9%  | 1.11     0.75     0.36   |\n",
      "    Vacuum_cle.. | 92      104   | 46.9%    44.2%    50.0%  | 1.13     0.50     0.63   |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check test\n",
    "best_parameters = get_class_dependant_parameters(class_wise_results, class_list)\n",
    "\n",
    "segments = encoder.encode(\n",
    "    pruned_strong_y_pred.numpy(),\n",
    "    method=\"threshold\",\n",
    "    **best_parameters\n",
    ")\n",
    "to_evaluate = encoder.parse(segments, y_filenames)\n",
    "evaluator = eb_evaluator(val_csv_y_true, to_evaluate)\n",
    "print(evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hysteresis thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T23:35:34.068674Z",
     "start_time": "2019-06-05T18:50:30.082131Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1728 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/users/samova/lcances/.miniconda3/envs/dcase2020/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/users/samova/lcances/.miniconda3/envs/dcase2020/lib/python3.7/site-packages/aeseg/optimizers.py\", line 41, in evaluate\n  File \"/users/samova/lcances/.miniconda3/envs/dcase2020/lib/python3.7/site-packages/aeseg/Encoder.py\", line 130, in encode\n  File \"/users/samova/lcances/.miniconda3/envs/dcase2020/lib/python3.7/site-packages/aeseg/Encoder.py\", line 331, in __encode_using_hysteresis\nIndexError: list index out of range\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-241-089057c9d575>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mstrong_y_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrong_y_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mstrong_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpruned_strong_y_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-211-0c27c2b1bfb8>\u001b[0m in \u001b[0;36mclass_wise_optimization\u001b[0;34m(optimizer, class_to_monitor, strong_y_true, strong_pred, filenames, method)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class_wise\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f_measure\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f_measure\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             verbose=1)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/dcase2020/lib/python3.7/site-packages/aeseg/optimizers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y_true, y_pred, filenames, monitor, verbose, method)\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/dcase2020/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Perform the optimization ON TEST\n",
    "# Create the optimizer\n",
    "optimizer = DichotomicOptimizer(\n",
    "    {\n",
    "        \"high\": (0.01, 0.99),\n",
    "        \"low\": (0.01, 0.99),\n",
    "#         \"smooth\": \"smoothMovingAvg\",\n",
    "        \"window_len\": (3, 27)\n",
    "    },\n",
    "    \n",
    "    encoder = encoder,\n",
    "    step = 6,\n",
    "    nb_recurse = 8,\n",
    "    nb_process = 5\n",
    ")\n",
    "\n",
    "class_wise_results = class_wise_optimization(\n",
    "    optimizer,\n",
    "    class_list,\n",
    "    method=\"hysteresis\",\n",
    "    strong_y_true=strong_y_true,\n",
    "    strong_pred=pruned_strong_y_pred.numpy(),\n",
    "    filenames=y_filenames\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T05:49:07.672707Z",
     "start_time": "2019-06-06T05:49:07.615719Z"
    }
   },
   "outputs": [],
   "source": [
    "best_parameters = get_class_dependant_parameters(class_wise_results, class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T05:49:28.567651Z",
     "start_time": "2019-06-06T05:49:09.882468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event based metrics (onset-offset)\n",
      "========================================\n",
      "  Evaluated length                  : 10161.15 sec\n",
      "  Evaluated files                   : 1168 \n",
      "  Evaluate onset                    : True \n",
      "  Evaluate offset                   : True \n",
      "  T collar                          : 200.00 ms\n",
      "  Offset (length)                   : 20.00 %\n",
      "\n",
      "  Overall metrics (micro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 36.63 %\n",
      "    Precision                       : 40.38 %\n",
      "    Recall                          : 33.52 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 1.13 \n",
      "    Substitution rate               : 0.03 \n",
      "    Deletion rate                   : 0.64 \n",
      "    Insertion rate                  : 0.47 \n",
      "\n",
      "  Class-wise average metrics (macro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 37.88 %\n",
      "    Precision                       : 39.53 %\n",
      "    Recall                          : 36.98 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 1.21 \n",
      "    Deletion rate                   : 0.63 \n",
      "    Insertion rate                  : 0.58 \n",
      "  \n",
      "\n",
      "  Class-wise metrics\n",
      "  ======================================\n",
      "    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n",
      "    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n",
      "    Alarm_bell.. | 418     326   | 39.2%    44.8%    34.9%  | 1.08     0.65     0.43   |\n",
      "    Blender      | 96      115   | 35.1%    32.2%    38.5%  | 1.43     0.61     0.81   |\n",
      "    Cat          | 340     272   | 41.5%    46.7%    37.4%  | 1.05     0.63     0.43   |\n",
      "    Dishes       | 492     386   | 27.6%    31.3%    24.6%  | 1.29     0.75     0.54   |\n",
      "    Dog          | 577     387   | 18.7%    23.3%    15.6%  | 1.36     0.84     0.51   |\n",
      "    Electric_s.. | 65      68    | 43.6%    42.6%    44.6%  | 1.15     0.55     0.60   |\n",
      "    Frying       | 91      101   | 34.4%    32.7%    36.3%  | 1.38     0.64     0.75   |\n",
      "    Running_wa.. | 230     300   | 27.5%    24.3%    31.7%  | 1.67     0.68     0.99   |\n",
      "    Speech       | 1662    1328  | 43.1%    48.5%    38.7%  | 1.02     0.61     0.41   |\n",
      "    Vacuum_cle.. | 92      90    | 68.1%    68.9%    67.4%  | 0.63     0.33     0.30   |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check test\n",
    "best_parameters = get_class_dependant_parameters(class_wise_results, class_list)\n",
    "\n",
    "segments = encoder.encode(\n",
    "    val_strong_pred,\n",
    "    method=\"hysteresis\",\n",
    "    **best_parameters\n",
    ")\n",
    "to_evaluate = encoder.parse(segments, val_filenames)\n",
    "evaluator = eb_evaluator(val_csv_y_true, to_evaluate)\n",
    "print(evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ♫♪.ılılıll|̲̅̅●̲̅̅|̲̅̅=̲̅̅|̲̅̅●̲̅̅|llılılı.♫♪"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcase2020",
   "language": "python",
   "name": "dcase2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
