{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%% Import\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# dataset manager\n",
    "from dcase2020.datasetManager import DESEDManager\n",
    "from dcase2020.datasets import DESEDDataset\n",
    "\n",
    "# utility function & metrics & augmentation\n",
    "from metric_utils.metrics import FScore, BinaryAccuracy\n",
    "from dcase2020_task4.util.utils import get_datetime, reset_seed\n",
    "\n",
    "# models\n",
    "from dcase2020_task4.dcase2019.models import dcase2019_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ==== set the log ====\n",
    "import logging\n",
    "import logging.config\n",
    "from dcase2020.util.log import DEFAULT_LOGGING\n",
    "logging.config.dictConfig(DEFAULT_LOGGING)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ==== reset the seed for reproductability ====\n",
    "reset_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mDEBUG --- datasetManager.__init__ >>> ../dataset/DESED/dataset/audio/dcase2020_dataset_22050.hdf5\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._load_metadata >>> Reading metadata: ../dataset/DESED/dataset/metadata/train/weak.tsv\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._load_metadata >>> Reading metadata: ../dataset/DESED/dataset/metadata/train/unlabel_in_domain.tsv\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._load_metadata >>> Reading metadata: ../dataset/DESED/dataset/metadata/train/synthetic20.tsv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7582/7582 [00:16<00:00, 456.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# ==== load the dataset ====\n",
    "desed_metadata_root = \"../dataset/DESED/dataset/metadata\"\n",
    "desed_audio_root = \"../dataset/DESED/dataset/audio\"\n",
    "# desed_metadata_root = os.path.join(\"e:/\", \"Corpus\", \"dcase2020\", \"DESED\", \"dataset\", \"metadata\")\n",
    "# desed_audio_root = os.path.join(\"e:/\", \"Corpus\", \"dcase2020\", \"DESED\", \"dataset\", \"audio\")\n",
    "\n",
    "manager = DESEDManager(\n",
    "    desed_metadata_root, desed_audio_root,\n",
    "    sampling_rate = 22050,\n",
    "    validation_ratio=0.2,\n",
    "    from_disk=False,\n",
    "    nb_vector_bin=431, # there is no temporal reduction in this model\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add weak ans synthetic20 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37mINFO --- datasetManager.add_subset >>> Loading dataset: train, subset: weak\u001b[0m\n",
      "Loading dataset: train, subset: weak\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> hdf_file: <HDF5 file \"dcase2020_dataset_22050.hdf5\" (mode r)>\u001b[0m\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> path: DESED/dataset/audio/train/weak\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager.add_subset >>> Loading dataset: train, subset: synthetic20\u001b[0m\n",
      "Loading dataset: train, subset: synthetic20\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> hdf_file: <HDF5 file \"dcase2020_dataset_22050.hdf5\" (mode r)>\u001b[0m\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> path: DESED/dataset/audio/train/synthetic20\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "manager.add_subset(\"weak\")\n",
    "manager.add_subset(\"synthetic20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the train / validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37mINFO --- datasetManager.split_train_validation >>> Creating new train / validation split\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager.split_train_validation >>> validation ratio : 0.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "manager.split_train_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%  setup augmentation and create pytorch dataset\n"
    }
   },
   "outputs": [],
   "source": [
    "augments = [\n",
    "    # signal_augmentation.Noise(0.5, target_snr=15),\n",
    "    # signal_augmentation.RandomTimeDropout(0.5, dropout=0.2)\n",
    "]\n",
    "\n",
    "train_dataset = DESEDDataset(manager, train=True, val=False, augments=augments, cached=True)\n",
    "val_dataset = DESEDDataset(manager, train=False, val=True, augments=[], cached=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class MultipleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, datasets):\n",
    "        super(MultipleDataset, self).__init__()\n",
    "        assert len(datasets) > 0, 'datasets should not be an empty iterable'\n",
    "        self.datasets = list(datasets)\n",
    "        for d in self.datasets:\n",
    "            assert not isinstance(d, IterableDataset), \"ConcatDataset does not support IterableDataset\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datasets[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [d[sample_idx] for d in self.datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3218, 706)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.filenames), len(val_dataset.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep dataset\n",
    "\n",
    "- We want both the weak and strong ground truth --> the *weak* and *strong* parameters to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "augments = [\n",
    "    # signal_augmentation.Noise(0.5, target_snr=15),\n",
    "    # signal_augmentation.RandomTimeDropout(0.5, dropout=0.2)\n",
    "]\n",
    "\n",
    "train_dataset = DESEDDataset(manager, train=True, val=False, weak=True, strong=True, augments=augments, cached=True)\n",
    "val_dataset = DESEDDataset(manager, train=False, val=True, weak=True, strong=True, augments=[], cached=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model\n",
    "\n",
    "This model is the same than the weak baseline but have an extra output. <br />\n",
    "the loc_output is compose of a single convolution layer with nb_filters == nb_class. <br />\n",
    "Since their is some pooling layer, the *loc_ouput* have a precision of 53 bins (~= 18 ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Setup model and training parameters\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dcase2019_model(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLUPool(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout2d(p=0.0, inplace=False)\n",
       "      (3): ReLU6(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): ConvBNReLUPool(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout2d(p=0.0, inplace=False)\n",
       "      (3): ReLU6(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): ConvBNReLUPool(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout2d(p=0.0, inplace=False)\n",
       "      (3): ReLU6(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (bi_gru): GRU(64, 64, batch_first=True, bidirectional=True)\n",
       "  (strong_classifier): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       "  (g_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (g_max_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "  (weak_classifier): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "model = dcase2019_model()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n",
      "                                 Kernel Shape      Output Shape   Params  \\\n",
      "Layer                                                                      \n",
      "0_features.0.Conv2d_0           [1, 64, 3, 3]  [2, 64, 64, 431]    640.0   \n",
      "1_features.0.BatchNorm2d_1               [64]  [2, 64, 64, 431]    128.0   \n",
      "2_features.0.Dropout2d_2                    -  [2, 64, 64, 431]        -   \n",
      "3_features.0.ReLU6_3                        -  [2, 64, 64, 431]        -   \n",
      "4_features.0.MaxPool2d_4                    -  [2, 64, 16, 431]        -   \n",
      "5_features.1.Conv2d_0          [64, 64, 3, 3]  [2, 64, 16, 431]  36.928k   \n",
      "6_features.1.BatchNorm2d_1               [64]  [2, 64, 16, 431]    128.0   \n",
      "7_features.1.Dropout2d_2                    -  [2, 64, 16, 431]        -   \n",
      "8_features.1.ReLU6_3                        -  [2, 64, 16, 431]        -   \n",
      "9_features.1.MaxPool2d_4                    -   [2, 64, 4, 431]        -   \n",
      "10_features.2.Conv2d_0         [64, 64, 3, 3]   [2, 64, 4, 431]  36.928k   \n",
      "11_features.2.BatchNorm2d_1              [64]   [2, 64, 4, 431]    128.0   \n",
      "12_features.2.Dropout2d_2                   -   [2, 64, 4, 431]        -   \n",
      "13_features.2.ReLU6_3                       -   [2, 64, 4, 431]        -   \n",
      "14_features.2.MaxPool2d_4                   -   [2, 64, 1, 431]        -   \n",
      "15_bi_gru                                   -     [2, 431, 128]   49.92k   \n",
      "16_strong_classifier.Linear_0       [128, 64]      [2, 431, 64]   8.256k   \n",
      "17_strong_classifier.ReLU_1                 -      [2, 431, 64]        -   \n",
      "18_strong_classifier.Linear_2        [64, 10]      [2, 431, 10]    650.0   \n",
      "19_g_avg_pool                               -        [2, 10, 1]        -   \n",
      "20_g_max_pool                               -        [2, 10, 1]        -   \n",
      "21_weak_classifier.Linear_0        [20, 1024]         [2, 1024]  21.504k   \n",
      "22_weak_classifier.ReLU_1                   -         [2, 1024]        -   \n",
      "23_weak_classifier.Linear_2        [1024, 10]           [2, 10]   10.25k   \n",
      "\n",
      "                                 Mult-Adds  \n",
      "Layer                                       \n",
      "0_features.0.Conv2d_0           15.888384M  \n",
      "1_features.0.BatchNorm2d_1            64.0  \n",
      "2_features.0.Dropout2d_2                 -  \n",
      "3_features.0.ReLU6_3                     -  \n",
      "4_features.0.MaxPool2d_4                 -  \n",
      "5_features.1.Conv2d_0          254.214144M  \n",
      "6_features.1.BatchNorm2d_1            64.0  \n",
      "7_features.1.Dropout2d_2                 -  \n",
      "8_features.1.ReLU6_3                     -  \n",
      "9_features.1.MaxPool2d_4                 -  \n",
      "10_features.2.Conv2d_0          63.553536M  \n",
      "11_features.2.BatchNorm2d_1           64.0  \n",
      "12_features.2.Dropout2d_2                -  \n",
      "13_features.2.ReLU6_3                    -  \n",
      "14_features.2.MaxPool2d_4                -  \n",
      "15_bi_gru                          49.152k  \n",
      "16_strong_classifier.Linear_0       8.192k  \n",
      "17_strong_classifier.ReLU_1              -  \n",
      "18_strong_classifier.Linear_2        640.0  \n",
      "19_g_avg_pool                            -  \n",
      "20_g_max_pool                            -  \n",
      "21_weak_classifier.Linear_0         20.48k  \n",
      "22_weak_classifier.ReLU_1                -  \n",
      "23_weak_classifier.Linear_2         10.24k  \n",
      "-------------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params             165.46k\n",
      "Trainable params         165.46k\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             333.74496M\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "input_tensor = torch.zeros((2, 64, 431), dtype=torch.float)\n",
    "input_tensor = input_tensor.cuda()\n",
    "\n",
    "s = summary(model, input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom loss function\n",
    "\n",
    "Since not all file have strong truth, it is necessary to remove those files. <br />\n",
    "For that, the strong mask is computed. If the sum of the strong ground truth is equal to 0 then it is a fake one <br />\n",
    "This file strong loss must not be taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weak_synth_loss(logits_weak, logits_strong, y_weak, y_strong, reduce: str = \"mean\"):\n",
    "    assert reduce in [\"mean\", \"sum\"], \"support only \\\"mean\\\" and \\\"sum\\\"\"\n",
    "    \n",
    "    #  Reduction function\n",
    "    if reduce == \"mean\":\n",
    "        reduce_fn = torch.mean\n",
    "    elif reduce == \"sum\":\n",
    "        reduce_fn = torch.sum\n",
    "    \n",
    "    # based on Binary Cross Entropy loss\n",
    "    weak_criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    strong_criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    \n",
    "    # calc separate loss function\n",
    "    weak_bce = weak_criterion(logits_weak, y_weak)\n",
    "    strong_bce = strong_criterion(logits_strong, y_strong)\n",
    "    \n",
    "    weak_bce = reduce_fn(weak_bce, dim=1)\n",
    "    strong_bce = reduce_fn(strong_bce, dim=(1, 2))\n",
    "    \n",
    "    # calc strong mask\n",
    "    strong_mask = torch.clamp(torch.sum(y_strong, dim=(1, 2)), 0, 1) # vector of 0 or 1\n",
    "#     strong_mask = strong_mask.detach() # declared not to need gradients\n",
    "    \n",
    "    # Output the different loss for logging purpose\n",
    "    weak_loss = reduce_fn(weak_bce)\n",
    "    strong_loss = reduce_fn(strong_mask * strong_bce)\n",
    "    total_loss = reduce_fn(weak_bce + strong_mask * strong_bce)\n",
    "    \n",
    "    return weak_loss, strong_loss, total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters (crit & callbacks & loaders & metrics)m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Setup model and training parameters\n"
    }
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "nb_epochs = 100\n",
    "batch_size = 32\n",
    "nb_batch = len(train_dataset) // batch_size\n",
    "\n",
    "optimizers = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# callbacks\n",
    "callbacks = []\n",
    "\n",
    "# tensorboard\n",
    "title = \"WeakBaseline_%s\" % (get_datetime())\n",
    "tensorboard = SummaryWriter(log_dir=Path(\"../tensorboard/%s\" % title), comment=\"weak baseline\")\n",
    "\n",
    "# loaders\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Metrics\n",
    "weak_binacc_func = BinaryAccuracy()\n",
    "strong_binacc_func = BinaryAccuracy()\n",
    "weak_f_func = FScore()\n",
    "strong_f_func = FScore()\n",
    "metrics = [weak_binacc_func, strong_binacc_func, weak_f_func, strong_f_func]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_all_metrics(metrics):\n",
    "    for m in metrics:\n",
    "        m.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Epoch  - %      - Losses:  Weak  | Strong  | Total  - metrics:  Weak acc  | Strong acc  | Weak F1  | Strong F1  - Time  \n"
     ]
    }
   ],
   "source": [
    "UNDERLINE_SEQ = \"\\033[1;4m\"\n",
    "RESET_SEQ = \"\\033[0m\"\n",
    "\n",
    "header_form = \"{:<8.8} {:<6.6} - {:<6.6} - {:<8.8} {:<6.6}| {:<8.8}| {:<6.6} - {:<9.9} {:<10.10}| {:<12.12}| {:<9.9}| {:<11.11}- {:<6.6}\"\n",
    "\n",
    "value_form  = \"{:<8.8} {:<6} - {:<6} - {:<8.8} {:<6.4f}| {:<8.4f}| {:<6.4f} - {:<9.9} {:<10.4f}| {:<12.4f}| {:<9.4f}| {:<11.4f}- {:<6.4f}\"\n",
    "\n",
    "train_form = value_form\n",
    "val_form = UNDERLINE_SEQ + value_form + RESET_SEQ\n",
    "\n",
    "header = header_form.format(\n",
    "    \"\", \"Epoch\", \"%\", \"Losses:\", \"Weak \", \"Strong \", \"Total \", \"metrics: \", \"Weak acc \", \"Strong acc \", \"Weak F1 \", \"Strong F1\", \"Time\"\n",
    ")\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% training function\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch: int):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    reset_all_metrics(metrics)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"\") # <-- Force new line\n",
    "    \n",
    "    for i, (X, y) in enumerate(training_loader):\n",
    "        # The DESEDDataset return a list of ground truth depending on the selecting option.\n",
    "        # If weak and strong ground truth are selected, the list order is [WEAK, STRONG]\n",
    "        # here there is only one [WEAK]\n",
    "        X = X.cuda().float()\n",
    "        y_weak = y[0].cuda().float()\n",
    "        y_strong = y[1].cuda().float()\n",
    "        \n",
    "        weak_logits, strong_logits = model(X)\n",
    "        \n",
    "        # calc the loss\n",
    "        weak_loss, strong_loss, total_loss = weak_synth_loss(\n",
    "            weak_logits, strong_logits,\n",
    "            y_weak, y_strong,\n",
    "            reduce=\"mean\"\n",
    "        )\n",
    "        \n",
    "        # back propagation\n",
    "        optimizers.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizers.step()\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            # calc metrics\n",
    "            weak_pred = torch.sigmoid(weak_logits)\n",
    "            strong_pred = torch.sigmoid(strong_logits)\n",
    "\n",
    "            # tagging\n",
    "            weak_binacc = weak_binacc_func(weak_pred, y_weak)\n",
    "            weak_fscore = weak_f_func(weak_pred, y_weak)\n",
    "\n",
    "            # loc\n",
    "            strong_binacc = strong_binacc_func(strong_pred, y_strong)\n",
    "            strong_fscore = strong_f_func(strong_pred, y_strong)\n",
    "        \n",
    "            # logs\n",
    "            print(train_form.format(\n",
    "                \"Training: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / len(training_loader)),\n",
    "                \"\", weak_loss.item(), strong_loss.item(), total_loss.item(),\n",
    "                \"\", weak_binacc, strong_binacc, weak_fscore, strong_fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "        # tensorboard logs\n",
    "        tensorboard.add_scalar(\"train/weak_loss\", weak_loss.item(), epoch)\n",
    "        tensorboard.add_scalar(\"train/strong_loss\", strong_loss.item(), epoch)\n",
    "        tensorboard.add_scalar(\"train/total_loss\", total_loss.item(), epoch)\n",
    "\n",
    "        tensorboard.add_scalar(\"train/weak_acc\", weak_binacc, epoch)\n",
    "        tensorboard.add_scalar(\"train/strong_acc\", strong_binacc, epoch)\n",
    "        tensorboard.add_scalar(\"train/weak_f1\", weak_fscore, epoch)\n",
    "        tensorboard.add_scalar(\"train/strong_f1\", strong_fscore, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% validation function\n"
    }
   },
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    start_time = time.time()\n",
    "\n",
    "        \n",
    "    reset_all_metrics(metrics)\n",
    "    \n",
    "    model.eval()\n",
    "    print(\"\") # <-- Force new line\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(val_loader):\n",
    "            X = X.cuda().float()\n",
    "            y_weak = y[0].cuda().float()\n",
    "            y_strong = y[1].cuda().float()\n",
    "\n",
    "            weak_logits, strong_logits = model(X)\n",
    "\n",
    "            # calc the loss\n",
    "            weak_loss, strong_loss, total_loss = weak_synth_loss(\n",
    "                weak_logits, strong_logits,\n",
    "                y_weak, y_strong,\n",
    "                reduce=\"mean\"\n",
    "            )\n",
    "            \n",
    "             # calc metrics\n",
    "            weak_pred = torch.sigmoid(weak_logits)\n",
    "            strong_pred = torch.sigmoid(strong_logits)\n",
    "\n",
    "            # tagging\n",
    "            weak_binacc = weak_binacc_func(weak_pred, y_weak)\n",
    "            weak_fscore = weak_f_func(weak_pred, y_weak)\n",
    "\n",
    "            # loc\n",
    "            strong_binacc = strong_binacc_func(strong_pred, y_strong)\n",
    "            strong_fscore = strong_f_func(strong_pred, y_strong)\n",
    "\n",
    "            # logs\n",
    "            print(val_form.format(\n",
    "                \"Validation: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / len(val_loader)),\n",
    "                \"\", weak_loss.item(), strong_loss.item(), total_loss.item(),\n",
    "                \"\", weak_binacc, strong_binacc, weak_fscore, strong_fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "        # tensorboard logs\n",
    "        tensorboard.add_scalar(\"val/weak_loss\", weak_loss.item(), epoch)\n",
    "        tensorboard.add_scalar(\"val/strong_loss\", strong_loss.item(), epoch)\n",
    "        tensorboard.add_scalar(\"val/total_loss\", total_loss.item(), epoch)\n",
    "\n",
    "        tensorboard.add_scalar(\"val/weak_acc\", weak_binacc, epoch)\n",
    "        tensorboard.add_scalar(\"val/strong_acc\", strong_binacc, epoch)\n",
    "        tensorboard.add_scalar(\"val/weak_f1\", weak_fscore, epoch)\n",
    "        tensorboard.add_scalar(\"val/strong_f1\", strong_fscore, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Epoch  - %      - Losses:  Weak  | Strong  | Total  - metrics:  Weak acc  | Strong acc  | Weak F1  | Strong F1  - Time  \n",
      "\n",
      "Training 1      - 100    -          0.3545| 0.0826  | 0.4372 -           0.8337    | 0.9576      | 0.2799   | 0.0007     - 50.3332\n",
      "\u001b[1;4mValidati 1      - 100    -          0.4430| 0.2166  | 0.6596 -           0.8380    | 0.9652      | 0.2862   | 0.0289     - 10.1444\u001b[0m\n",
      "Training 2      - 100    -          0.3089| 0.0893  | 0.3982 -           0.8448    | 0.9604      | 0.3519   | 0.1045     - 6.1374\n",
      "\u001b[1;4mValidati 2      - 100    -          0.6919| 0.2321  | 0.9240 -           0.8457    | 0.9571      | 0.4133   | 0.1789     - 0.5163\u001b[0m\n",
      "Training 3      - 100    -          0.3450| 0.1278  | 0.4729 -           0.8636    | 0.9639      | 0.4285   | 0.2327     - 6.0882\n",
      "\u001b[1;4mValidati 3      - 100    -          0.4698| 0.2540  | 0.7237 -           0.8605    | 0.9568      | 0.4266   | 0.2237     - 0.5282\u001b[0m\n",
      "Training 4      - 100    -          0.2743| 0.0455  | 0.3198 -           0.8760    | 0.9583      | 0.5140   | 0.3180     - 6.0607\n",
      "\u001b[1;4mValidati 4      - 100    -          0.3831| 0.2635  | 0.6467 -           0.8644    | 0.9540      | 0.4651   | 0.2876     - 0.5144\u001b[0m\n",
      "Training 5      - 100    -          0.2258| 0.0559  | 0.2817 -           0.8899    | 0.9566      | 0.6037   | 0.3484     - 6.0632\n",
      "\u001b[1;4mValidati 5      - 100    -          0.4658| 0.2603  | 0.7261 -           0.8792    | 0.9553      | 0.5184   | 0.2860     - 0.5151\u001b[0m\n",
      "Training 6      - 100    -          0.2214| 0.0713  | 0.2928 -           0.9019    | 0.9575      | 0.6628   | 0.3797     - 6.0573\n",
      "\u001b[1;4mValidati 6      - 100    -          0.4168| 0.2254  | 0.6423 -           0.8992    | 0.9625      | 0.6292   | 0.3445     - 0.5125\u001b[0m\n",
      "Training 7      - 100    -          0.2793| 0.0680  | 0.3474 -           0.9127    | 0.9576      | 0.7092   | 0.4085     - 6.0446\n",
      "\u001b[1;4mValidati 7      - 100    -          0.4254| 0.2285  | 0.6539 -           0.9064    | 0.9579      | 0.6874   | 0.3809     - 0.5212\u001b[0m\n",
      "Training 8      - 100    -          0.2500| 0.0906  | 0.3405 -           0.9226    | 0.9565      | 0.7481   | 0.4260     - 6.2014\n",
      "\u001b[1;4mValidati 8      - 100    -          0.4430| 0.2468  | 0.6898 -           0.8976    | 0.9527      | 0.6326   | 0.3652     - 0.5392\u001b[0m\n",
      "Training 9      - 100    -          0.1076| 0.0557  | 0.1633 -           0.9263    | 0.9578      | 0.7630   | 0.4451     - 6.0921\n",
      "\u001b[1;4mValidati 9      - 100    -          0.4121| 0.2068  | 0.6189 -           0.9295    | 0.9583      | 0.7766   | 0.4298     - 0.5237\u001b[0m\n",
      "Training 10     - 100    -          0.1389| 0.0487  | 0.1876 -           0.9338    | 0.9592      | 0.7891   | 0.4659     - 6.1789\n",
      "\u001b[1;4mValidati 10     - 100    -          0.4280| 0.2026  | 0.6306 -           0.9177    | 0.9590      | 0.7385   | 0.4065     - 0.5320\u001b[0m\n",
      "Training 11     - 100    -          0.2146| 0.0556  | 0.2702 -           0.9348    | 0.9584      | 0.7938   | 0.4686     - 6.2011\n",
      "\u001b[1;4mValidati 11     - 100    -          0.4591| 0.2125  | 0.6716 -           0.9333    | 0.9604      | 0.7863   | 0.4369     - 0.5346\u001b[0m\n",
      "Training 12     - 100    -          0.2312| 0.0676  | 0.2988 -           0.9406    | 0.9593      | 0.8150   | 0.4877     - 6.4768\n",
      "\u001b[1;4mValidati 12     - 100    -          0.4326| 0.2120  | 0.6447 -           0.9230    | 0.9567      | 0.7544   | 0.4250     - 0.5232\u001b[0m\n",
      "Training 13     - 100    -          0.0758| 0.0363  | 0.1121 -           0.9455    | 0.9595      | 0.8308   | 0.5000     - 6.1555\n",
      "\u001b[1;4mValidati 13     - 100    -          0.3982| 0.2083  | 0.6065 -           0.9251    | 0.9627      | 0.7676   | 0.4434     - 0.5343\u001b[0m\n",
      "Training 14     - 100    -          0.1101| 0.0570  | 0.1672 -           0.9472    | 0.9601      | 0.8366   | 0.5010     - 6.2437\n",
      "\u001b[1;4mValidati 14     - 100    -          0.4848| 0.2019  | 0.6867 -           0.9295    | 0.9644      | 0.7857   | 0.4455     - 0.5344\u001b[0m\n",
      "Training 15     - 100    -          0.1118| 0.0599  | 0.1717 -           0.9515    | 0.9612      | 0.8508   | 0.5186     - 6.2325\n",
      "\u001b[1;4mValidati 15     - 100    -          0.4341| 0.2246  | 0.6587 -           0.9356    | 0.9642      | 0.8098   | 0.4714     - 0.5353\u001b[0m\n",
      "Training 16     - 100    -          0.1352| 0.0549  | 0.1901 -           0.9538    | 0.9614      | 0.8589   | 0.5268     - 6.3331\n",
      "\u001b[1;4mValidati 16     - 100    -          0.4026| 0.1971  | 0.5997 -           0.9416    | 0.9606      | 0.8196   | 0.4794     - 0.5506\u001b[0m\n",
      "Training 17     - 100    -          0.1365| 0.0311  | 0.1676 -           0.9523    | 0.9620      | 0.8541   | 0.5332     - 6.2661\n",
      "\u001b[1;4mValidati 17     - 100    -          0.3883| 0.2076  | 0.5959 -           0.9371    | 0.9595      | 0.7957   | 0.4768     - 0.5486\u001b[0m\n",
      "Training 18     - 100    -          0.0811| 0.0475  | 0.1287 -           0.9568    | 0.9629      | 0.8682   | 0.5421     - 6.2744\n",
      "\u001b[1;4mValidati 18     - 100    -          0.4593| 0.2073  | 0.6666 -           0.9329    | 0.9633      | 0.7739   | 0.4825     - 0.5420\u001b[0m\n",
      "Training 19     - 100    -          0.0394| 0.0312  | 0.0706 -           0.9613    | 0.9634      | 0.8830   | 0.5540     - 6.2079\n",
      "\u001b[1;4mValidati 19     - 100    -          0.3954| 0.2039  | 0.5993 -           0.9341    | 0.9551      | 0.7901   | 0.4463     - 0.5577\u001b[0m\n",
      "Training 20     - 100    -          0.1000| 0.0517  | 0.1517 -           0.9622    | 0.9636      | 0.8851   | 0.5567     - 6.3328\n",
      "\u001b[1;4mValidati 20     - 100    -          0.4173| 0.2061  | 0.6234 -           0.9375    | 0.9658      | 0.7980   | 0.4841     - 0.5389\u001b[0m\n",
      "Training 21     - 100    -          0.0887| 0.0342  | 0.1230 -           0.9616    | 0.9627      | 0.8837   | 0.5544     - 6.3676\n",
      "\u001b[1;4mValidati 21     - 100    -          0.4388| 0.1967  | 0.6355 -           0.8880    | 0.9569      | 0.6621   | 0.3489     - 0.5638\u001b[0m\n",
      "Training 22     - 100    -          0.1442| 0.0162  | 0.1603 -           0.9663    | 0.9639      | 0.8977   | 0.5622     - 6.6516\n",
      "\u001b[1;4mValidati 22     - 100    -          0.4046| 0.1985  | 0.6030 -           0.9439    | 0.9648      | 0.8281   | 0.5073     - 0.5576\u001b[0m\n",
      "Training 23     - 100    -          0.0500| 0.0244  | 0.0745 -           0.9669    | 0.9635      | 0.8995   | 0.5579     - 6.3478\n",
      "\u001b[1;4mValidati 23     - 100    -          0.4217| 0.2121  | 0.6338 -           0.9420    | 0.9592      | 0.8181   | 0.4877     - 0.5582\u001b[0m\n",
      "Training 24     - 100    -          0.0589| 0.0123  | 0.0712 -           0.9675    | 0.9637      | 0.9018   | 0.5653     - 6.3166\n",
      "\u001b[1;4mValidati 24     - 100    -          0.4225| 0.2317  | 0.6542 -           0.9450    | 0.9612      | 0.8310   | 0.5058     - 0.5430\u001b[0m\n",
      "Training 25     - 100    -          0.0805| 0.0363  | 0.1168 -           0.9649    | 0.9635      | 0.8945   | 0.5664     - 6.2871\n",
      "\u001b[1;4mValidati 25     - 100    -          0.4417| 0.1965  | 0.6383 -           0.9462    | 0.9642      | 0.8132   | 0.5071     - 0.5694\u001b[0m\n",
      "Training 26     - 100    -          0.1136| 0.0446  | 0.1583 -           0.9706    | 0.9642      | 0.9116   | 0.5733     - 6.4003\n",
      "\u001b[1;4mValidati 26     - 100    -          0.4271| 0.2141  | 0.6412 -           0.9219    | 0.9478      | 0.7563   | 0.3873     - 0.5536\u001b[0m\n",
      "Training 27     - 100    -          0.0750| 0.0433  | 0.1183 -           0.9708    | 0.9636      | 0.9122   | 0.5697     - 6.3928\n",
      "\u001b[1;4mValidati 27     - 100    -          0.4466| 0.2017  | 0.6484 -           0.9433    | 0.9627      | 0.8050   | 0.5022     - 0.5408\u001b[0m\n",
      "Training 28     - 100    -          0.0718| 0.0409  | 0.1127 -           0.9719    | 0.9646      | 0.9155   | 0.5773     - 6.2424\n",
      "\u001b[1;4mValidati 28     - 100    -          0.4002| 0.2136  | 0.6138 -           0.9446    | 0.9597      | 0.8279   | 0.4923     - 0.5354\u001b[0m\n",
      "Training 29     - 100    -          0.0483| 0.0168  | 0.0650 -           0.9757    | 0.9640      | 0.9275   | 0.5766     - 6.4398\n",
      "\u001b[1;4mValidati 29     - 100    -          0.3937| 0.2292  | 0.6229 -           0.9455    | 0.9636      | 0.8317   | 0.5049     - 0.5428\u001b[0m\n",
      "Training 30     - 100    -          0.1501| 0.0381  | 0.1882 -           0.9729    | 0.9642      | 0.9187   | 0.5764     - 6.3269\n",
      "\u001b[1;4mValidati 30     - 100    -          0.4435| 0.2072  | 0.6507 -           0.9363    | 0.9641      | 0.7863   | 0.5138     - 0.5549\u001b[0m\n",
      "Training 31     - 100    -          0.0527| 0.0228  | 0.0755 -           0.9734    | 0.9645      | 0.9202   | 0.5805     - 6.3060\n",
      "\u001b[1;4mValidati 31     - 100    -          0.4174| 0.2188  | 0.6362 -           0.9474    | 0.9652      | 0.8350   | 0.5064     - 0.5390\u001b[0m\n",
      "Training 32     - 100    -          0.1027| 0.0392  | 0.1419 -           0.9760    | 0.9645      | 0.9285   | 0.5823     - 6.4485\n",
      "\u001b[1;4mValidati 32     - 100    -          0.3824| 0.1939  | 0.5763 -           0.9417    | 0.9624      | 0.8226   | 0.4970     - 0.5604\u001b[0m\n",
      "Training 33     - 100    -          0.0548| 0.0411  | 0.0960 -           0.9744    | 0.9629      | 0.9231   | 0.5710     - 6.5600\n",
      "\u001b[1;4mValidati 33     - 100    -          0.4204| 0.1960  | 0.6164 -           0.9398    | 0.9577      | 0.8104   | 0.4706     - 0.5403\u001b[0m\n",
      "Training 34     - 100    -          0.0975| 0.0922  | 0.1897 -           0.9743    | 0.9632      | 0.9230   | 0.5695     - 6.3470\n",
      "\u001b[1;4mValidati 34     - 100    -          0.4139| 0.2208  | 0.6347 -           0.9374    | 0.9620      | 0.8060   | 0.4890     - 0.5370\u001b[0m\n",
      "Training 35     - 100    -          0.0322| 0.0207  | 0.0529 -           0.9761    | 0.9652      | 0.9283   | 0.5872     - 6.4498\n",
      "\u001b[1;4mValidati 35     - 100    -          0.4138| 0.2251  | 0.6389 -           0.9424    | 0.9649      | 0.8213   | 0.4996     - 0.5518\u001b[0m\n",
      "Training 36     - 100    -          0.0458| 0.0194  | 0.0652 -           0.9786    | 0.9661      | 0.9360   | 0.5979     - 6.3954\n",
      "\u001b[1;4mValidati 36     - 100    -          0.4080| 0.1966  | 0.6045 -           0.9433    | 0.9652      | 0.8220   | 0.4932     - 0.5375\u001b[0m\n",
      "Training 37     - 100    -          0.0547| 0.0440  | 0.0987 -           0.9787    | 0.9655      | 0.9363   | 0.5910     - 6.3862\n",
      "\u001b[1;4mValidati 37     - 100    -          0.4038| 0.2216  | 0.6254 -           0.9389    | 0.9629      | 0.8183   | 0.5112     - 0.5435\u001b[0m\n",
      "Training 38     - 100    -          0.0952| 0.0483  | 0.1435 -           0.9809    | 0.9655      | 0.9435   | 0.5974     - 6.2267\n",
      "\u001b[1;4mValidati 38     - 100    -          0.4613| 0.2071  | 0.6684 -           0.9485    | 0.9630      | 0.8407   | 0.5138     - 0.5563\u001b[0m\n",
      "Training 39     - 100    -          0.0890| 0.0338  | 0.1227 -           0.9807    | 0.9651      | 0.9425   | 0.5916     - 6.3779\n",
      "\u001b[1;4mValidati 39     - 100    -          0.4044| 0.2208  | 0.6252 -           0.9276    | 0.9636      | 0.7757   | 0.4610     - 0.5393\u001b[0m\n",
      "Training 40     - 100    -          0.0387| 0.0312  | 0.0699 -           0.9750    | 0.9655      | 0.9243   | 0.5852     - 6.2761\n",
      "\u001b[1;4mValidati 40     - 100    -          0.4253| 0.2153  | 0.6407 -           0.9452    | 0.9628      | 0.8328   | 0.5193     - 0.5402\u001b[0m\n",
      "Training 41     - 100    -          0.0358| 0.0147  | 0.0506 -           0.9795    | 0.9651      | 0.9389   | 0.5919     - 6.3294\n",
      "\u001b[1;4mValidati 41     - 100    -          0.4057| 0.2204  | 0.6261 -           0.9440    | 0.9625      | 0.8264   | 0.5109     - 0.5479\u001b[0m\n",
      "Training 42     - 100    -          0.0353| 0.0303  | 0.0656 -           0.9799    | 0.9654      | 0.9402   | 0.5951     - 6.2241\n",
      "\u001b[1;4mValidati 42     - 100    -          0.3539| 0.2156  | 0.5695 -           0.9484    | 0.9651      | 0.8376   | 0.5059     - 0.5535\u001b[0m\n",
      "Training 43     - 100    -          0.0933| 0.0301  | 0.1234 -           0.9816    | 0.9656      | 0.9456   | 0.5990     - 6.2745\n",
      "\u001b[1;4mValidati 43     - 100    -          0.4222| 0.2131  | 0.6353 -           0.9492    | 0.9678      | 0.8412   | 0.5122     - 0.5667\u001b[0m\n",
      "Training 44     - 100    -          0.0258| 0.0360  | 0.0618 -           0.9810    | 0.9661      | 0.9431   | 0.6015     - 6.6170\n",
      "\u001b[1;4mValidati 44     - 100    -          0.4201| 0.1880  | 0.6081 -           0.9493    | 0.9657      | 0.8431   | 0.5211     - 0.5513\u001b[0m\n",
      "Training 45     - 100    -          0.0228| 0.0180  | 0.0408 -           0.9864    | 0.9653      | 0.9596   | 0.6016     - 6.3338\n",
      "\u001b[1;4mValidati 45     - 100    -          0.4004| 0.2026  | 0.6030 -           0.9401    | 0.9586      | 0.8204   | 0.5119     - 0.5606\u001b[0m\n",
      "Training 46     - 100    -          0.0428| 0.0202  | 0.0630 -           0.9821    | 0.9660      | 0.9464   | 0.6022     - 6.5802\n",
      "\u001b[1;4mValidati 46     - 100    -          0.4604| 0.2240  | 0.6845 -           0.9376    | 0.9674      | 0.7860   | 0.4871     - 0.5409\u001b[0m\n",
      "Training 47     - 100    -          0.0249| 0.0138  | 0.0388 -           0.9820    | 0.9663      | 0.9461   | 0.6001     - 6.2613\n",
      "\u001b[1;4mValidati 47     - 100    -          0.3841| 0.2038  | 0.5879 -           0.9471    | 0.9619      | 0.8390   | 0.5225     - 0.5360\u001b[0m\n",
      "Training 48     - 100    -          0.0800| 0.0161  | 0.0961 -           0.9867    | 0.9660      | 0.9603   | 0.6064     - 6.2746\n",
      "\u001b[1;4mValidati 48     - 100    -          0.4330| 0.2036  | 0.6367 -           0.9416    | 0.9606      | 0.8008   | 0.5120     - 0.5354\u001b[0m\n",
      "Training 49     - 100    -          0.0065| 0.0119  | 0.0184 -           0.9846    | 0.9656      | 0.9547   | 0.6018     - 6.2195\n",
      "\u001b[1;4mValidati 49     - 100    -          0.3718| 0.1990  | 0.5708 -           0.9442    | 0.9608      | 0.8310   | 0.5213     - 0.5420\u001b[0m\n",
      "Training 50     - 100    -          0.0700| 0.0342  | 0.1042 -           0.9852    | 0.9657      | 0.9560   | 0.6030     - 6.2635\n",
      "\u001b[1;4mValidati 50     - 100    -          0.4138| 0.2253  | 0.6391 -           0.9401    | 0.9601      | 0.8176   | 0.5223     - 0.5571\u001b[0m\n",
      "Training 51     - 100    -          0.0578| 0.0334  | 0.0912 -           0.9833    | 0.9661      | 0.9503   | 0.6052     - 6.3480\n",
      "\u001b[1;4mValidati 51     - 100    -          0.4096| 0.1969  | 0.6064 -           0.9476    | 0.9635      | 0.8401   | 0.5183     - 0.5366\u001b[0m\n",
      "Training 52     - 100    -          0.0101| 0.0418  | 0.0519 -           0.9856    | 0.9660      | 0.9574   | 0.6064     - 6.2685\n",
      "\u001b[1;4mValidati 52     - 100    -          0.4283| 0.2026  | 0.6309 -           0.9482    | 0.9655      | 0.8418   | 0.5274     - 0.5362\u001b[0m\n",
      "Training 53     - 100    -          0.0620| 0.0511  | 0.1131 -           0.9855    | 0.9654      | 0.9567   | 0.5991     - 6.1738\n",
      "\u001b[1;4mValidati 53     - 100    -          0.3858| 0.2153  | 0.6011 -           0.9486    | 0.9626      | 0.8407   | 0.5125     - 0.5448\u001b[0m\n",
      "Training 54     - 100    -          0.0281| 0.0255  | 0.0536 -           0.9830    | 0.9661      | 0.9493   | 0.6071     - 6.6443\n",
      "\u001b[1;4mValidati 54     - 100    -          0.4298| 0.2430  | 0.6728 -           0.9455    | 0.9635      | 0.8326   | 0.5131     - 0.5444\u001b[0m\n",
      "Training 55     - 100    -          0.0825| 0.0143  | 0.0968 -           0.9837    | 0.9660      | 0.9519   | 0.6079     - 6.1657\n",
      "\u001b[1;4mValidati 55     - 100    -          0.4214| 0.2071  | 0.6284 -           0.9497    | 0.9667      | 0.8427   | 0.5140     - 0.5314\u001b[0m\n",
      "Training 56     - 100    -          0.0097| 0.0175  | 0.0272 -           0.9849    | 0.9656      | 0.9553   | 0.6032     - 6.2448\n",
      "\u001b[1;4mValidati 56     - 100    -          0.4400| 0.2190  | 0.6590 -           0.9389    | 0.9613      | 0.8121   | 0.4953     - 0.5543\u001b[0m\n",
      "Training 57     - 100    -          0.0555| 0.0156  | 0.0711 -           0.9855    | 0.9655      | 0.9573   | 0.6030     - 6.2538\n",
      "\u001b[1;4mValidati 57     - 100    -          0.4235| 0.2270  | 0.6505 -           0.9469    | 0.9648      | 0.8399   | 0.5268     - 0.5679\u001b[0m\n",
      "Training 58     - 100    -          0.1114| 0.0325  | 0.1439 -           0.9830    | 0.9668      | 0.9496   | 0.6069     - 6.2724\n",
      "\u001b[1;4mValidati 58     - 100    -          0.4141| 0.2605  | 0.6746 -           0.9391    | 0.9615      | 0.8137   | 0.4775     - 0.5153\u001b[0m\n",
      "Training 59     - 100    -          0.0069| 0.0262  | 0.0331 -           0.9860    | 0.9665      | 0.9586   | 0.6112     - 6.3162\n",
      "\u001b[1;4mValidati 59     - 100    -          0.4056| 0.2025  | 0.6081 -           0.9522    | 0.9646      | 0.8515   | 0.5260     - 0.5336\u001b[0m\n",
      "Training 60     - 100    -          0.0382| 0.0159  | 0.0541 -           0.9876    | 0.9664      | 0.9634   | 0.6136     - 6.2350\n",
      "\u001b[1;4mValidati 60     - 100    -          0.4122| 0.2353  | 0.6475 -           0.9437    | 0.9613      | 0.8298   | 0.5208     - 0.5325\u001b[0m\n",
      "Training 61     - 100    -          0.0059| 0.0232  | 0.0291 -           0.9871    | 0.9662      | 0.9618   | 0.6088     - 6.1889\n",
      "\u001b[1;4mValidati 61     - 100    -          0.3966| 0.2106  | 0.6072 -           0.9393    | 0.9614      | 0.8167   | 0.5039     - 0.5266\u001b[0m\n",
      "Training 62     - 100    -          0.0352| 0.0207  | 0.0559 -           0.9869    | 0.9658      | 0.9613   | 0.6093     - 6.2470\n",
      "\u001b[1;4mValidati 62     - 100    -          0.3908| 0.2542  | 0.6451 -           0.9454    | 0.9662      | 0.8288   | 0.5211     - 0.5281\u001b[0m\n",
      "Training 63     - 100    -          0.0681| 0.0395  | 0.1077 -           0.9855    | 0.9668      | 0.9570   | 0.6142     - 6.2801\n",
      "\u001b[1;4mValidati 63     - 100    -          0.4186| 0.2269  | 0.6455 -           0.9395    | 0.9571      | 0.8183   | 0.5064     - 0.5275\u001b[0m\n",
      "Training 64     - 100    -          0.0537| 0.0482  | 0.1018 -           0.9864    | 0.9664      | 0.9597   | 0.6125     - 6.1161\n",
      "\u001b[1;4mValidati 64     - 100    -          0.4151| 0.2140  | 0.6291 -           0.9395    | 0.9654      | 0.7872   | 0.5078     - 0.5298\u001b[0m\n",
      "Training 65     - 100    -          0.1336| 0.0181  | 0.1517 -           0.9839    | 0.9666      | 0.9524   | 0.6103     - 6.4396\n",
      "\u001b[1;4mValidati 65     - 100    -          0.3918| 0.2166  | 0.6084 -           0.9383    | 0.9616      | 0.8153   | 0.5123     - 0.5283\u001b[0m\n",
      "Training 66     - 100    -          0.0500| 0.0257  | 0.0757 -           0.9831    | 0.9658      | 0.9499   | 0.6035     - 6.1018\n",
      "\u001b[1;4mValidati 66     - 100    -          0.3831| 0.1933  | 0.5764 -           0.9408    | 0.9582      | 0.8211   | 0.5014     - 0.5207\u001b[0m\n",
      "Training 67     - 100    -          0.0025| 0.0165  | 0.0190 -           0.9884    | 0.9664      | 0.9661   | 0.6143     - 6.2297\n",
      "\u001b[1;4mValidati 67     - 100    -          0.4293| 0.1975  | 0.6268 -           0.9505    | 0.9666      | 0.8446   | 0.5263     - 0.5305\u001b[0m\n",
      "Training 68     - 100    -          0.0713| 0.0434  | 0.1147 -           0.9906    | 0.9667      | 0.9722   | 0.6183     - 6.1487\n",
      "\u001b[1;4mValidati 68     - 100    -          0.4180| 0.2177  | 0.6357 -           0.9504    | 0.9659      | 0.8485   | 0.5294     - 0.5223\u001b[0m\n",
      "Training 69     - 100    -          0.0122| 0.0219  | 0.0341 -           0.9900    | 0.9672      | 0.9705   | 0.6215     - 6.2545\n",
      "\u001b[1;4mValidati 69     - 100    -          0.4022| 0.2088  | 0.6110 -           0.9508    | 0.9633      | 0.8500   | 0.5345     - 0.5258\u001b[0m\n",
      "Training 70     - 100    -          0.1727| 0.0256  | 0.1983 -           0.9856    | 0.9667      | 0.9570   | 0.6143     - 6.0865\n",
      "\u001b[1;4mValidati 70     - 100    -          0.4019| 0.2278  | 0.6298 -           0.9431    | 0.9636      | 0.8207   | 0.5072     - 0.5207\u001b[0m\n",
      "Training 71     - 100    -          0.0194| 0.0345  | 0.0539 -           0.9853    | 0.9667      | 0.9565   | 0.6134     - 6.1908\n",
      "\u001b[1;4mValidati 71     - 100    -          0.4091| 0.2083  | 0.6174 -           0.9444    | 0.9650      | 0.8283   | 0.5161     - 0.5290\u001b[0m\n",
      "Training 72     - 100    -          0.0368| 0.0215  | 0.0583 -           0.9877    | 0.9665      | 0.9635   | 0.6136     - 6.1158\n",
      "\u001b[1;4mValidati 72     - 100    -          0.4058| 0.2156  | 0.6214 -           0.9541    | 0.9641      | 0.8589   | 0.5412     - 0.5179\u001b[0m\n",
      "Training 73     - 100    -          0.0689| 0.0265  | 0.0953 -           0.9883    | 0.9665      | 0.9654   | 0.6154     - 6.2184\n",
      "\u001b[1;4mValidati 73     - 100    -          0.4249| 0.2174  | 0.6423 -           0.9416    | 0.9616      | 0.8241   | 0.5148     - 0.5355\u001b[0m\n",
      "Training 74     - 100    -          0.0330| 0.0184  | 0.0514 -           0.9868    | 0.9668      | 0.9610   | 0.6171     - 6.1479\n",
      "\u001b[1;4mValidati 74     - 100    -          0.4024| 0.2235  | 0.6259 -           0.9516    | 0.9665      | 0.8518   | 0.5392     - 0.5191\u001b[0m\n",
      "Training 75     - 100    -          0.1179| 0.0506  | 0.1685 -           0.9887    | 0.9662      | 0.9665   | 0.6141     - 6.1884\n",
      "\u001b[1;4mValidati 75     - 100    -          0.4308| 0.2180  | 0.6488 -           0.9260    | 0.9524      | 0.7645   | 0.4532     - 0.5387\u001b[0m\n",
      "Training 76     - 100    -          0.0114| 0.0198  | 0.0313 -           0.9835    | 0.9654      | 0.9514   | 0.6046     - 6.1502\n",
      "\u001b[1;4mValidati 76     - 100    -          0.4051| 0.2477  | 0.6528 -           0.9512    | 0.9629      | 0.8522   | 0.5362     - 0.5149\u001b[0m\n",
      "Training 77     - 100    -          0.0046| 0.0203  | 0.0249 -           0.9911    | 0.9657      | 0.9737   | 0.6141     - 6.1315\n",
      "\u001b[1;4mValidati 77     - 100    -          0.4651| 0.2128  | 0.6779 -           0.9473    | 0.9655      | 0.8172   | 0.5315     - 0.5193\u001b[0m\n",
      "Training 78     - 100    -          0.0681| 0.0270  | 0.0951 -           0.9919    | 0.9672      | 0.9763   | 0.6238     - 6.3516\n",
      "\u001b[1;4mValidati 78     - 100    -          0.4345| 0.2282  | 0.6627 -           0.9432    | 0.9644      | 0.8019   | 0.5043     - 0.5251\u001b[0m\n",
      "Training 79     - 100    -          0.0707| 0.0451  | 0.1158 -           0.9868    | 0.9657      | 0.9606   | 0.6103     - 6.1687\n",
      "\u001b[1;4mValidati 79     - 100    -          0.3998| 0.2082  | 0.6080 -           0.9374    | 0.9598      | 0.8118   | 0.5150     - 0.5211\u001b[0m\n",
      "Training 80     - 100    -          0.0970| 0.0351  | 0.1322 -           0.9889    | 0.9662      | 0.9674   | 0.6156     - 6.1223\n",
      "\u001b[1;4mValidati 80     - 100    -          0.4234| 0.2207  | 0.6441 -           0.9529    | 0.9623      | 0.8554   | 0.5313     - 0.5126\u001b[0m\n",
      "Training 81     - 100    -          0.0381| 0.0401  | 0.0782 -           0.9896    | 0.9660      | 0.9692   | 0.6110     - 6.2071\n",
      "\u001b[1;4mValidati 81     - 100    -          0.4168| 0.2169  | 0.6336 -           0.9473    | 0.9637      | 0.8389   | 0.5347     - 0.5281\u001b[0m\n",
      "Training 82     - 100    -          0.0969| 0.0273  | 0.1242 -           0.9889    | 0.9662      | 0.9670   | 0.6151     - 6.0181\n",
      "\u001b[1;4mValidati 82     - 100    -          0.4012| 0.2310  | 0.6322 -           0.9484    | 0.9642      | 0.8407   | 0.5256     - 0.5094\u001b[0m\n",
      "Training 83     - 100    -          0.0103| 0.0169  | 0.0271 -           0.9908    | 0.9660      | 0.9728   | 0.6150     - 6.0767\n",
      "\u001b[1;4mValidati 83     - 100    -          0.4104| 0.2306  | 0.6410 -           0.9511    | 0.9644      | 0.8486   | 0.5347     - 0.5117\u001b[0m\n",
      "Training 84     - 100    -          0.0298| 0.0297  | 0.0595 -           0.9852    | 0.9660      | 0.9561   | 0.6099     - 6.1168\n",
      "\u001b[1;4mValidati 84     - 100    -          0.4466| 0.2365  | 0.6831 -           0.9345    | 0.9585      | 0.8008   | 0.4849     - 0.5425\u001b[0m\n",
      "Training 85     - 100    -          0.1339| 0.0429  | 0.1768 -           0.9847    | 0.9674      | 0.9548   | 0.6185     - 6.1127\n",
      "\u001b[1;4mValidati 85     - 100    -          0.3956| 0.2129  | 0.6085 -           0.9276    | 0.9572      | 0.7834   | 0.4678     - 0.5198\u001b[0m\n",
      "Training 86     - 100    -          0.0439| 0.0321  | 0.0760 -           0.9863    | 0.9667      | 0.9594   | 0.6155     - 6.0531\n",
      "\u001b[1;4mValidati 86     - 100    -          0.3945| 0.2027  | 0.5972 -           0.9443    | 0.9638      | 0.8307   | 0.5210     - 0.5028\u001b[0m\n",
      "Training 87     - 100    -          0.0498| 0.0222  | 0.0720 -           0.9915    | 0.9672      | 0.9749   | 0.6241     - 6.0594\n",
      "\u001b[1;4mValidati 87     - 100    -          0.4116| 0.2145  | 0.6261 -           0.9499    | 0.9644      | 0.8463   | 0.5309     - 0.5281\u001b[0m\n",
      "Training 88     - 100    -          0.0085| 0.0076  | 0.0161 -           0.9930    | 0.9671      | 0.9794   | 0.6240     - 6.1211\n",
      "\u001b[1;4mValidati 88     - 100    -          0.3894| 0.2311  | 0.6205 -           0.9519    | 0.9628      | 0.8531   | 0.5407     - 0.5172\u001b[0m\n",
      "Training 89     - 100    -          0.0476| 0.0191  | 0.0666 -           0.9929    | 0.9669      | 0.9789   | 0.6243     - 6.1038\n",
      "\u001b[1;4mValidati 89     - 100    -          0.3942| 0.2112  | 0.6054 -           0.9490    | 0.9615      | 0.8448   | 0.5308     - 0.5024\u001b[0m\n",
      "Training 90     - 100    -          0.0279| 0.0158  | 0.0437 -           0.9907    | 0.9661      | 0.9725   | 0.6170     - 6.0003\n",
      "\u001b[1;4mValidati 90     - 100    -          0.4250| 0.1888  | 0.6138 -           0.9389    | 0.9593      | 0.7904   | 0.4935     - 0.5019\u001b[0m\n",
      "Training 91     - 100    -          0.1146| 0.0178  | 0.1324 -           0.9880    | 0.9663      | 0.9645   | 0.6157     - 6.0939\n",
      "\u001b[1;4mValidati 91     - 100    -          0.4017| 0.2008  | 0.6025 -           0.9485    | 0.9659      | 0.8410   | 0.5308     - 0.5125\u001b[0m\n",
      "Training 92     - 100    -          0.0069| 0.0157  | 0.0227 -           0.9874    | 0.9661      | 0.9632   | 0.6146     - 6.0418\n",
      "\u001b[1;4mValidati 92     - 100    -          0.4401| 0.2223  | 0.6625 -           0.9448    | 0.9660      | 0.8094   | 0.5297     - 0.5042\u001b[0m\n",
      "Training 93     - 100    -          0.0703| 0.0369  | 0.1072 -           0.9873    | 0.9665      | 0.9627   | 0.6177     - 6.0559\n",
      "\u001b[1;4mValidati 93     - 100    -          0.4048| 0.1939  | 0.5987 -           0.9408    | 0.9607      | 0.8225   | 0.5234     - 0.5073\u001b[0m\n",
      "Training 94     - 100    -          0.0138| 0.0224  | 0.0363 -           0.9878    | 0.9661      | 0.9635   | 0.6139     - 6.0237\n",
      "\u001b[1;4mValidati 94     - 100    -          0.4182| 0.1910  | 0.6092 -           0.9394    | 0.9523      | 0.8136   | 0.4736     - 0.5081\u001b[0m\n",
      "Training 95     - 100    -          0.0279| 0.0196  | 0.0475 -           0.9866    | 0.9666      | 0.9610   | 0.6179     - 6.1215\n",
      "\u001b[1;4mValidati 95     - 100    -          0.4126| 0.2158  | 0.6283 -           0.9469    | 0.9651      | 0.8349   | 0.5358     - 0.5274\u001b[0m\n",
      "Training 96     - 100    -          0.0535| 0.0371  | 0.0905 -           0.9873    | 0.9659      | 0.9626   | 0.6128     - 6.0579\n",
      "\u001b[1;4mValidati 96     - 100    -          0.3799| 0.2088  | 0.5886 -           0.9413    | 0.9635      | 0.8212   | 0.5209     - 0.5026\u001b[0m\n",
      "Training 97     - 100    -          0.0097| 0.0291  | 0.0388 -           0.9883    | 0.9681      | 0.9655   | 0.6302     - 6.0311\n",
      "\u001b[1;4mValidati 97     - 100    -          0.4180| 0.2007  | 0.6187 -           0.9477    | 0.9684      | 0.8368   | 0.5276     - 0.5018\u001b[0m\n",
      "Training 98     - 100    -          0.0033| 0.0211  | 0.0244 -           0.9923    | 0.9676      | 0.9773   | 0.6290     - 6.0984\n",
      "\u001b[1;4mValidati 98     - 100    -          0.4303| 0.2212  | 0.6515 -           0.9515    | 0.9643      | 0.8493   | 0.5443     - 0.5189\u001b[0m\n",
      "Training 99     - 100    -          0.0043| 0.0262  | 0.0305 -           0.9942    | 0.9672      | 0.9829   | 0.6291     - 6.0472\n",
      "\u001b[1;4mValidati 99     - 100    -          0.4050| 0.2149  | 0.6199 -           0.9501    | 0.9616      | 0.8476   | 0.5367     - 0.5056\u001b[0m\n",
      "Training 100    - 100    -          0.0273| 0.0290  | 0.0563 -           0.9940    | 0.9672      | 0.9823   | 0.6309     - 6.0363\n",
      "\u001b[1;4mValidati 100    - 100    -          0.4238| 0.2073  | 0.6311 -           0.9477    | 0.9643      | 0.8195   | 0.5492     - 0.5025\u001b[0m\r"
     ]
    }
   ],
   "source": [
    "# tensorboard\n",
    "title = \"dcase2019_system_%s\" % (get_datetime())\n",
    "tensorboard = SummaryWriter(log_dir=Path(\"../tensorboard/%s\" % title), comment=\"weak baseline\")\n",
    "\n",
    "print(header)\n",
    "for e in range(nb_epochs):\n",
    "    train(e)\n",
    "    val(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ♫♪.ılılıll|̲̅̅●̲̅̅|̲̅̅=̲̅̅|̲̅̅●̲̅̅|llılılı.♫♪"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcase2020",
   "language": "python",
   "name": "dcase2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
