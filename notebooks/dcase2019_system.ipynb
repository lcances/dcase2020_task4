{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%% Import\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# dataset manager\n",
    "from dcase2020.datasetManager import DESEDManager\n",
    "from dcase2020.datasets import DESEDDataset\n",
    "\n",
    "# utility function & metrics & augmentation\n",
    "from metric_utils.metrics import FScore, BinaryAccuracy\n",
    "from dcase2020_task4.util.utils import get_datetime, reset_seed\n",
    "\n",
    "# models\n",
    "from dcase2020_task4.dcase2019.models import dcase2019_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ==== set the log ====\n",
    "import logging\n",
    "import logging.config\n",
    "from dcase2020.util.log import DEFAULT_LOGGING\n",
    "logging.config.dictConfig(DEFAULT_LOGGING)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ==== reset the seed for reproductability ====\n",
    "reset_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mDEBUG --- datasetManager.__init__ >>> ../dataset/DESED/dataset/audio/dcase2020_dataset_22050.hdf5\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._load_metadata >>> Reading metadata: ../dataset/DESED/dataset/metadata/train/weak.tsv\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._load_metadata >>> Reading metadata: ../dataset/DESED/dataset/metadata/train/unlabel_in_domain.tsv\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager._load_metadata >>> Reading metadata: ../dataset/DESED/dataset/metadata/train/synthetic20.tsv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7582/7582 [00:15<00:00, 485.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# ==== load the dataset ====\n",
    "desed_metadata_root = \"../dataset/DESED/dataset/metadata\"\n",
    "desed_audio_root = \"../dataset/DESED/dataset/audio\"\n",
    "# desed_metadata_root = os.path.join(\"e:/\", \"Corpus\", \"dcase2020\", \"DESED\", \"dataset\", \"metadata\")\n",
    "# desed_audio_root = os.path.join(\"e:/\", \"Corpus\", \"dcase2020\", \"DESED\", \"dataset\", \"audio\")\n",
    "\n",
    "manager = DESEDManager(\n",
    "    desed_metadata_root, desed_audio_root,\n",
    "    sampling_rate = 22050,\n",
    "    validation_ratio=0.2,\n",
    "    from_disk=False,\n",
    "    nb_vector_bin=431, # there is no temporal reduction in this model\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add weak ans synthetic20 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37mINFO --- datasetManager.add_subset >>> Loading dataset: train, subset: weak\u001b[0m\n",
      "Loading dataset: train, subset: weak\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> hdf_file: <HDF5 file \"dcase2020_dataset_22050.hdf5\" (mode r)>\u001b[0m\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> path: DESED/dataset/audio/train/weak\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager.add_subset >>> Loading dataset: train, subset: synthetic20\u001b[0m\n",
      "Loading dataset: train, subset: synthetic20\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> hdf_file: <HDF5 file \"dcase2020_dataset_22050.hdf5\" (mode r)>\u001b[0m\n",
      "\u001b[1;34mDEBUG --- datasetManager._hdf_to_dict >>> path: DESED/dataset/audio/train/synthetic20\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "manager.add_subset(\"weak\")\n",
    "manager.add_subset(\"synthetic20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the train / validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37mINFO --- datasetManager.split_train_validation >>> Creating new train / validation split\u001b[0m\n",
      "\u001b[1;37mINFO --- datasetManager.split_train_validation >>> validation ratio : 0.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "manager.split_train_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%  setup augmentation and create pytorch dataset\n"
    }
   },
   "outputs": [],
   "source": [
    "augments = [\n",
    "    # signal_augmentation.Noise(0.5, target_snr=15),\n",
    "    # signal_augmentation.RandomTimeDropout(0.5, dropout=0.2)\n",
    "]\n",
    "\n",
    "train_dataset = DESEDDataset(manager, train=True, val=False, augments=augments, cached=True)\n",
    "val_dataset = DESEDDataset(manager, train=False, val=True, augments=[], cached=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class MultipleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, datasets):\n",
    "        super(MultipleDataset, self).__init__()\n",
    "        assert len(datasets) > 0, 'datasets should not be an empty iterable'\n",
    "        self.datasets = list(datasets)\n",
    "        for d in self.datasets:\n",
    "            assert not isinstance(d, IterableDataset), \"ConcatDataset does not support IterableDataset\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datasets[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [d[sample_idx] for d in self.datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3322, 727)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.filenames), len(val_dataset.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep dataset\n",
    "\n",
    "- We want both the weak and strong ground truth --> the *weak* and *strong* parameters to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "augments = [\n",
    "    # signal_augmentation.Noise(0.5, target_snr=15),\n",
    "    # signal_augmentation.RandomTimeDropout(0.5, dropout=0.2)\n",
    "]\n",
    "\n",
    "train_dataset = DESEDDataset(manager, train=True, val=False, weak=True, strong=True, augments=augments, cached=True)\n",
    "val_dataset = DESEDDataset(manager, train=False, val=True, weak=True, strong=True, augments=[], cached=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model\n",
    "\n",
    "This model is the same than the weak baseline but have an extra output. <br />\n",
    "the loc_output is compose of a single convolution layer with nb_filters == nb_class. <br />\n",
    "Since their is some pooling layer, the *loc_ouput* have a precision of 53 bins (~= 18 ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Setup model and training parameters\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dcase2019_model(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLUPool(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout2d(p=0.0, inplace=False)\n",
       "      (3): ReLU6(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): ConvBNReLUPool(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout2d(p=0.0, inplace=False)\n",
       "      (3): ReLU6(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): ConvBNReLUPool(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout2d(p=0.0, inplace=False)\n",
       "      (3): ReLU6(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (bi_gru): GRU(64, 64, batch_first=True, bidirectional=True)\n",
       "  (strong_classifier): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       "  (g_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (g_max_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "  (weak_classifier): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "model = dcase2019_model()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n",
      "                                 Kernel Shape      Output Shape   Params  \\\n",
      "Layer                                                                      \n",
      "0_features.0.Conv2d_0           [1, 64, 3, 3]  [2, 64, 64, 431]    640.0   \n",
      "1_features.0.BatchNorm2d_1               [64]  [2, 64, 64, 431]    128.0   \n",
      "2_features.0.Dropout2d_2                    -  [2, 64, 64, 431]        -   \n",
      "3_features.0.ReLU6_3                        -  [2, 64, 64, 431]        -   \n",
      "4_features.0.MaxPool2d_4                    -  [2, 64, 16, 431]        -   \n",
      "5_features.1.Conv2d_0          [64, 64, 3, 3]  [2, 64, 16, 431]  36.928k   \n",
      "6_features.1.BatchNorm2d_1               [64]  [2, 64, 16, 431]    128.0   \n",
      "7_features.1.Dropout2d_2                    -  [2, 64, 16, 431]        -   \n",
      "8_features.1.ReLU6_3                        -  [2, 64, 16, 431]        -   \n",
      "9_features.1.MaxPool2d_4                    -   [2, 64, 4, 431]        -   \n",
      "10_features.2.Conv2d_0         [64, 64, 3, 3]   [2, 64, 4, 431]  36.928k   \n",
      "11_features.2.BatchNorm2d_1              [64]   [2, 64, 4, 431]    128.0   \n",
      "12_features.2.Dropout2d_2                   -   [2, 64, 4, 431]        -   \n",
      "13_features.2.ReLU6_3                       -   [2, 64, 4, 431]        -   \n",
      "14_features.2.MaxPool2d_4                   -   [2, 64, 1, 431]        -   \n",
      "15_bi_gru                                   -     [2, 431, 128]   49.92k   \n",
      "16_strong_classifier.Linear_0       [128, 64]      [2, 431, 64]   8.256k   \n",
      "17_strong_classifier.ReLU_1                 -      [2, 431, 64]        -   \n",
      "18_strong_classifier.Linear_2        [64, 10]      [2, 431, 10]    650.0   \n",
      "19_g_avg_pool                               -        [2, 10, 1]        -   \n",
      "20_g_max_pool                               -        [2, 10, 1]        -   \n",
      "21_weak_classifier.Linear_0        [20, 1024]         [2, 1024]  21.504k   \n",
      "22_weak_classifier.ReLU_1                   -         [2, 1024]        -   \n",
      "23_weak_classifier.Linear_2        [1024, 10]           [2, 10]   10.25k   \n",
      "\n",
      "                                 Mult-Adds  \n",
      "Layer                                       \n",
      "0_features.0.Conv2d_0           15.888384M  \n",
      "1_features.0.BatchNorm2d_1            64.0  \n",
      "2_features.0.Dropout2d_2                 -  \n",
      "3_features.0.ReLU6_3                     -  \n",
      "4_features.0.MaxPool2d_4                 -  \n",
      "5_features.1.Conv2d_0          254.214144M  \n",
      "6_features.1.BatchNorm2d_1            64.0  \n",
      "7_features.1.Dropout2d_2                 -  \n",
      "8_features.1.ReLU6_3                     -  \n",
      "9_features.1.MaxPool2d_4                 -  \n",
      "10_features.2.Conv2d_0          63.553536M  \n",
      "11_features.2.BatchNorm2d_1           64.0  \n",
      "12_features.2.Dropout2d_2                -  \n",
      "13_features.2.ReLU6_3                    -  \n",
      "14_features.2.MaxPool2d_4                -  \n",
      "15_bi_gru                          49.152k  \n",
      "16_strong_classifier.Linear_0       8.192k  \n",
      "17_strong_classifier.ReLU_1              -  \n",
      "18_strong_classifier.Linear_2        640.0  \n",
      "19_g_avg_pool                            -  \n",
      "20_g_max_pool                            -  \n",
      "21_weak_classifier.Linear_0         20.48k  \n",
      "22_weak_classifier.ReLU_1                -  \n",
      "23_weak_classifier.Linear_2         10.24k  \n",
      "-------------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params             165.46k\n",
      "Trainable params         165.46k\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             333.74496M\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "input_tensor = torch.zeros((2, 64, 431), dtype=torch.float)\n",
    "input_tensor = input_tensor.cuda()\n",
    "\n",
    "s = summary(model, input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom loss function\n",
    "\n",
    "Since not all file have strong truth, it is necessary to remove those files. <br />\n",
    "For that, the strong mask is computed. If the sum of the strong ground truth is equal to 0 then it is a fake one <br />\n",
    "This file strong loss must not be taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weak_synth_loss(logits_weak, logits_strong, y_weak, y_strong, reduce: str = \"mean\"):\n",
    "    assert reduce in [\"mean\", \"sum\"], \"support only \\\"mean\\\" and \\\"sum\\\"\"\n",
    "    \n",
    "    #  Reduction function\n",
    "    if reduce == \"mean\":\n",
    "        reduce_fn = torch.mean\n",
    "    elif reduce == \"sum\":\n",
    "        reduce_fn = torch.sum\n",
    "    \n",
    "    # based on Binary Cross Entropy loss\n",
    "    weak_criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    strong_criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    \n",
    "    # calc separate loss function\n",
    "    weak_bce = weak_criterion(logits_weak, y_weak)\n",
    "    strong_bce = strong_criterion(logits_strong, y_strong)\n",
    "    \n",
    "    weak_bce = reduce_fn(weak_bce, dim=1)\n",
    "    strong_bce = reduce_fn(strong_bce, dim=(1, 2))\n",
    "    \n",
    "    # calc strong mask\n",
    "    strong_mask = torch.clamp(torch.sum(y_strong, dim=(1, 2)), 0, 1) # vector of 0 or 1\n",
    "#     strong_mask = strong_mask.detach() # declared not to need gradients\n",
    "    \n",
    "    # Output the different loss for logging purpose\n",
    "    weak_loss = reduce_fn(weak_bce)\n",
    "    strong_loss = reduce_fn(strong_mask * strong_bce)\n",
    "    total_loss = reduce_fn(weak_bce + strong_mask * strong_bce)\n",
    "    \n",
    "    return weak_loss, strong_loss, total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters (crit & callbacks & loaders & metrics)m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Setup model and training parameters\n"
    }
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "nb_epochs = 100\n",
    "batch_size = 32\n",
    "nb_batch = len(train_dataset) // batch_size\n",
    "\n",
    "optimizers = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# callbacks\n",
    "callbacks = []\n",
    "\n",
    "# tensorboard\n",
    "title = \"WeakBaseline_%s\" % (get_datetime())\n",
    "tensorboard = SummaryWriter(log_dir=Path(\"../tensorboard/%s\" % title), comment=\"weak baseline\")\n",
    "\n",
    "# loaders\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Metrics\n",
    "weak_binacc_func = BinaryAccuracy()\n",
    "strong_binacc_func = BinaryAccuracy()\n",
    "weak_f_func = FScore()\n",
    "strong_f_func = FScore()\n",
    "metrics = [weak_binacc_func, strong_binacc_func, weak_f_func, strong_f_func]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_all_metrics(metrics):\n",
    "    for m in metrics:\n",
    "        m.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Epoch  - %      - Losses:  Weak  | Strong  | Total  - metrics:  Weak acc  | Strong acc  | Weak F1  | Strong F1  - Time  \n"
     ]
    }
   ],
   "source": [
    "UNDERLINE_SEQ = \"\\033[1;4m\"\n",
    "RESET_SEQ = \"\\033[0m\"\n",
    "\n",
    "header_form = \"{:<8.8} {:<6.6} - {:<6.6} - {:<8.8} {:<6.6}| {:<8.8}| {:<6.6} - {:<9.9} {:<10.10}| {:<12.12}| {:<9.9}| {:<11.11}- {:<6.6}\"\n",
    "\n",
    "value_form  = \"{:<8.8} {:<6} - {:<6} - {:<8.8} {:<6.4f}| {:<8.4f}| {:<6.4f} - {:<9.9} {:<10.4f}| {:<12.4f}| {:<9.4f}| {:<11.4f}- {:<6.4f}\"\n",
    "\n",
    "train_form = value_form\n",
    "val_form = UNDERLINE_SEQ + value_form + RESET_SEQ\n",
    "\n",
    "header = header_form.format(\n",
    "    \"\", \"Epoch\", \"%\", \"Losses:\", \"Weak \", \"Strong \", \"Total \", \"metrics: \", \"Weak acc \", \"Strong acc \", \"Weak F1 \", \"Strong F1\", \"Time\"\n",
    ")\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% training function\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch: int):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    reset_all_metrics(metrics)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"\") # <-- Force new line\n",
    "    \n",
    "    for i, (X, y) in enumerate(training_loader):\n",
    "        # The DESEDDataset return a list of ground truth depending on the selecting option.\n",
    "        # If weak and strong ground truth are selected, the list order is [WEAK, STRONG]\n",
    "        # here there is only one [WEAK]\n",
    "        X = X.cuda().float()\n",
    "        y_weak = y[0].cuda().float()\n",
    "        y_strong = y[1].cuda().float()\n",
    "        \n",
    "        weak_logits, strong_logits = model(X)\n",
    "        \n",
    "        # calc the loss\n",
    "        weak_loss, strong_loss, total_loss = weak_synth_loss(\n",
    "            weak_logits, strong_logits,\n",
    "            y_weak, y_strong,\n",
    "            reduce=\"mean\"\n",
    "        )\n",
    "        \n",
    "        # back propagation\n",
    "        optimizers.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizers.step()\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            # calc metrics\n",
    "            weak_pred = torch.sigmoid(weak_logits)\n",
    "            strong_pred = torch.sigmoid(strong_logits)\n",
    "\n",
    "            # tagging\n",
    "            weak_binacc = weak_binacc_func(weak_pred, y_weak)\n",
    "            weak_fscore = weak_f_func(weak_pred, y_weak)\n",
    "\n",
    "            # loc\n",
    "            strong_binacc = strong_binacc_func(strong_pred, y_strong)\n",
    "            strong_fscore = strong_f_func(strong_pred, y_strong)\n",
    "        \n",
    "            # logs\n",
    "            print(train_form.format(\n",
    "                \"Training: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / len(training_loader)),\n",
    "                \"\", weak_loss.item(), strong_loss.item(), total_loss.item(),\n",
    "                \"\", weak_binacc, strong_binacc, weak_fscore, strong_fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "        # tensorboard logs\n",
    "        tensorboard.add_scalar(\"train/weak_loss\", weak_loss.item(), epoch)\n",
    "        tensorboard.add_scalar(\"train/strong_loss\", strong_loss.item(), epoch)\n",
    "        tensorboard.add_scalar(\"train/total_loss\", total_loss.item(), epoch)\n",
    "\n",
    "        tensorboard.add_scalar(\"train/weak_acc\", weak_binacc, epoch)\n",
    "        tensorboard.add_scalar(\"train/strong_acc\", strong_binacc, epoch)\n",
    "        tensorboard.add_scalar(\"train/weak_f1\", weak_fscore, epoch)\n",
    "        tensorboard.add_scalar(\"train/strong_f1\", strong_fscore, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% validation function\n"
    }
   },
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    start_time = time.time()\n",
    "\n",
    "        \n",
    "    reset_all_metrics(metrics)\n",
    "    \n",
    "    model.eval()\n",
    "    print(\"\") # <-- Force new line\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(val_loader):\n",
    "            X = X.cuda().float()\n",
    "            y_weak = y[0].cuda().float()\n",
    "            y_strong = y[1].cuda().float()\n",
    "\n",
    "            weak_logits, strong_logits = model(X)\n",
    "\n",
    "            # calc the loss\n",
    "            weak_loss, strong_loss, total_loss = weak_synth_loss(\n",
    "                weak_logits, strong_logits,\n",
    "                y_weak, y_strong,\n",
    "                reduce=\"mean\"\n",
    "            )\n",
    "            \n",
    "             # calc metrics\n",
    "            weak_pred = torch.sigmoid(weak_logits)\n",
    "            strong_pred = torch.sigmoid(strong_logits)\n",
    "\n",
    "            # tagging\n",
    "            weak_binacc = weak_binacc_func(weak_pred, y_weak)\n",
    "            weak_fscore = weak_f_func(weak_pred, y_weak)\n",
    "\n",
    "            # loc\n",
    "            strong_binacc = strong_binacc_func(strong_pred, y_strong)\n",
    "            strong_fscore = strong_f_func(strong_pred, y_strong)\n",
    "\n",
    "            # logs\n",
    "            print(val_form.format(\n",
    "                \"Validation: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / len(val_loader)),\n",
    "                \"\", weak_loss.item(), strong_loss.item(), total_loss.item(),\n",
    "                \"\", weak_binacc, strong_binacc, weak_fscore, strong_fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "        # tensorboard logs\n",
    "        tensorboard.add_scalar(\"val/weak_loss\", weak_loss.item(), epoch)\n",
    "        tensorboard.add_scalar(\"val/strong_loss\", strong_loss.item(), epoch)\n",
    "        tensorboard.add_scalar(\"val/total_loss\", total_loss.item(), epoch)\n",
    "\n",
    "        tensorboard.add_scalar(\"val/weak_acc\", weak_binacc, epoch)\n",
    "        tensorboard.add_scalar(\"val/strong_acc\", strong_binacc, epoch)\n",
    "        tensorboard.add_scalar(\"val/weak_f1\", weak_fscore, epoch)\n",
    "        tensorboard.add_scalar(\"val/strong_f1\", strong_fscore, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Epoch  - %      - Losses:  Weak  | Strong  | Total  - metrics:  Weak acc  | Strong acc  | Weak F1  | Strong F1  - Time  \n",
      "\n",
      "Training 1      - 100    -          0.3613| 0.0654  | 0.4266 -           0.8330    | 0.9593      | 0.2731   | 0.0015     - 48.2136\n",
      "\u001b[1;4mValidati 1      - 100    -          0.4649| 0.2065  | 0.6715 -           0.8330    | 0.9668      | 0.0000   | 0.0000     - 9.6528\u001b[0m\n",
      "Training 2      - 100    -          0.3280| 0.0970  | 0.4250 -           0.8481    | 0.9631      | 0.3446   | 0.1316     - 6.0403\n",
      "\u001b[1;4mValidati 2      - 100    -          0.3941| 0.1871  | 0.5812 -           0.8557    | 0.9666      | 0.3784   | 0.0843     - 0.4965\u001b[0m\n",
      "Training 3      - 100    -          0.2840| 0.0662  | 0.3502 -           0.8682    | 0.9625      | 0.4556   | 0.2201     - 5.9595\n",
      "\u001b[1;4mValidati 3      - 100    -          0.3885| 0.1928  | 0.5813 -           0.8717    | 0.9595      | 0.5078   | 0.2096     - 0.4835\u001b[0m\n",
      "Training 4      - 100    -          0.3122| 0.0519  | 0.3641 -           0.8798    | 0.9584      | 0.5356   | 0.3001     - 5.9411\n",
      "\u001b[1;4mValidati 4      - 100    -          0.4271| 0.2006  | 0.6277 -           0.8816    | 0.9614      | 0.5325   | 0.2437     - 0.4810\u001b[0m\n",
      "Training 5      - 100    -          0.2696| 0.0681  | 0.3377 -           0.8944    | 0.9580      | 0.6185   | 0.3536     - 5.9738\n",
      "\u001b[1;4mValidati 5      - 100    -          0.3740| 0.1867  | 0.5607 -           0.8997    | 0.9620      | 0.6282   | 0.3179     - 0.4827\u001b[0m\n",
      "Training 6      - 100    -          0.2387| 0.0733  | 0.3119 -           0.9022    | 0.9600      | 0.6607   | 0.3926     - 5.9258\n",
      "\u001b[1;4mValidati 6      - 100    -          0.3848| 0.1926  | 0.5774 -           0.8974    | 0.9567      | 0.6161   | 0.3622     - 0.4863\u001b[0m\n",
      "Training 7      - 100    -          0.2609| 0.0390  | 0.2999 -           0.9177    | 0.9611      | 0.7274   | 0.4313     - 5.9464\n",
      "\u001b[1;4mValidati 7      - 100    -          0.3740| 0.1951  | 0.5691 -           0.9097    | 0.9597      | 0.6839   | 0.3613     - 0.4838\u001b[0m\n",
      "Training 8      - 100    -          0.1599| 0.0414  | 0.2013 -           0.9230    | 0.9605      | 0.7490   | 0.4358     - 6.0700\n",
      "\u001b[1;4mValidati 8      - 100    -          0.3568| 0.1728  | 0.5296 -           0.9220    | 0.9617      | 0.7281   | 0.4010     - 0.5035\u001b[0m\n",
      "Training 9      - 100    -          0.1910| 0.0534  | 0.2444 -           0.9315    | 0.9603      | 0.7809   | 0.4540     - 5.9983\n",
      "\u001b[1;4mValidati 9      - 100    -          0.3774| 0.1832  | 0.5606 -           0.9156    | 0.9593      | 0.6990   | 0.3926     - 0.4879\u001b[0m\n",
      "Training 10     - 100    -          0.1343| 0.0254  | 0.1596 -           0.9324    | 0.9600      | 0.7845   | 0.4628     - 6.0366\n",
      "\u001b[1;4mValidati 10     - 100    -          0.3962| 0.1836  | 0.5799 -           0.9165    | 0.9621      | 0.7016   | 0.3866     - 0.4847\u001b[0m\n",
      "Training 11     - 100    -          0.1433| 0.0686  | 0.2118 -           0.9395    | 0.9605      | 0.8089   | 0.4721     - 6.0267\n",
      "\u001b[1;4mValidati 11     - 100    -          0.3790| 0.1937  | 0.5727 -           0.9067    | 0.9584      | 0.6747   | 0.3886     - 0.4965\u001b[0m\n",
      "Training 12     - 100    -          0.1204| 0.0546  | 0.1750 -           0.9421    | 0.9602      | 0.8185   | 0.4812     - 5.9996\n",
      "\u001b[1;4mValidati 12     - 100    -          0.3561| 0.1786  | 0.5347 -           0.9181    | 0.9577      | 0.7263   | 0.4204     - 0.4881\u001b[0m\n",
      "Training 13     - 100    -          0.1266| 0.0502  | 0.1768 -           0.9468    | 0.9598      | 0.8350   | 0.4877     - 6.0156\n",
      "\u001b[1;4mValidati 13     - 100    -          0.3648| 0.1795  | 0.5443 -           0.9257    | 0.9627      | 0.7448   | 0.4311     - 0.4855\u001b[0m\n",
      "Training 14     - 100    -          0.1571| 0.0263  | 0.1834 -           0.9486    | 0.9595      | 0.8402   | 0.4944     - 6.0609\n",
      "\u001b[1;4mValidati 14     - 100    -          0.3478| 0.1777  | 0.5255 -           0.9013    | 0.9508      | 0.6698   | 0.3465     - 0.4990\u001b[0m\n",
      "Training 15     - 100    -          0.0965| 0.0471  | 0.1436 -           0.9524    | 0.9599      | 0.8530   | 0.5002     - 6.0229\n",
      "\u001b[1;4mValidati 15     - 100    -          0.3632| 0.1794  | 0.5425 -           0.9015    | 0.9303      | 0.6848   | 0.3367     - 0.4889\u001b[0m\n",
      "Training 16     - 100    -          0.1020| 0.0383  | 0.1403 -           0.9548    | 0.9605      | 0.8607   | 0.5100     - 5.9763\n",
      "\u001b[1;4mValidati 16     - 100    -          0.3582| 0.1816  | 0.5398 -           0.9380    | 0.9561      | 0.7992   | 0.4794     - 0.4884\u001b[0m\n",
      "Training 17     - 100    -          0.1364| 0.0380  | 0.1744 -           0.9520    | 0.9593      | 0.8518   | 0.5011     - 6.0425\n",
      "\u001b[1;4mValidati 17     - 100    -          0.3523| 0.1814  | 0.5337 -           0.9321    | 0.9587      | 0.7773   | 0.4649     - 0.4982\u001b[0m\n",
      "Training 18     - 100    -          0.1358| 0.0264  | 0.1623 -           0.9605    | 0.9600      | 0.8799   | 0.5170     - 6.0687\n",
      "\u001b[1;4mValidati 18     - 100    -          0.3584| 0.1768  | 0.5352 -           0.9420    | 0.9561      | 0.8053   | 0.4905     - 0.4891\u001b[0m\n",
      "Training 19     - 100    -          0.1455| 0.0358  | 0.1813 -           0.9608    | 0.9594      | 0.8795   | 0.5139     - 6.0432\n",
      "\u001b[1;4mValidati 19     - 100    -          0.3545| 0.1769  | 0.5313 -           0.9378    | 0.9612      | 0.7960   | 0.4722     - 0.4880\u001b[0m\n",
      "Training 20     - 100    -          0.1755| 0.0647  | 0.2402 -           0.9600    | 0.9598      | 0.8774   | 0.5192     - 6.0156\n",
      "\u001b[1;4mValidati 20     - 100    -          0.3635| 0.1883  | 0.5518 -           0.9334    | 0.9567      | 0.7766   | 0.4730     - 0.4854\u001b[0m\n",
      "Training 21     - 100    -          0.0921| 0.0310  | 0.1230 -           0.9635    | 0.9606      | 0.8891   | 0.5269     - 6.0621\n",
      "\u001b[1;4mValidati 21     - 100    -          0.3603| 0.1953  | 0.5557 -           0.9375    | 0.9549      | 0.7964   | 0.4909     - 0.4975\u001b[0m\n",
      "Training 22     - 100    -          0.0847| 0.0442  | 0.1289 -           0.9664    | 0.9603      | 0.8983   | 0.5300     - 6.0194\n",
      "\u001b[1;4mValidati 22     - 100    -          0.3511| 0.1755  | 0.5266 -           0.9411    | 0.9666      | 0.7970   | 0.4986     - 0.4872\u001b[0m\n",
      "Training 23     - 100    -          0.1253| 0.0538  | 0.1790 -           0.9672    | 0.9614      | 0.9006   | 0.5407     - 6.0280\n",
      "\u001b[1;4mValidati 23     - 100    -          0.3589| 0.1778  | 0.5367 -           0.9441    | 0.9634      | 0.8114   | 0.5004     - 0.4846\u001b[0m\n",
      "Training 24     - 100    -          0.0772| 0.0284  | 0.1056 -           0.9684    | 0.9621      | 0.9049   | 0.5509     - 6.0735\n",
      "\u001b[1;4mValidati 24     - 100    -          0.3417| 0.1734  | 0.5151 -           0.9335    | 0.9567      | 0.7843   | 0.4880     - 0.4977\u001b[0m\n",
      "Training 25     - 100    -          0.0539| 0.0160  | 0.0699 -           0.9690    | 0.9606      | 0.9063   | 0.5406     - 6.0148\n",
      "\u001b[1;4mValidati 25     - 100    -          0.3521| 0.1737  | 0.5259 -           0.9410    | 0.9635      | 0.7900   | 0.4767     - 0.4913\u001b[0m\n",
      "Training 26     - 100    -          0.1079| 0.0394  | 0.1473 -           0.9694    | 0.9608      | 0.9077   | 0.5434     - 6.0081\n",
      "\u001b[1;4mValidati 26     - 100    -          0.3349| 0.1685  | 0.5034 -           0.9414    | 0.9599      | 0.7944   | 0.4999     - 0.4896\u001b[0m\n",
      "Training 27     - 100    -          0.0810| 0.0410  | 0.1221 -           0.9710    | 0.9611      | 0.9122   | 0.5453     - 6.0783\n",
      "\u001b[1;4mValidati 27     - 100    -          0.3403| 0.1892  | 0.5295 -           0.9386    | 0.9591      | 0.7945   | 0.5076     - 0.5044\u001b[0m\n",
      "Training 28     - 100    -          0.0664| 0.0348  | 0.1012 -           0.9731    | 0.9622      | 0.9186   | 0.5535     - 6.0900\n",
      "\u001b[1;4mValidati 28     - 100    -          0.3646| 0.1766  | 0.5411 -           0.9375    | 0.9633      | 0.7847   | 0.4903     - 0.4862\u001b[0m\n",
      "Training 29     - 100    -          0.0416| 0.0254  | 0.0669 -           0.9736    | 0.9616      | 0.9200   | 0.5519     - 6.0191\n",
      "\u001b[1;4mValidati 29     - 100    -          0.3585| 0.1763  | 0.5349 -           0.9441    | 0.9638      | 0.8207   | 0.5117     - 0.4880\u001b[0m\n",
      "Training 30     - 100    -          0.0786| 0.0201  | 0.0987 -           0.9729    | 0.9622      | 0.9185   | 0.5536     - 6.0257\n",
      "\u001b[1;4mValidati 30     - 100    -          0.3492| 0.1863  | 0.5355 -           0.9445    | 0.9604      | 0.8188   | 0.5137     - 0.4850\u001b[0m\n",
      "Training 31     - 100    -          0.0774| 0.0331  | 0.1106 -           0.9745    | 0.9614      | 0.9231   | 0.5520     - 6.1352\n",
      "\u001b[1;4mValidati 31     - 100    -          0.3394| 0.1814  | 0.5209 -           0.9450    | 0.9619      | 0.8171   | 0.4968     - 0.5067\u001b[0m\n",
      "Training 32     - 100    -          0.0271| 0.0216  | 0.0486 -           0.9749    | 0.9620      | 0.9250   | 0.5570     - 6.0131\n",
      "\u001b[1;4mValidati 32     - 100    -          0.3488| 0.1776  | 0.5264 -           0.9479    | 0.9625      | 0.8271   | 0.5097     - 0.4872\u001b[0m\n",
      "Training 33     - 100    -          0.0970| 0.0306  | 0.1276 -           0.9793    | 0.9638      | 0.9378   | 0.5728     - 6.0359\n",
      "\u001b[1;4mValidati 33     - 100    -          0.3396| 0.1855  | 0.5251 -           0.9423    | 0.9639      | 0.8066   | 0.5125     - 0.4873\u001b[0m\n",
      "Training 34     - 100    -          0.0966| 0.0304  | 0.1270 -           0.9776    | 0.9620      | 0.9327   | 0.5617     - 6.0712\n",
      "\u001b[1;4mValidati 34     - 100    -          0.3537| 0.1872  | 0.5409 -           0.9435    | 0.9638      | 0.8095   | 0.5075     - 0.4989\u001b[0m\n",
      "Training 35     - 100    -          0.0505| 0.0330  | 0.0834 -           0.9793    | 0.9633      | 0.9380   | 0.5699     - 6.0180\n",
      "\u001b[1;4mValidati 35     - 100    -          0.3407| 0.1883  | 0.5289 -           0.9397    | 0.9567      | 0.8040   | 0.5089     - 0.4846\u001b[0m\n",
      "Training 36     - 100    -          0.0878| 0.0346  | 0.1224 -           0.9773    | 0.9621      | 0.9321   | 0.5653     - 6.0595\n",
      "\u001b[1;4mValidati 36     - 100    -          0.3675| 0.1778  | 0.5453 -           0.9456    | 0.9624      | 0.8226   | 0.5179     - 0.4890\u001b[0m\n",
      "Training 37     - 100    -          0.0384| 0.0377  | 0.0761 -           0.9803    | 0.9624      | 0.9410   | 0.5668     - 6.0191\n",
      "\u001b[1;4mValidati 37     - 100    -          0.3760| 0.1721  | 0.5480 -           0.9370    | 0.9666      | 0.7853   | 0.4928     - 0.4861\u001b[0m\n",
      "Training 38     - 100    -          0.0306| 0.0295  | 0.0601 -           0.9777    | 0.9631      | 0.9332   | 0.5670     - 6.1260\n",
      "\u001b[1;4mValidati 38     - 100    -          0.3589| 0.1773  | 0.5363 -           0.9359    | 0.9581      | 0.7801   | 0.4964     - 0.4976\u001b[0m\n",
      "Training 39     - 100    -          0.0934| 0.0362  | 0.1296 -           0.9776    | 0.9613      | 0.9329   | 0.5562     - 6.0024\n",
      "\u001b[1;4mValidati 39     - 100    -          0.3386| 0.1794  | 0.5180 -           0.9449    | 0.9627      | 0.8132   | 0.5113     - 0.4916\u001b[0m\n",
      "Training 40     - 100    -          0.0382| 0.0153  | 0.0534 -           0.9829    | 0.9626      | 0.9488   | 0.5709     - 6.0107\n",
      "\u001b[1;4mValidati 40     - 100    -          0.3623| 0.1773  | 0.5396 -           0.9462    | 0.9594      | 0.8224   | 0.5166     - 0.4846\u001b[0m\n",
      "Training 42     - 100    -          0.0794| 0.0597  | 0.1391 -           0.9828    | 0.9618      | 0.9489   | 0.5649     - 6.0426\n",
      "\u001b[1;4mValidati 42     - 100    -          0.3626| 0.1785  | 0.5410 -           0.9463    | 0.9617      | 0.8070   | 0.5120     - 0.4871\u001b[0m\n",
      "Training 43     - 100    -          0.0946| 0.0283  | 0.1229 -           0.9784    | 0.9626      | 0.9354   | 0.5672     - 6.0252\n",
      "\u001b[1;4mValidati 43     - 100    -          0.3639| 0.1746  | 0.5385 -           0.9253    | 0.9602      | 0.7524   | 0.4664     - 0.4878\u001b[0m\n",
      "Training 44     - 100    -          0.0939| 0.0285  | 0.1224 -           0.9778    | 0.9623      | 0.9335   | 0.5639     - 6.0525\n",
      "\u001b[1;4mValidati 44     - 100    -          0.3663| 0.1887  | 0.5550 -           0.9394    | 0.9576      | 0.7886   | 0.4936     - 0.4862\u001b[0m\n",
      "Training 45     - 100    -          0.0346| 0.0211  | 0.0557 -           0.9799    | 0.9617      | 0.9398   | 0.5630     - 6.0590\n",
      "\u001b[1;4mValidati 45     - 100    -          0.3523| 0.1916  | 0.5439 -           0.9370    | 0.9571      | 0.7943   | 0.4963     - 0.4980\u001b[0m\n",
      "Training 46     - 100    -          0.0465| 0.0334  | 0.0799 -           0.9808    | 0.9613      | 0.9425   | 0.5596     - 6.0753\n",
      "\u001b[1;4mValidati 46     - 100    -          0.3679| 0.1861  | 0.5539 -           0.9373    | 0.9503      | 0.7850   | 0.4738     - 0.4901\u001b[0m\n",
      "Training 47     - 100    -          0.0383| 0.0103  | 0.0486 -           0.9849    | 0.9617      | 0.9545   | 0.5683     - 6.0088\n",
      "\u001b[1;4mValidati 47     - 100    -          0.3441| 0.1675  | 0.5116 -           0.9492    | 0.9619      | 0.8307   | 0.5357     - 0.4872\u001b[0m\n",
      "Training 48     - 100    -          0.0346| 0.0195  | 0.0541 -           0.9844    | 0.9618      | 0.9535   | 0.5703     - 6.1416\n",
      "\u001b[1;4mValidati 48     - 100    -          0.3739| 0.1882  | 0.5622 -           0.9403    | 0.9621      | 0.7877   | 0.5009     - 0.4991\u001b[0m\n",
      "Training 49     - 100    -          0.0574| 0.0428  | 0.1002 -           0.9817    | 0.9617      | 0.9453   | 0.5648     - 6.0337\n",
      "\u001b[1;4mValidati 49     - 100    -          0.3437| 0.1718  | 0.5155 -           0.9435    | 0.9611      | 0.8077   | 0.5216     - 0.4886\u001b[0m\n",
      "Training 50     - 100    -          0.1141| 0.0135  | 0.1276 -           0.9833    | 0.9627      | 0.9502   | 0.5747     - 6.0314\n",
      "\u001b[1;4mValidati 50     - 100    -          0.3363| 0.1864  | 0.5227 -           0.9336    | 0.9591      | 0.7868   | 0.5085     - 0.4876\u001b[0m\n",
      "Training 51     - 100    -          0.0359| 0.0258  | 0.0616 -           0.9809    | 0.9621      | 0.9434   | 0.5648     - 6.0545\n",
      "\u001b[1;4mValidati 51     - 100    -          0.3510| 0.1764  | 0.5274 -           0.9487    | 0.9593      | 0.8319   | 0.5257     - 0.5107\u001b[0m\n",
      "Training 52     - 100    -          0.0348| 0.0195  | 0.0543 -           0.9870    | 0.9626      | 0.9608   | 0.5760     - 6.0916\n",
      "\u001b[1;4mValidati 52     - 100    -          0.3676| 0.1780  | 0.5457 -           0.9479    | 0.9628      | 0.8125   | 0.5255     - 0.4846\u001b[0m\n",
      "Training 53     - 100    -          0.0357| 0.0273  | 0.0630 -           0.9864    | 0.9630      | 0.9594   | 0.5776     - 6.0264\n",
      "\u001b[1;4mValidati 53     - 100    -          0.3490| 0.1693  | 0.5183 -           0.9487    | 0.9635      | 0.8302   | 0.5363     - 0.4872\u001b[0m\n",
      "Training 54     - 100    -          0.0579| 0.0094  | 0.0673 -           0.9844    | 0.9628      | 0.9536   | 0.5771     - 6.0372\n",
      "\u001b[1;4mValidati 54     - 100    -          0.3531| 0.1705  | 0.5235 -           0.9429    | 0.9664      | 0.7991   | 0.4948     - 0.4845\u001b[0m\n",
      "Training 55     - 100    -          0.0197| 0.0207  | 0.0404 -           0.9841    | 0.9629      | 0.9527   | 0.5770     - 6.1184\n",
      "\u001b[1;4mValidati 55     - 100    -          0.3489| 0.1754  | 0.5244 -           0.9485    | 0.9634      | 0.8290   | 0.5111     - 0.4974\u001b[0m\n",
      "Training 56     - 100    -          0.0331| 0.0378  | 0.0709 -           0.9843    | 0.9628      | 0.9526   | 0.5763     - 5.9792\n",
      "\u001b[1;4mValidati 56     - 100    -          0.3505| 0.1672  | 0.5176 -           0.9451    | 0.9616      | 0.8209   | 0.5162     - 0.4903\u001b[0m\n",
      "Training 57     - 100    -          0.0361| 0.0316  | 0.0677 -           0.9850    | 0.9628      | 0.9554   | 0.5787     - 6.0344\n",
      "\u001b[1;4mValidati 57     - 100    -          0.3403| 0.1679  | 0.5082 -           0.9526    | 0.9630      | 0.8424   | 0.5155     - 0.4870\u001b[0m\n",
      "Training 58     - 100    -          0.0128| 0.0124  | 0.0252 -           0.9865    | 0.9633      | 0.9599   | 0.5826     - 6.0479\n",
      "\u001b[1;4mValidati 58     - 100    -          0.3406| 0.1694  | 0.5101 -           0.9451    | 0.9632      | 0.8196   | 0.5205     - 0.5008\u001b[0m\n",
      "Training 59     - 100    -          0.0347| 0.0293  | 0.0639 -           0.9858    | 0.9638      | 0.9574   | 0.5788     - 6.0389\n",
      "\u001b[1;4mValidati 59     - 100    -          0.3419| 0.1691  | 0.5110 -           0.9458    | 0.9609      | 0.8172   | 0.5242     - 0.4920\u001b[0m\n",
      "Training 60     - 100    -          0.0441| 0.0312  | 0.0752 -           0.9844    | 0.9626      | 0.9538   | 0.5760     - 6.2052\n",
      "\u001b[1;4mValidati 60     - 100    -          0.3588| 0.1758  | 0.5347 -           0.9484    | 0.9623      | 0.8294   | 0.5219     - 0.4880\u001b[0m\n",
      "Training 61     - 100    -          0.0317| 0.0116  | 0.0432 -           0.9868    | 0.9633      | 0.9604   | 0.5808     - 6.0172\n",
      "\u001b[1;4mValidati 61     - 100    -          0.3415| 0.1714  | 0.5129 -           0.9404    | 0.9636      | 0.8071   | 0.4973     - 0.4921\u001b[0m\n",
      "Training 62     - 100    -          0.0241| 0.0122  | 0.0363 -           0.9854    | 0.9620      | 0.9562   | 0.5704     - 6.0803\n",
      "\u001b[1;4mValidati 62     - 100    -          0.3529| 0.1733  | 0.5262 -           0.9407    | 0.9580      | 0.8076   | 0.5218     - 0.4979\u001b[0m\n",
      "Training 63     - 100    -          0.0654| 0.0323  | 0.0977 -           0.9865    | 0.9628      | 0.9597   | 0.5776     - 6.0101\n",
      "\u001b[1;4mValidati 63     - 100    -          0.3423| 0.1741  | 0.5164 -           0.9484    | 0.9603      | 0.8294   | 0.5209     - 0.4901\u001b[0m\n",
      "Training 64     - 100    -          0.0415| 0.0294  | 0.0708 -           0.9867    | 0.9621      | 0.9604   | 0.5735     - 6.0257\n",
      "\u001b[1;4mValidati 64     - 100    -          0.3454| 0.1684  | 0.5138 -           0.9436    | 0.9601      | 0.8168   | 0.5275     - 0.4848\u001b[0m\n",
      "Training 65     - 100    -          0.0442| 0.0437  | 0.0880 -           0.9865    | 0.9618      | 0.9595   | 0.5722     - 6.0937\n",
      "\u001b[1;4mValidati 65     - 100    -          0.3581| 0.1696  | 0.5277 -           0.9475    | 0.9600      | 0.8245   | 0.5229     - 0.4972\u001b[0m\n",
      "Training 66     - 100    -          0.0710| 0.0215  | 0.0925 -           0.9822    | 0.9618      | 0.9471   | 0.5646     - 5.9952\n",
      "\u001b[1;4mValidati 66     - 100    -          0.3481| 0.1669  | 0.5149 -           0.9441    | 0.9597      | 0.8179   | 0.5135     - 0.4874\u001b[0m\n",
      "Training 67     - 100    -          0.0094| 0.0248  | 0.0342 -           0.9873    | 0.9631      | 0.9620   | 0.5811     - 6.0060\n",
      "\u001b[1;4mValidati 67     - 100    -          0.3497| 0.1680  | 0.5177 -           0.9506    | 0.9630      | 0.8216   | 0.5268     - 0.4898\u001b[0m\n",
      "Training 68     - 100    -          0.0413| 0.0116  | 0.0529 -           0.9900    | 0.9625      | 0.9703   | 0.5815     - 6.0177\n",
      "\u001b[1;4mValidati 68     - 100    -          0.3388| 0.1655  | 0.5043 -           0.9499    | 0.9583      | 0.8311   | 0.5250     - 0.4859\u001b[0m\n",
      "Training 69     - 100    -          0.0370| 0.0308  | 0.0678 -           0.9893    | 0.9621      | 0.9683   | 0.5799     - 6.0564\n",
      "\u001b[1;4mValidati 69     - 100    -          0.3432| 0.1659  | 0.5091 -           0.9412    | 0.9563      | 0.8074   | 0.5156     - 0.5076\u001b[0m\n",
      "Training 70     - 100    -          0.0414| 0.0154  | 0.0569 -           0.9850    | 0.9628      | 0.9550   | 0.5797     - 6.0596\n",
      "\u001b[1;4mValidati 70     - 100    -          0.3541| 0.1796  | 0.5337 -           0.9411    | 0.9576      | 0.8113   | 0.5132     - 0.4895\u001b[0m\n",
      "Training 71     - 100    -          0.0058| 0.0195  | 0.0253 -           0.9860    | 0.9630      | 0.9583   | 0.5809     - 6.0153\n",
      "\u001b[1;4mValidati 71     - 100    -          0.3672| 0.1722  | 0.5395 -           0.9438    | 0.9595      | 0.8109   | 0.5220     - 0.4866\u001b[0m\n",
      "Training 72     - 100    -          0.0638| 0.0187  | 0.0825 -           0.9870    | 0.9637      | 0.9613   | 0.5840     - 6.0713\n",
      "\u001b[1;4mValidati 72     - 100    -          0.3845| 0.1819  | 0.5664 -           0.9471    | 0.9644      | 0.8292   | 0.5180     - 0.5128\u001b[0m\n",
      "Training 73     - 100    -          0.0375| 0.0271  | 0.0646 -           0.9865    | 0.9631      | 0.9600   | 0.5824     - 6.0363\n",
      "\u001b[1;4mValidati 73     - 100    -          0.3447| 0.1833  | 0.5280 -           0.9484    | 0.9578      | 0.8307   | 0.5347     - 0.4865\u001b[0m\n",
      "Training 74     - 100    -          0.0123| 0.0240  | 0.0362 -           0.9889    | 0.9627      | 0.9671   | 0.5820     - 6.0306\n",
      "\u001b[1;4mValidati 74     - 100    -          0.3433| 0.1704  | 0.5137 -           0.9496    | 0.9632      | 0.8321   | 0.5332     - 0.4892\u001b[0m\n",
      "Training 75     - 100    -          0.0379| 0.0210  | 0.0589 -           0.9900    | 0.9635      | 0.9706   | 0.5888     - 6.0814\n",
      "\u001b[1;4mValidati 75     - 100    -          0.3463| 0.1718  | 0.5181 -           0.9492    | 0.9617      | 0.8341   | 0.5276     - 0.4883\u001b[0m\n",
      "Training 76     - 100    -          0.0740| 0.0243  | 0.0982 -           0.9890    | 0.9633      | 0.9674   | 0.5883     - 6.0279\n",
      "\u001b[1;4mValidati 76     - 100    -          0.3420| 0.1765  | 0.5185 -           0.9461    | 0.9594      | 0.8251   | 0.5317     - 0.5004\u001b[0m\n",
      "Training 77     - 100    -          0.0987| 0.0354  | 0.1341 -           0.9850    | 0.9633      | 0.9556   | 0.5830     - 6.0068\n",
      "\u001b[1;4mValidati 77     - 100    -          0.3383| 0.1690  | 0.5073 -           0.9457    | 0.9633      | 0.8184   | 0.5299     - 0.4909\u001b[0m\n",
      "Training 78     - 100    -          0.0574| 0.0427  | 0.1001 -           0.9834    | 0.9625      | 0.9509   | 0.5762     - 6.0089\n",
      "\u001b[1;4mValidati 78     - 100    -          0.3363| 0.1709  | 0.5072 -           0.9422    | 0.9565      | 0.8130   | 0.4921     - 0.4879\u001b[0m\n",
      "Training 79     - 100    -          0.0376| 0.0264  | 0.0641 -           0.9866    | 0.9629      | 0.9600   | 0.5795     - 6.0805\n",
      "\u001b[1;4mValidati 79     - 100    -          0.3484| 0.1710  | 0.5194 -           0.9466    | 0.9611      | 0.8246   | 0.5184     - 0.4993\u001b[0m\n",
      "Training 80     - 100    -          0.0354| 0.0205  | 0.0559 -           0.9830    | 0.9614      | 0.9493   | 0.5676     - 6.0563\n",
      "\u001b[1;4mValidati 80     - 100    -          0.3553| 0.1704  | 0.5256 -           0.9450    | 0.9588      | 0.8158   | 0.5033     - 0.4847\u001b[0m\n",
      "Training 81     - 100    -          0.0588| 0.0378  | 0.0966 -           0.9885    | 0.9627      | 0.9658   | 0.5800     - 6.0051\n",
      "\u001b[1;4mValidati 81     - 100    -          0.3491| 0.1710  | 0.5201 -           0.9496    | 0.9595      | 0.8323   | 0.5301     - 0.4911\u001b[0m\n",
      "Training 82     - 100    -          0.0031| 0.0158  | 0.0190 -           0.9904    | 0.9617      | 0.9711   | 0.5741     - 6.0317\n",
      "\u001b[1;4mValidati 82     - 100    -          0.3378| 0.1719  | 0.5097 -           0.9492    | 0.9585      | 0.8310   | 0.5298     - 0.5032\u001b[0m\n",
      "Training 83     - 100    -          0.0604| 0.0272  | 0.0875 -           0.9901    | 0.9624      | 0.9706   | 0.5789     - 6.0590\n",
      "\u001b[1;4mValidati 83     - 100    -          0.3408| 0.1675  | 0.5083 -           0.9485    | 0.9631      | 0.8284   | 0.5175     - 0.4902\u001b[0m\n",
      "Training 84     - 100    -          0.0347| 0.0273  | 0.0620 -           0.9890    | 0.9638      | 0.9674   | 0.5880     - 6.0156\n",
      "\u001b[1;4mValidati 84     - 100    -          0.3426| 0.1669  | 0.5094 -           0.9483    | 0.9631      | 0.8306   | 0.5293     - 0.4914\u001b[0m\n",
      "Training 85     - 100    -          0.0339| 0.0252  | 0.0591 -           0.9892    | 0.9627      | 0.9676   | 0.5818     - 6.0605\n",
      "\u001b[1;4mValidati 85     - 100    -          0.3478| 0.1709  | 0.5187 -           0.9466    | 0.9572      | 0.8249   | 0.5110     - 0.4882\u001b[0m\n",
      "Training 86     - 100    -          0.0812| 0.0290  | 0.1102 -           0.9903    | 0.9627      | 0.9713   | 0.5841     - 6.0281\n",
      "\u001b[1;4mValidati 86     - 100    -          0.3445| 0.1667  | 0.5112 -           0.9453    | 0.9625      | 0.8222   | 0.5173     - 0.4992\u001b[0m\n",
      "Training 87     - 100    -          0.0065| 0.0130  | 0.0195 -           0.9893    | 0.9646      | 0.9682   | 0.5941     - 6.0117\n",
      "\u001b[1;4mValidati 87     - 100    -          0.3720| 0.1654  | 0.5374 -           0.9457    | 0.9656      | 0.8094   | 0.5186     - 0.4900\u001b[0m\n",
      "Training 88     - 100    -          0.0503| 0.0444  | 0.0946 -           0.9865    | 0.9632      | 0.9597   | 0.5837     - 6.0229\n",
      "\u001b[1;4mValidati 88     - 100    -          0.3502| 0.1719  | 0.5221 -           0.9462    | 0.9593      | 0.8221   | 0.5208     - 0.4851\u001b[0m\n",
      "Training 89     - 100    -          0.0181| 0.0172  | 0.0353 -           0.9887    | 0.9637      | 0.9666   | 0.5887     - 6.0488\n",
      "\u001b[1;4mValidati 89     - 100    -          0.3397| 0.1676  | 0.5073 -           0.9514    | 0.9652      | 0.8373   | 0.5338     - 0.4982\u001b[0m\n",
      "Training 90     - 100    -          0.0056| 0.0293  | 0.0350 -           0.9893    | 0.9638      | 0.9684   | 0.5889     - 6.0919\n",
      "\u001b[1;4mValidati 90     - 100    -          0.3482| 0.1825  | 0.5308 -           0.9492    | 0.9598      | 0.8320   | 0.5205     - 0.4857\u001b[0m\n",
      "Training 91     - 100    -          0.0293| 0.0209  | 0.0502 -           0.9898    | 0.9634      | 0.9697   | 0.5886     - 6.0074\n",
      "\u001b[1;4mValidati 91     - 100    -          0.3405| 0.1696  | 0.5100 -           0.9419    | 0.9611      | 0.8091   | 0.5101     - 0.4904\u001b[0m\n",
      "Training 92     - 100    -          0.0355| 0.0218  | 0.0573 -           0.9858    | 0.9639      | 0.9574   | 0.5857     - 6.0076\n",
      "\u001b[1;4mValidati 92     - 100    -          0.3388| 0.1703  | 0.5091 -           0.9487    | 0.9596      | 0.8334   | 0.5321     - 0.4869\u001b[0m\n",
      "Training 93     - 100    -          0.0457| 0.0167  | 0.0625 -           0.9908    | 0.9632      | 0.9729   | 0.5860     - 6.0762\n",
      "\u001b[1;4mValidati 93     - 100    -          0.3434| 0.1680  | 0.5115 -           0.9500    | 0.9663      | 0.8340   | 0.5341     - 0.5007\u001b[0m\n",
      "Training 94     - 100    -          0.0171| 0.0236  | 0.0407 -           0.9920    | 0.9642      | 0.9762   | 0.5953     - 6.0094\n",
      "\u001b[1;4mValidati 94     - 100    -          0.3590| 0.1719  | 0.5309 -           0.9506    | 0.9617      | 0.8264   | 0.5387     - 0.4879\u001b[0m\n",
      "Training 95     - 100    -          0.0197| 0.0214  | 0.0410 -           0.9910    | 0.9625      | 0.9731   | 0.5846     - 6.0519\n",
      "\u001b[1;4mValidati 95     - 100    -          0.3368| 0.1635  | 0.5003 -           0.9488    | 0.9651      | 0.8320   | 0.5255     - 0.4850\u001b[0m\n",
      "Training 96     - 100    -          0.0498| 0.0176  | 0.0673 -           0.9885    | 0.9634      | 0.9659   | 0.5883     - 6.0025\n",
      "\u001b[1;4mValidati 96     - 100    -          0.3501| 0.1657  | 0.5158 -           0.9519    | 0.9625      | 0.8407   | 0.5259     - 0.4970\u001b[0m\n",
      "Training 97     - 100    -          0.0448| 0.0284  | 0.0732 -           0.9836    | 0.9641      | 0.9512   | 0.5867     - 6.0293\n",
      "\u001b[1;4mValidati 97     - 100    -          0.3371| 0.1816  | 0.5187 -           0.9420    | 0.9637      | 0.8120   | 0.5104     - 0.4871\u001b[0m\n",
      "Training 98     - 100    -          0.0599| 0.0264  | 0.0863 -           0.9850    | 0.9636      | 0.9553   | 0.5862     - 6.0156\n",
      "\u001b[1;4mValidati 98     - 100    -          0.3509| 0.1688  | 0.5197 -           0.9416    | 0.9639      | 0.8089   | 0.5211     - 0.4890\u001b[0m\n",
      "Training 99     - 100    -          0.0087| 0.0129  | 0.0217 -           0.9881    | 0.9649      | 0.9647   | 0.5926     - 6.0122\n",
      "\u001b[1;4mValidati 99     - 100    -          0.3410| 0.1734  | 0.5144 -           0.9469    | 0.9609      | 0.8235   | 0.5235     - 0.4863\u001b[0m\n",
      "Training 100    - 100    -          0.0106| 0.0222  | 0.0327 -           0.9883    | 0.9645      | 0.9652   | 0.5937     - 6.1286\n",
      "\u001b[1;4mValidati 100    - 100    -          0.3498| 0.1713  | 0.5211 -           0.9435    | 0.9663      | 0.8117   | 0.5151     - 0.5132\u001b[0m\r"
     ]
    }
   ],
   "source": [
    "# tensorboard\n",
    "title = \"dcase2019_system_%s\" % (get_datetime())\n",
    "tensorboard = SummaryWriter(log_dir=Path(\"../tensorboard/%s\" % title), comment=\"weak baseline\")\n",
    "\n",
    "print(header)\n",
    "for e in range(nb_epochs):\n",
    "    train(e)\n",
    "    val(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ♫♪.ılılıll|̲̅̅●̲̅̅|̲̅̅=̲̅̅|̲̅̅●̲̅̅|llılılı.♫♪"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcase2020",
   "language": "python",
   "name": "dcase2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
